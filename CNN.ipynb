{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0HR5yNIdl0n"
      },
      "source": [
        "# Load Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai8XDSkGdvff"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from tensorflow.keras import layers, losses\r\n",
        "from tensorflow.keras.datasets import fashion_mnist\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\r\n",
        "from keras.layers import Conv1D, MaxPooling1D\r\n",
        "from keras.callbacks import TensorBoard\r\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiUeNG2KVACw"
      },
      "source": [
        "\r\n",
        "\r\n",
        "# Loading and Preparing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "qBnjoQLTVMP5",
        "outputId": "fcb1f452-b124-4d9b-a8d7-79882cded0b9"
      },
      "source": [
        "# Set a random seed for reproducibility.\r\n",
        "np.random.seed(1648)\r\n",
        "# Download the dataset\r\n",
        "dataframe = pd.read_csv('http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv', header=None)\r\n",
        "raw_data = dataframe.values\r\n",
        "dataframe.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>105</th>\n",
              "      <th>106</th>\n",
              "      <th>107</th>\n",
              "      <th>108</th>\n",
              "      <th>109</th>\n",
              "      <th>110</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>113</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.112522</td>\n",
              "      <td>-2.827204</td>\n",
              "      <td>-3.773897</td>\n",
              "      <td>-4.349751</td>\n",
              "      <td>-4.376041</td>\n",
              "      <td>-3.474986</td>\n",
              "      <td>-2.181408</td>\n",
              "      <td>-1.818287</td>\n",
              "      <td>-1.250522</td>\n",
              "      <td>-0.477492</td>\n",
              "      <td>-0.363808</td>\n",
              "      <td>-0.491957</td>\n",
              "      <td>-0.421855</td>\n",
              "      <td>-0.309201</td>\n",
              "      <td>-0.495939</td>\n",
              "      <td>-0.342119</td>\n",
              "      <td>-0.355336</td>\n",
              "      <td>-0.367913</td>\n",
              "      <td>-0.316503</td>\n",
              "      <td>-0.412374</td>\n",
              "      <td>-0.471672</td>\n",
              "      <td>-0.413458</td>\n",
              "      <td>-0.364617</td>\n",
              "      <td>-0.449298</td>\n",
              "      <td>-0.471419</td>\n",
              "      <td>-0.424777</td>\n",
              "      <td>-0.462517</td>\n",
              "      <td>-0.552472</td>\n",
              "      <td>-0.475375</td>\n",
              "      <td>-0.694200</td>\n",
              "      <td>-0.701868</td>\n",
              "      <td>-0.593812</td>\n",
              "      <td>-0.660684</td>\n",
              "      <td>-0.713831</td>\n",
              "      <td>-0.769807</td>\n",
              "      <td>-0.672282</td>\n",
              "      <td>-0.653676</td>\n",
              "      <td>-0.639406</td>\n",
              "      <td>-0.559302</td>\n",
              "      <td>-0.591670</td>\n",
              "      <td>...</td>\n",
              "      <td>1.258179</td>\n",
              "      <td>1.433789</td>\n",
              "      <td>1.700533</td>\n",
              "      <td>1.999043</td>\n",
              "      <td>2.125341</td>\n",
              "      <td>1.993291</td>\n",
              "      <td>1.932246</td>\n",
              "      <td>1.797437</td>\n",
              "      <td>1.522284</td>\n",
              "      <td>1.251168</td>\n",
              "      <td>0.998730</td>\n",
              "      <td>0.483722</td>\n",
              "      <td>0.023132</td>\n",
              "      <td>-0.194914</td>\n",
              "      <td>-0.220917</td>\n",
              "      <td>-0.243737</td>\n",
              "      <td>-0.254695</td>\n",
              "      <td>-0.291136</td>\n",
              "      <td>-0.256490</td>\n",
              "      <td>-0.227874</td>\n",
              "      <td>-0.322423</td>\n",
              "      <td>-0.289286</td>\n",
              "      <td>-0.318170</td>\n",
              "      <td>-0.363654</td>\n",
              "      <td>-0.393456</td>\n",
              "      <td>-0.266419</td>\n",
              "      <td>-0.256823</td>\n",
              "      <td>-0.288694</td>\n",
              "      <td>-0.162338</td>\n",
              "      <td>0.160348</td>\n",
              "      <td>0.792168</td>\n",
              "      <td>0.933541</td>\n",
              "      <td>0.796958</td>\n",
              "      <td>0.578621</td>\n",
              "      <td>0.257740</td>\n",
              "      <td>0.228077</td>\n",
              "      <td>0.123431</td>\n",
              "      <td>0.925286</td>\n",
              "      <td>0.193137</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.100878</td>\n",
              "      <td>-3.996840</td>\n",
              "      <td>-4.285843</td>\n",
              "      <td>-4.506579</td>\n",
              "      <td>-4.022377</td>\n",
              "      <td>-3.234368</td>\n",
              "      <td>-1.566126</td>\n",
              "      <td>-0.992258</td>\n",
              "      <td>-0.754680</td>\n",
              "      <td>0.042321</td>\n",
              "      <td>0.148951</td>\n",
              "      <td>0.183527</td>\n",
              "      <td>0.294876</td>\n",
              "      <td>0.190233</td>\n",
              "      <td>0.235575</td>\n",
              "      <td>0.253487</td>\n",
              "      <td>0.221742</td>\n",
              "      <td>0.050233</td>\n",
              "      <td>0.178042</td>\n",
              "      <td>0.139563</td>\n",
              "      <td>0.046794</td>\n",
              "      <td>0.043007</td>\n",
              "      <td>0.106544</td>\n",
              "      <td>0.012654</td>\n",
              "      <td>0.003995</td>\n",
              "      <td>0.045724</td>\n",
              "      <td>-0.045999</td>\n",
              "      <td>-0.072667</td>\n",
              "      <td>-0.071078</td>\n",
              "      <td>-0.153866</td>\n",
              "      <td>-0.227254</td>\n",
              "      <td>-0.249270</td>\n",
              "      <td>-0.253489</td>\n",
              "      <td>-0.332835</td>\n",
              "      <td>-0.264330</td>\n",
              "      <td>-0.345825</td>\n",
              "      <td>-0.310781</td>\n",
              "      <td>-0.334160</td>\n",
              "      <td>-0.306178</td>\n",
              "      <td>-0.174563</td>\n",
              "      <td>...</td>\n",
              "      <td>1.808428</td>\n",
              "      <td>2.164346</td>\n",
              "      <td>2.070747</td>\n",
              "      <td>1.903614</td>\n",
              "      <td>1.764455</td>\n",
              "      <td>1.507769</td>\n",
              "      <td>1.293428</td>\n",
              "      <td>0.894562</td>\n",
              "      <td>0.578016</td>\n",
              "      <td>0.244343</td>\n",
              "      <td>-0.286443</td>\n",
              "      <td>-0.515881</td>\n",
              "      <td>-0.732707</td>\n",
              "      <td>-0.832465</td>\n",
              "      <td>-0.803318</td>\n",
              "      <td>-0.836252</td>\n",
              "      <td>-0.777865</td>\n",
              "      <td>-0.774753</td>\n",
              "      <td>-0.733404</td>\n",
              "      <td>-0.721386</td>\n",
              "      <td>-0.832095</td>\n",
              "      <td>-0.711982</td>\n",
              "      <td>-0.751867</td>\n",
              "      <td>-0.757720</td>\n",
              "      <td>-0.853120</td>\n",
              "      <td>-0.766988</td>\n",
              "      <td>-0.688161</td>\n",
              "      <td>-0.519923</td>\n",
              "      <td>0.039406</td>\n",
              "      <td>0.560327</td>\n",
              "      <td>0.538356</td>\n",
              "      <td>0.656881</td>\n",
              "      <td>0.787490</td>\n",
              "      <td>0.724046</td>\n",
              "      <td>0.555784</td>\n",
              "      <td>0.476333</td>\n",
              "      <td>0.773820</td>\n",
              "      <td>1.119621</td>\n",
              "      <td>-1.436250</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.567088</td>\n",
              "      <td>-2.593450</td>\n",
              "      <td>-3.874230</td>\n",
              "      <td>-4.584095</td>\n",
              "      <td>-4.187449</td>\n",
              "      <td>-3.151462</td>\n",
              "      <td>-1.742940</td>\n",
              "      <td>-1.490658</td>\n",
              "      <td>-1.183580</td>\n",
              "      <td>-0.394229</td>\n",
              "      <td>-0.282897</td>\n",
              "      <td>-0.356926</td>\n",
              "      <td>-0.287297</td>\n",
              "      <td>-0.399489</td>\n",
              "      <td>-0.473244</td>\n",
              "      <td>-0.379048</td>\n",
              "      <td>-0.399039</td>\n",
              "      <td>-0.178594</td>\n",
              "      <td>-0.339522</td>\n",
              "      <td>-0.498447</td>\n",
              "      <td>-0.337251</td>\n",
              "      <td>-0.425480</td>\n",
              "      <td>-0.423952</td>\n",
              "      <td>-0.463170</td>\n",
              "      <td>-0.493253</td>\n",
              "      <td>-0.549749</td>\n",
              "      <td>-0.529831</td>\n",
              "      <td>-0.530935</td>\n",
              "      <td>-0.502365</td>\n",
              "      <td>-0.417368</td>\n",
              "      <td>-0.526346</td>\n",
              "      <td>-0.471005</td>\n",
              "      <td>-0.676784</td>\n",
              "      <td>-0.898612</td>\n",
              "      <td>-0.610571</td>\n",
              "      <td>-0.530164</td>\n",
              "      <td>-0.765674</td>\n",
              "      <td>-0.581937</td>\n",
              "      <td>-0.537848</td>\n",
              "      <td>-0.556386</td>\n",
              "      <td>...</td>\n",
              "      <td>1.810988</td>\n",
              "      <td>2.185398</td>\n",
              "      <td>2.262985</td>\n",
              "      <td>2.052920</td>\n",
              "      <td>1.890488</td>\n",
              "      <td>1.793033</td>\n",
              "      <td>1.564784</td>\n",
              "      <td>1.234619</td>\n",
              "      <td>0.900302</td>\n",
              "      <td>0.551957</td>\n",
              "      <td>0.258222</td>\n",
              "      <td>-0.128587</td>\n",
              "      <td>-0.092585</td>\n",
              "      <td>-0.168606</td>\n",
              "      <td>-0.495989</td>\n",
              "      <td>-0.395034</td>\n",
              "      <td>-0.328238</td>\n",
              "      <td>-0.448138</td>\n",
              "      <td>-0.268230</td>\n",
              "      <td>-0.456415</td>\n",
              "      <td>-0.357867</td>\n",
              "      <td>-0.317508</td>\n",
              "      <td>-0.434112</td>\n",
              "      <td>-0.549203</td>\n",
              "      <td>-0.324615</td>\n",
              "      <td>-0.268082</td>\n",
              "      <td>-0.220384</td>\n",
              "      <td>-0.117429</td>\n",
              "      <td>0.614059</td>\n",
              "      <td>1.284825</td>\n",
              "      <td>0.886073</td>\n",
              "      <td>0.531452</td>\n",
              "      <td>0.311377</td>\n",
              "      <td>-0.021919</td>\n",
              "      <td>-0.713683</td>\n",
              "      <td>-0.532197</td>\n",
              "      <td>0.321097</td>\n",
              "      <td>0.904227</td>\n",
              "      <td>-0.421797</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.490473</td>\n",
              "      <td>-1.914407</td>\n",
              "      <td>-3.616364</td>\n",
              "      <td>-4.318823</td>\n",
              "      <td>-4.268016</td>\n",
              "      <td>-3.881110</td>\n",
              "      <td>-2.993280</td>\n",
              "      <td>-1.671131</td>\n",
              "      <td>-1.333884</td>\n",
              "      <td>-0.965629</td>\n",
              "      <td>-0.183319</td>\n",
              "      <td>-0.101657</td>\n",
              "      <td>-0.273874</td>\n",
              "      <td>-0.127818</td>\n",
              "      <td>-0.195983</td>\n",
              "      <td>-0.213523</td>\n",
              "      <td>-0.176473</td>\n",
              "      <td>-0.156932</td>\n",
              "      <td>-0.149172</td>\n",
              "      <td>-0.181510</td>\n",
              "      <td>-0.180074</td>\n",
              "      <td>-0.246151</td>\n",
              "      <td>-0.274260</td>\n",
              "      <td>-0.140960</td>\n",
              "      <td>-0.277449</td>\n",
              "      <td>-0.382549</td>\n",
              "      <td>-0.311937</td>\n",
              "      <td>-0.360093</td>\n",
              "      <td>-0.405968</td>\n",
              "      <td>-0.571433</td>\n",
              "      <td>-0.524106</td>\n",
              "      <td>-0.537886</td>\n",
              "      <td>-0.606778</td>\n",
              "      <td>-0.661446</td>\n",
              "      <td>-0.683375</td>\n",
              "      <td>-0.746683</td>\n",
              "      <td>-0.635662</td>\n",
              "      <td>-0.625231</td>\n",
              "      <td>-0.540094</td>\n",
              "      <td>-0.674995</td>\n",
              "      <td>...</td>\n",
              "      <td>1.772155</td>\n",
              "      <td>2.000769</td>\n",
              "      <td>1.925003</td>\n",
              "      <td>1.898426</td>\n",
              "      <td>1.720953</td>\n",
              "      <td>1.501711</td>\n",
              "      <td>1.422492</td>\n",
              "      <td>1.023225</td>\n",
              "      <td>0.776341</td>\n",
              "      <td>0.504426</td>\n",
              "      <td>0.056382</td>\n",
              "      <td>-0.233161</td>\n",
              "      <td>-0.406388</td>\n",
              "      <td>-0.327528</td>\n",
              "      <td>-0.460868</td>\n",
              "      <td>-0.402536</td>\n",
              "      <td>-0.345752</td>\n",
              "      <td>-0.354206</td>\n",
              "      <td>-0.439959</td>\n",
              "      <td>-0.425326</td>\n",
              "      <td>-0.439789</td>\n",
              "      <td>-0.451835</td>\n",
              "      <td>-0.395926</td>\n",
              "      <td>-0.448762</td>\n",
              "      <td>-0.391789</td>\n",
              "      <td>-0.376307</td>\n",
              "      <td>-0.461069</td>\n",
              "      <td>-0.253524</td>\n",
              "      <td>0.213006</td>\n",
              "      <td>0.491173</td>\n",
              "      <td>0.350816</td>\n",
              "      <td>0.499111</td>\n",
              "      <td>0.600345</td>\n",
              "      <td>0.842069</td>\n",
              "      <td>0.952074</td>\n",
              "      <td>0.990133</td>\n",
              "      <td>1.086798</td>\n",
              "      <td>1.403011</td>\n",
              "      <td>-0.383564</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.800232</td>\n",
              "      <td>-0.874252</td>\n",
              "      <td>-2.384761</td>\n",
              "      <td>-3.973292</td>\n",
              "      <td>-4.338224</td>\n",
              "      <td>-3.802422</td>\n",
              "      <td>-2.534510</td>\n",
              "      <td>-1.783423</td>\n",
              "      <td>-1.594450</td>\n",
              "      <td>-0.753199</td>\n",
              "      <td>-0.298107</td>\n",
              "      <td>-0.428928</td>\n",
              "      <td>-0.491351</td>\n",
              "      <td>-0.361304</td>\n",
              "      <td>-0.339296</td>\n",
              "      <td>-0.324952</td>\n",
              "      <td>-0.290113</td>\n",
              "      <td>-0.363051</td>\n",
              "      <td>-0.525684</td>\n",
              "      <td>-0.597423</td>\n",
              "      <td>-0.575523</td>\n",
              "      <td>-0.567503</td>\n",
              "      <td>-0.504555</td>\n",
              "      <td>-0.618406</td>\n",
              "      <td>-0.682814</td>\n",
              "      <td>-0.743849</td>\n",
              "      <td>-0.815588</td>\n",
              "      <td>-0.826902</td>\n",
              "      <td>-0.782374</td>\n",
              "      <td>-0.929462</td>\n",
              "      <td>-0.999672</td>\n",
              "      <td>-1.060969</td>\n",
              "      <td>-1.007877</td>\n",
              "      <td>-1.028735</td>\n",
              "      <td>-1.122629</td>\n",
              "      <td>-1.028650</td>\n",
              "      <td>-1.046515</td>\n",
              "      <td>-1.063372</td>\n",
              "      <td>-1.122423</td>\n",
              "      <td>-0.983242</td>\n",
              "      <td>...</td>\n",
              "      <td>1.155363</td>\n",
              "      <td>1.336254</td>\n",
              "      <td>1.627534</td>\n",
              "      <td>1.717594</td>\n",
              "      <td>1.696487</td>\n",
              "      <td>1.741686</td>\n",
              "      <td>1.674078</td>\n",
              "      <td>1.546928</td>\n",
              "      <td>1.331738</td>\n",
              "      <td>1.110168</td>\n",
              "      <td>0.922210</td>\n",
              "      <td>0.521777</td>\n",
              "      <td>0.154852</td>\n",
              "      <td>-0.123861</td>\n",
              "      <td>-0.202998</td>\n",
              "      <td>-0.247956</td>\n",
              "      <td>-0.219122</td>\n",
              "      <td>-0.214695</td>\n",
              "      <td>-0.319215</td>\n",
              "      <td>-0.198597</td>\n",
              "      <td>-0.151618</td>\n",
              "      <td>-0.129593</td>\n",
              "      <td>-0.074939</td>\n",
              "      <td>-0.196807</td>\n",
              "      <td>-0.174795</td>\n",
              "      <td>-0.208833</td>\n",
              "      <td>-0.210754</td>\n",
              "      <td>-0.100485</td>\n",
              "      <td>0.197446</td>\n",
              "      <td>0.966606</td>\n",
              "      <td>1.148884</td>\n",
              "      <td>0.958434</td>\n",
              "      <td>1.059025</td>\n",
              "      <td>1.371682</td>\n",
              "      <td>1.277392</td>\n",
              "      <td>0.960304</td>\n",
              "      <td>0.971020</td>\n",
              "      <td>1.614392</td>\n",
              "      <td>1.421456</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 141 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3    ...       137       138       139  140\n",
              "0 -0.112522 -2.827204 -3.773897 -4.349751  ...  0.123431  0.925286  0.193137  1.0\n",
              "1 -1.100878 -3.996840 -4.285843 -4.506579  ...  0.773820  1.119621 -1.436250  1.0\n",
              "2 -0.567088 -2.593450 -3.874230 -4.584095  ...  0.321097  0.904227 -0.421797  1.0\n",
              "3  0.490473 -1.914407 -3.616364 -4.318823  ...  1.086798  1.403011 -0.383564  1.0\n",
              "4  0.800232 -0.874252 -2.384761 -3.973292  ...  0.971020  1.614392  1.421456  1.0\n",
              "\n",
              "[5 rows x 141 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Sj303bndVVKq",
        "outputId": "aa6b3c2f-86fb-4926-cee8-69c4a2d50c14"
      },
      "source": [
        "# The last element contains the labels\r\n",
        "labels = raw_data[:, -1]\r\n",
        "\r\n",
        "# The other data points are the electrocadriogram data\r\n",
        "data = raw_data[:, 0:-1]\r\n",
        "\r\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=21)\r\n",
        "\r\n",
        "# Normalize to [0, 1]\r\n",
        "min_val = tf.reduce_min(train_data)\r\n",
        "max_val = tf.reduce_max(train_data)\r\n",
        "\r\n",
        "train_data = (train_data - min_val) / (max_val - min_val)\r\n",
        "test_data = (test_data - min_val) / (max_val - min_val)\r\n",
        "\r\n",
        "train_data = tf.cast(train_data, tf.float32)\r\n",
        "test_data = tf.cast(test_data, tf.float32)\r\n",
        "\r\n",
        "# plot data\r\n",
        "plt.grid()\r\n",
        "plt.plot(np.arange(140), train_data[0])\r\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "PzEZDLuMVdS5",
        "outputId": "2d0d1695-520a-480a-d74e-bada317236d5"
      },
      "source": [
        "plt.grid()\r\n",
        "plt.plot(np.arange(140), train_data[100])\r\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAlmELcueHuX"
      },
      "source": [
        "All the above code for loading and preparing the data was provided by Richard Jiang."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hy3BnvN5AT4"
      },
      "source": [
        "# the model requires a 3-dimensional input therefore, we need to expand the \r\n",
        "# dimensions of the training and testing data.\r\n",
        "train_data = np.expand_dims(train_data, 2)\r\n",
        "test_data = np.expand_dims(test_data, 2)\r\n",
        "\r\n",
        "# the model requires these to be in binary matrix form.\r\n",
        "train_classes = to_categorical(train_labels, 2)\r\n",
        "test_classes = to_categorical(test_labels, 2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpNjY4rgWGvJ"
      },
      "source": [
        "# Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi7tQaaMWQ-b"
      },
      "source": [
        "input_shape = (140, 1)\r\n",
        "def buildmodel(filters, kernel_size, no_epochs, batch_size):\r\n",
        "    #initiate a sequential keras model (sequential for simplicity)\r\n",
        "    model = Sequential()\r\n",
        "    #first two layers are convolutional.\r\n",
        "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', \r\n",
        "                     input_shape=input_shape))\r\n",
        "    model.add(Conv1D(filters=filters, kernel_size=kernel_size, activation='relu'))\r\n",
        "    #dropout layer for regularisation\r\n",
        "    model.add(Dropout(0.5))\r\n",
        "    #pooling layer\r\n",
        "    model.add(MaxPooling1D(pool_size=2))\r\n",
        "    #outputs flattened to one long vector\r\n",
        "    model.add(Flatten())\r\n",
        "    #fully-connected layer\r\n",
        "    model.add(Dense(100, activation='relu'))\r\n",
        "    #output layer\r\n",
        "    model.add(Dense(2, activation='softmax'))\r\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', \r\n",
        "                  metrics=['accuracy'])\r\n",
        "    #fit the network to our data\r\n",
        "    model.fit(train_data, train_classes, epochs=no_epochs, batch_size=batch_size, \r\n",
        "              shuffle=True, validation_data=(test_data, test_classes),\r\n",
        "              callbacks=[TensorBoard(log_dir='/tmp/model_cnn')])\r\n",
        "    return model\r\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk9c5VE3pi7j"
      },
      "source": [
        "# Optimise Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zav01d-p0NV"
      },
      "source": [
        "Determining number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "CRIAocXUqYe_",
        "outputId": "653ca44c-dec8-45b3-b019-e09984d4fc8b"
      },
      "source": [
        "#build the model \r\n",
        "model = buildmodel(64, 3, 10, 100)\r\n",
        "#plot the loss and the value loss over the different epochs.\r\n",
        "plt.plot(model.history.history[\"loss\"])\r\n",
        "plt.plot(model.history.history[\"val_loss\"])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "40/40 [==============================] - 4s 75ms/step - loss: 0.5268 - accuracy: 0.7070 - val_loss: 0.1113 - val_accuracy: 0.9590\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 2s 62ms/step - loss: 0.0954 - accuracy: 0.9632 - val_loss: 0.0781 - val_accuracy: 0.9800\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 2s 62ms/step - loss: 0.0678 - accuracy: 0.9802 - val_loss: 0.0658 - val_accuracy: 0.9830\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 2s 62ms/step - loss: 0.0639 - accuracy: 0.9818 - val_loss: 0.0639 - val_accuracy: 0.9860\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 2s 62ms/step - loss: 0.0523 - accuracy: 0.9830 - val_loss: 0.0686 - val_accuracy: 0.9840\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0456 - accuracy: 0.9851 - val_loss: 0.0588 - val_accuracy: 0.9840\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 3s 63ms/step - loss: 0.0436 - accuracy: 0.9873 - val_loss: 0.0475 - val_accuracy: 0.9910\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 3s 63ms/step - loss: 0.0299 - accuracy: 0.9904 - val_loss: 0.0453 - val_accuracy: 0.9900\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 3s 63ms/step - loss: 0.0378 - accuracy: 0.9887 - val_loss: 0.0443 - val_accuracy: 0.9880\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 2s 63ms/step - loss: 0.0321 - accuracy: 0.9922 - val_loss: 0.0426 - val_accuracy: 0.9880\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1435279860>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3Scd33n8fd3ZjS6a2Rb8k0jxzZxSHyREscYKF16ug3gAE2gCYeEQ09ou6ScJS279LSEXmBPuj2nCyyFLWkhp6W728JmIaFdlxoC5dKFpQRfEjuxHceKCbEkX+SbbtZlRvPdP55H1kiWrbF1eUYzn9c5c2ae28xXE+fzPPP7Pc/vMXdHRERKVyzqAkREZH4p6EVESpyCXkSkxCnoRURKnIJeRKTEJaIuYKqmpiZfu3Zt1GWIiCwqe/fuPePuzdMtK7qgX7t2LXv27Im6DBGRRcXMfnalZWq6EREpcQp6EZESp6AXESlxCnoRkRKnoBcRKXEKehGREqegFxEpcQUFvZntMLMjZtZhZg9Ps/wDZvacmT1rZj80s43h/LVmNhTOf9bMPj/Xf8C4CxdH+ew/H+W5zt75+ggRkUVpxgumzCwOPAq8CegEdpvZTnc/lLfal9398+H6dwGfBnaEy15y91vntuzLxWPGZ77zImawJZ2a748TEVk0Cjmi3w50uPsxdx8FHgfuzl/B3fvyJmuBBb+bSX1VBeubajnQeWGhP1pEpKgVEvQtwPG86c5w3iRm9kEzewn4BPDbeYvWmdkzZvYvZvZvpvsAM3vQzPaY2Z6enp5rKH+y9nQj+zt70V2zREQmzFlnrLs/6u6vAj4C/GE4+wSwxt1vAz4MfNnMGqbZ9jF33+bu25qbpx2TpyBt6RQ9/SOc7Bu+7vcQESk1hQR9F9CaN50O513J48A7ANx9xN3Phq/3Ai8BN11fqTNra20EYP9xdciKiIwrJOh3AxvMbJ2ZJYH7gJ35K5jZhrzJtwFHw/nNYWcuZrYe2AAcm4vCp7NxVQOJmLFf7fQiIpfMeNaNu2fN7CHgKSAOfNHdD5rZI8Aed98JPGRmdwAZ4DzwQLj5G4FHzCwD5IAPuPu5+fhDAKoq4ty8ql4dsiIieQoaj97ddwG7psz7WN7rD11huyeBJ2dT4LVqSzfyj/u7yeWcWMwW8qNFRIpSyV0Z255O0T+c5eWzg1GXIiJSFEou6NvSQYfsAV0hKyIClGDQb1heR1VFTB2yIiKhkgv6RDzGlpYU+48r6EVEoASDHoLmm4PdfWTGclGXIiISuRIN+hQj2RwvnuqPuhQRkciVZNC3q0NWROSSkgz6G5bVkKqu0IVTIiKUaNCbGW3plMa8ERGhRIMeguabI6f6GRodi7oUEZFIlWzQt6VTjOWcQyd0VC8i5a1kg75dQxaLiAAlHPQrGqpY0VCpDlkRKXslG/QQXDilUyxFpNyVdNC3p1McOzNI71Am6lJERCJT2kEfttM/p6N6ESljJR30bS1hh6za6UWkjJV00KdqKli7rEYdsiJS1ko66EEdsiIiZRD0KU70DnO6fzjqUkREIlHyQT/eIXtAF06JSJkq+aDftLqBeMzUISsiZaugoDezHWZ2xMw6zOzhaZZ/wMyeM7NnzeyHZrYxb9lHw+2OmNlb5rL4QtQkE2xYXsd+tdOLSJmaMejNLA48CtwJbATuzw/y0JfdfYu73wp8Avh0uO1G4D5gE7AD+Ivw/RZUe7qRA50XcPeF/mgRkcgVckS/Hehw92PuPgo8Dtydv4K79+VN1gLjiXo38Li7j7j7T4GO8P0WVFtrigsXMxw/N7TQHy0iErlCgr4FOJ433RnOm8TMPmhmLxEc0f/2NW77oJntMbM9PT09hdZesPFbC6qdXkTK0Zx1xrr7o+7+KuAjwB9e47aPufs2d9/W3Nw8VyVd8uqV9SQTMV04JSJlqZCg7wJa86bT4bwreRx4x3VuOy8q4jE2rW7Q2PQiUpYKCfrdwAYzW2dmSYLO1Z35K5jZhrzJtwFHw9c7gfvMrNLM1gEbgJ/Mvuxr155u5PnuXsZy6pAVkfIyY9C7exZ4CHgKOAx8xd0PmtkjZnZXuNpDZnbQzJ4FPgw8EG57EPgKcAj4JvBBd4/kJq5t6RQXR8foOD0QxceLiEQmUchK7r4L2DVl3sfyXn/oKtv+CfAn11vgXGnL65B99cr6iKsREVk4JX9l7Lj1TbXUVybUISsiZadsgj4WMza3pDSSpYiUnbIJeggGODt8oo+RbCTdBCIikSivoE+nyIw5h0/0R12KiMiCKaugbxsfsljt9CJSRsoq6FenqmiqS+rCKREpK2UV9GYW3lpQR/QiUj7KKughuHCqo2eAgZFs1KWIiCyIsgv69tZG3OE5nWYpImWi/II+rQ5ZESkvZRf0S2uTpJdU68IpESkbZRf0EBzV6yYkIlIuyjLo29IpOs8PcXZgJOpSRETmXVkGffv4hVNdar4RkdJXlkG/uSWFGew/ruYbESl9ZRn0dZUJbmyuU4esiJSFsgx64NIVsu66taCIlLayDfr21hRnBkbp7h2OuhQRkXlVtkE/fmvBA2qnF5ESV7ZBf8uqeirixn6104tIiSvboK9MxLllVYOGQhCRkle2QQ/BhVPPdfaSy6lDVkRKV0FBb2Y7zOyImXWY2cPTLP+wmR0yswNm9h0zuyFv2ZiZPRs+ds5l8bPVlm6kfyTLsTODUZciIjJvZgx6M4sDjwJ3AhuB+81s45TVngG2uXsb8ATwibxlQ+5+a/i4a47qnhMayVJEykEhR/TbgQ53P+buo8DjwN35K7j799z9Yjj5YyA9t2XOjxuX11GTjOvCKREpaYUEfQtwPG+6M5x3Jb8BfCNvusrM9pjZj83sHdNtYGYPhuvs6enpKaCkuRGPGZtbUhrJUkRK2px2xprZe4FtwCfzZt/g7tuA9wCfMbNXTd3O3R9z923uvq25uXkuS5pRezrFwe4+MmO5Bf1cEZGFUkjQdwGtedPpcN4kZnYH8AfAXe5+afxfd+8Kn48B3wdum0W9c64t3choNseRk/1RlyIiMi8KCfrdwAYzW2dmSeA+YNLZM2Z2G/AFgpA/nTd/iZlVhq+bgDcAh+aq+Lkw3iGr5hsRKVUzBr27Z4GHgKeAw8BX3P2gmT1iZuNn0XwSqAO+OuU0yluAPWa2H/ge8KfuXlRB37q0miU1FRw4rg5ZESlNiUJWcvddwK4p8z6W9/qOK2z3I2DLbAqcb2bGFt1aUERKWFlfGTvu1nSKo6cHGBodi7oUEZE5p6An6JAdyzkHu9V8IyKlR0EPtLWmAHhWQxaLSAlS0APL66tYlarSFbIiUpIU9KG2dEpj3ohISVLQh9rSjbx89iK9FzNRlyIiMqcU9KFbW8ORLLt0VC8ipUVBH9rcEnTIqp1eREqNgj6Uqq5gfVOtzrwRkZKjoM+jDlkRKUUK+jxt6UZO9Y1wqm846lJEROaMgj5Pe3jh1H4134hICVHQ59m0OkU8ZuqQFZGSoqDPU1UR59Ur6jWSpYiUFAX9FO2tKQ509uLuUZciIjInFPRTtKUb6R3K8LOzF6MuRURkTijop2hLhx2yar4RkRKhoJ/iphX1VCZi6pAVkZKhoJ+iIh5jc4sunBKR0qGgn0ZbOsXzXX1kx3JRlyIiMmsK+mm0pxsZyoxx9PRA1KWIiMyagn4a4x2yar4RkVJQUNCb2Q4zO2JmHWb28DTLP2xmh8zsgJl9x8xuyFv2gJkdDR8PzGXx82XtslrqqxLsV4esiJSAGYPezOLAo8CdwEbgfjPbOGW1Z4Bt7t4GPAF8Itx2KfBx4LXAduDjZrZk7sqfH7GYaSRLESkZhRzRbwc63P2Yu48CjwN356/g7t9z9/ErjH4MpMPXbwG+7e7n3P088G1gx9yUPr/a0428cKKf4cxY1KWIiMxKIUHfAhzPm+4M513JbwDfuJZtzexBM9tjZnt6enoKKGn+taUbyeacwyf6oi5FRGRW5rQz1szeC2wDPnkt27n7Y+6+zd23NTc3z2VJ101DFotIqSgk6LuA1rzpdDhvEjO7A/gD4C53H7mWbYvRyoYqmusrdYWsiCx6hQT9bmCDma0zsyRwH7AzfwUzuw34AkHIn85b9BTwZjNbEnbCvjmcV/TMjPZ0SmPeiMiiN2PQu3sWeIggoA8DX3H3g2b2iJndFa72SaAO+KqZPWtmO8NtzwF/TLCz2A08Es5bFNrSjRw7M0j/cCbqUkRErluikJXcfRewa8q8j+W9vuMq234R+OL1Fhil9tZG3OG5rl5+7lVNUZcjInJddGXsVbS1jF8hq3Z6EVm8FPRXsaQ2yZqlNTrzRkQWNQX9DIIrZHVELyKLl4J+Bu3pRrouDHFmYGTmlUVEipCCfgYayVJEFjsF/Qw2t6SIGew/ruYbEVmcFPQzqK1MsGF5vY7oRWTRUtAXoC2dYn9nL+4edSkiItdMQV+AttZGzg2O0nl+KOpSRESumYK+AO1pXTglIouXgr4AN69sIBmPqZ1eRBYlBX0BkokYt6xu0EiWIrIoKegL1J5O8XxXH2M5dciKyOKioC9QW7qRgZEsx3oGoi5FROSaKOgLNN4hu18dsiKyyCjoC7S+uY7aZFwdsiKy6CjoCxSPGZtbUjqiF5FFR0F/DW5tbeRwdx+j2VzUpYiIFExBfw3a0o2MjuU4crI/6lJERAqmoL8G40MWP6t2ehFZRBT01yC9pJqltUkO6NaCIrKIFBT0ZrbDzI6YWYeZPTzN8jea2T4zy5rZvVOWjZnZs+Fj51wVHgUz060FRWTRmTHozSwOPArcCWwE7jezjVNWewV4H/Dlad5iyN1vDR93zbLeyLWlGzl6up+Lo9moSxERKUghR/TbgQ53P+buo8DjwN35K7j7y+5+ACj501FubU2Rc3i+qy/qUkREClJI0LcAx/OmO8N5haoysz1m9mMze8c1VVeE2tKNgO4hKyKLR2IBPuMGd+8ys/XAd83sOXd/KX8FM3sQeBBgzZo1C1DS9Wuqq6SlsZpn1SErIotEIUf0XUBr3nQ6nFcQd+8Kn48B3wdum2adx9x9m7tva25uLvStI6MOWRFZTAoJ+t3ABjNbZ2ZJ4D6goLNnzGyJmVWGr5uANwCHrrfYYtGWbuSVcxc5PzgadSkiIjOaMejdPQs8BDwFHAa+4u4HzewRM7sLwMxeY2adwLuAL5jZwXDzW4A9ZrYf+B7wp+6+6IP+0q0Fu3RULyLFr6A2enffBeyaMu9jea93EzTpTN3uR8CWWdZYdDanU5jBgeMX+IWbir+pSUTKm66MvQ4NVRWsb6rVSJYisigo6K9Te7qR/Z0XcNetBUWkuCnor1NbOkVP/wgn+4ajLkVE5KoU9NeprTW4cGr/cTXfiEhxU9Bfp42rGkjETFfIikjRU9Bfp6qKODevqteFUyJS9BT0s9CWbuRA5wVyOXXIikjxUtDPQns6Rd9wlpfPDkZdiojIFSnoZ2FiJEs134hI8VLQz8KG5XVUVcTYrw5ZESliCvpZSMRjbF6tkSxFpLgp6GepvbWRg929ZMdK/uZaIrJIKehnqS2dYjiT48VTA1GXIiIyLQX9LLXr1oIiUuQU9LN0w7IaUtUV6pAVkaKloJ8lM6MtndKYNyJStBT0c6A93ciRU/0MZ8aiLkVE5DKlFfR7/gYunlvwj21LpxjLOQe7+xb8s0VEZlI6QX/mKPzT78DntsG+v4Xcwp3u2N6qDlkRKV6lE/RNG+A3/wWW3Qg7H4K/2QEnDizIR69oqGJFQ6UunBKRolQ6QQ+wcgv82jfh7kfhbAc89gvwjY/A8PwHcFu6kf3HdUQvIsWntIIeIBaD294LD+2B238Nnv4CfO41cOArMI/3d21Ppzh2ZpDeocy8fYaIyPUoKOjNbIeZHTGzDjN7eJrlbzSzfWaWNbN7pyx7wMyOho8H5qrwGdUshbd/Gt7/XWhoga+9H/7HL8PpF+bl48bb6Z/vUvONiBSXGYPezOLAo8CdwEbgfjPbOGW1V4D3AV+esu1S4OPAa4HtwMfNbMnsy74GLVvh3/0zvP3P4ORz8Pk3wLf+CEbmdsiCtpbwHrLqkBWRIlPIEf12oMPdj7n7KPA4cHf+Cu7+srsfAKae6vIW4Nvufs7dzwPfBnbMQd3XJhaHbb8Ov7UX2u+DH/23oDnn4N/PWXNOqqaCtctqOKALp0SkyBQS9C3A8bzpznBeIQra1sweNLM9Zranp6enwLe+DrVNQUftb3wbapfBV98Hf/tOONMxJ28/fmtBEZFiUhSdse7+mLtvc/dtzc3N8/+Brdvh/d+HOz8BXXvhL18P3/ljGL04q7dtS6fo7h3mdP/w3NQpIjIHCgn6LqA1bzodzivEbLadX/EEvPY3g7NzNr0TfvApePS18MKu637LSxdOqflGRIpIIUG/G9hgZuvMLAncB+ws8P2fAt5sZkvCTtg3h/OKR/0K+JXH4H3/BMlaePx++PK74dxPr/mtNq1uIB4zNd+ISFGZMejdPQs8RBDQh4GvuPtBM3vEzO4CMLPXmFkn8C7gC2Z2MNz2HPDHBDuL3cAj4bzis/bn4QM/gDf/Z3j5h/AXr4Pv/xfIFN4MU5NMsGF5Hft1hayIFBHzebyI6Hps27bN9+zZE20Rfd3w1O8HZ+UsXQ93fhI23FHQph954gDfOnSSfX/0JsxsngsVEQmY2V533zbdsqLojC06DavhXf8dfvUfwGLwpXvgf78XLhyfcdO21hTnL2b46t5ODVssIkVBR/QzyY7Aj/4c/u+nwAze+Lvw+ocgkZx29VN9w7zr8//KK+cu0lCV4O3tq7lna5qtaxp1hC8i8+ZqR/QK+kJdeAW++VF44evQdBO89VOw/hemXTWXc/712Fme3NvJN54/yVBmjPVNtdxze5p33tbC6sbqBS5eREqdgn4uvfgt+MbvwvmXYfM98OY/gYZVV1x9YCTLrudO8MTeTn7y03OYwRte1cS9t6d5y6aVVCfjC1e7iJQsBf1cywzBDz8DP/wziCfhFz8K238zODf/Kl45e5En93XytWc6OX5uiLrKBG/dspJ7b2/lNWuXqGlHRK6bgn6+nDsGu34POr4NyzfB2/4r3PD6GTfL5ZzdL5/jib2d7HruBIOjY6xZWsM9W9P8ytYWWpfWLEDxIlJKFPTzyR1e+Cf45sPQexza3wNvegTqChvK4eJolm8+f5In93Xyo5fO4g6vW7+Ue7ameeuWVdRWXv1XgogIKOgXxuhgcGbOj/4cElXBBVit24PH6q2QnPkovevCEH+/r5Mn9nby8tmL1CTj7Ni8kntvT/O6dcuIxdS0IyLTU9AvpDNH4f99Fl75MZw9GsyLJWDFZmh97UT4p1qD0zWn4e7se+U8T+zt4uv7u+kfydLSWM09W1v4la1p1jbVLuAfJCKLgYI+KhfPQeduOP4TOP40dO2DzGCwrG7lROi3vhZWtUOi8rK3GM6M8a1Dp3hibyc/PNpDzmHbDUu49/Y0b21bRUNVxQL/USJSjBT0xWIsC6cPhsH/E+j8SXCaJgRn76y6dSL809svO23zZO8wf/9MF0/u66Tj9ACViRg7Nq/knq1p3nBjE3E17YiULQV9Mes/FR71Px08d+2DsZFgWWoNtL4mOOJPvwZWboF4Be7Ogc5entjbyc793fQOZVjZUMU7t7Zwz9Y0Ny6vi/ZvEpEFp6BfTLKjwb1tjz8dHPEf/wn0hUP4J6qDe+COH/G3bmekcgnfOXyaJ/d28v0XexjLObe2NnLP7Wl+uW0VjTXTD9VQdnK5oE9E1ypIiVLQL3a9nWFTT3jkf+IA5DLBsqXrLx3xn112K//Q2cBX953ghZP9ALQ0VrNhRR0bltexYXk9N66o48bldYu/bd8dRvpg8AwM9oSPM1Omeyamh85Bsg6Wb4QVm2DFxqCDfPlGqGqI+q8RmTUFfanJDEH3sxNH/Md/AoOng2XJejx9Oz2pdnYPp/lpv/Fyb45j57P0jSUYJsmIJ2mor6N1+VLWLl/CjSvqgx3BinqW1kb4CyAzNHNgX8xbNjY6/ftUpoL7A9c2T34eOg+nDgaPkb6J9RvXBKG/YlO4I9gc7EBnuNJZpJgo6Eude9CpO37Ef/zpIMw8N+OmOTeGSTJMBSMkyVgST1QRS1ZTkayhsrqGmpo6ktW1WEVVcI1AogoqqvOeK4NmpYqq4DlROXl5bmxyWE8N7PFlowPTF5monhLa46+nhnkz1Cyb9uyly76v3s4w9J+fCP+zHeDh0NKJKmi+eWIHMP4LoLbp2v7biCwQBX05GhkIzuPPDEF2OLhTVnZo4jk7ApkhPDPEwOAAff0DDAz0M3RxkJHhQbIjF4nnRqlilEpGqYllqI1lqbYMSR8hkRvBuM5/O7EE1EwT0pPCO29ZcoGuG8gMw5kjE8F/6nk4dWji1xJA3Yow+DcFw16s2ATNr5555yIyz64W9PptWqoq62D1bTOuZkB9+Mjn7vQMjNBxaoD9pwc4erqfo6cGeKlngDODo4CTJEtjMsfNTQluWlrBq5bEWZeKc0MqxvJqiI8NBzuaWHxyeFc1FmenaEVVcD3DqvbJ8wdO54X/weAU2acfmzg7yuLB0NX5R/4rNkFDS3H+nVJ2dEQv1+zc4CgdU8L/6KkBTvZN3F83mYixvqmWDSvqWbeshhWpKlY2VLGioYqVqSqW1iQX95AOY1k491Je08+h4Ln3lYl1qlKXt/0vvyXYCYvMMTXdyILoG87QcXrg0uPoqX6Onh6g68IQU/+ZVcSN5fVVrGioZGWqiuX1wQ5gfGcwPr8much+dA5dgNOHgx3A6UMTvwIu9T8YLLsx+LXVsjUYB2nlloLGQhK5GgW9RCozluPMwAgne4c51TccPPePcKp3mJN9weN03wgDI9nLtq2vSuSFfxUrU5WsbKhieUOwU1iZqqKprrK4rwrO5YIj/VOHgh1A97PQvQ/6TwTLLR4c6a++bWIHsHzTFW9XKTIdBb0sCgMj2Us7g1PhDuBU7zCn+kaC133DnO4fYSw3+d9szKC5vnJS09ClHUO4c1jeUEV9ZaK4bu7SdwK6nwlCv/uZ4KrooXPBsngyaOpp2RruALYGnb4x3ZFMpjfroDezHcBngTjwV+7+p1OWVwL/E7gdOAu8291fNrO1wGHgSLjqj939A1f7LAW9XM1Yzjk7OMKp3pG8XwPBr4TxncGpvhF6hzKXbdtUl2Tj6hSbVzewaXWKzS0NrFlaUzzh7w4XfjYR+t3PBEf/o8HFb1TUBB3Fq7dOHPkvXa8OXwFmGfRmFgdeBN4EdAK7gfvd/VDeOv8eaHP3D5jZfcA73f3dYdB/3d03F1qsgl7mwtDo2MSvgnBH0HF6gIPdfbx4qp9s+KugvirBxlUNbG5JsWl18Ly+qZZEPBbxXxDK5YLz+8eP/Lv2wckDwSmzEHT4rrp1or1/9W2QSiv8y9BsT6/cDnS4+7HwzR4H7gYO5a1zN/CfwtdPAJ+zojlMknJUnYyztql22rH7R7JjvHhygIPdvTzf3cvB7j6+9PTPGM4EF5hVVcS4eWUDm1sa2Lw6xabVKW5aWUdlIoJmk1gMmm8KHu3vDuaNZaHncN5R/77ghje5sI+jtnmiuWe86adu+cLXLkWjkKBvAY7nTXcCr73SOu6eNbNeYFm4bJ2ZPQP0AX/o7j+Y+gFm9iDwIMCaNWuu6Q8QuVaViThb0im2pFOX5mXHchw7MxiEf1cfz3f18n+e6ebvfhycLpmIGRtW1IfNPsGR/y2rGqK51WM8EZyps3IL3P5AMC8zHJzdk9/e3/HPE1dHN6Sh5baJHcCqdqheoiP/MjHf/0pPAGvc/ayZ3Q78g5ltcve+/JXc/THgMQiabua5JpHLJOIxblpRz00r6nlneJ1ZLuccP3+Rg91B8D/f3cd3XzjNV/d2AkFGrmuqDY/6J5p/IhkxtKIK0rcHj3EjA0EzT/6R/+F/zNvIgnb/iurgOZn3uqI673XNNPOqgyuWp8679Fw7MQxGrEiawcpYIUHfBbTmTafDedOt02lmCSAFnPWgA2AEwN33mtlLwE2AGuGl6MVixg3LarlhWS1v3RLcBMbdOdU3MnHk393L3p+dZ+f+7kvbtTRWs7llosN38+oUyxuqFv4PqKyDG34ueIwbOh908J58Dkb6IXMxfAzlPQ8F6/V2TZ6XGSxo/KTLJKqvvDNJVAe/UGIVEK8IhseIVwTTscR1LBufl79sfPoqy+JJiFeW7E6pkKDfDWwws3UEgX4f8J4p6+wEHgD+FbgX+K67u5k1A+fcfczM1gMbgGNzVr3IAjOz4MKuVBW/dMuKS/PPDY5yqDsI/ue7ejnU3cdTB09dWt5UVxmGfwPpJTUsq02yrK4yfE5St1CnflYvgVf9YvC4Vu4wlgkC/1L4hzuC0cHLdxaXdiJT54XrD/dB5lTQt5DLBH0PuUzwGblMMBje+Ovr2cFcj3gyHLivcprn6ivMn/JccbX1rvKe8Yp5a0qbMejDNveHgKcITq/8orsfNLNHgD3uvhP4a+BvzawDOEewMwB4I/CImWWAHPABdz83H3+ISJSW1ib5+Q1N/PyGidEt+4czHD7Rf+no/2B3Lz84euay6wAgGDJiPPSX1U7sAJbVVbK0NklTOD94XUl1MoKOYbPgIq5EMthhLKRc7so7gbFMsLOYcVl28nr5y8ZGg0d2OBjw79JAgHnT2REY7oXs6Snzw8eVhs0umMGa18Gvf3NOvrJJ76wLpkQWzmg2x9nBEc4OjHJmYIRzg6PB68ERzg2McnZwlLMDI5wdDJaPnwk0VU0yztLwV0FTuFNYWlsZ7BDC18vCncLS2iTJRGk2SRSVXC4Y6G7qzmH8OTM0zfwp69Qth+3vv66P1+iVIkUimYixKlXNqlR1QetfHM1yNn8HMGVncHZwlJN9wxzs7uPc4CijY9PvGOqrEpdCf/zXQnVFgqqKGJWJOFUVMaoqJp4rE3EqK2JUTVoWpzKRt14ivrgHpptrsRjEwv6IIqOgFyliNckENUsTtC6dedAzd6d/JNgxnBsc4cxA8Gshf6dwdmCEV85d5JnjFxgeHWM4O0Zm7Pp/1SfjMSqn21lM2ttq1KIAAASdSURBVFGEryviU+bHqEzEiMdjJGJG3IxYzEjE8p4teI5f6WETry/bLj55+XTblcvlPgp6kRJhZjRUVdBQVcG6aS4Uu5LsWI6RbI7hzBjD2RwjmTGGMzmGs2MMZ8YYyQTLLq0TrjccrjeSDZ8zY+E2E8suXMxcvt4sdy5zKWaQiMVIJmI0VCVoqA6+v4bqRPhcMTF/yrJUOF1XlSjuQfVQ0IuUvUQ8RiIeW9CLv8Z3LiPZHNlcjlyOS89j7ozlcozlzcvmcuTcyY55uHzyI+dONnf5/OnWzeac3JRlw5kc/cMZ+oYz9A1lOdE7zJFT/fQNZekbzlw2zPZU9ZX5O4MZdhjjO4nqYLoumZj3JjAFvYgsuImdS9SVzCyXcwZGs/QNZS4Ff99Qhr7hYF7v0MQOYnxZ5/kh+ob66BvO0D98+fDb+cwmdhS3tjbyufdsnfO/QUEvInIVsdhEkxjXcVbpWM4ZGA52AtPtFMZ3GH1DGVam5ufCOgW9iMg8iseMVE0FqZqKSUMMLCSdXCsiUuIU9CIiJU5BLyJS4hT0IiIlTkEvIlLiFPQiIiVOQS8iUuIU9CIiJa7oxqM3sx7gZ7N4iybgzByVs9jpu5hM38dk+j4mlMJ3cYO7N0+3oOiCfrbMbM+VBt8vN/ouJtP3MZm+jwml/l2o6UZEpMQp6EVESlwpBv1jURdQRPRdTKbvYzJ9HxNK+rsouTZ6ERGZrBSP6EVEJI+CXkSkxJVM0JvZDjM7YmYdZvZw1PVEycxazex7ZnbIzA6a2YeirilqZhY3s2fM7OtR1xI1M2s0syfM7AUzO2xmr4+6piiZ2X8M/z953sz+l5nNz22eIlQSQW9mceBR4E5gI3C/mW2MtqpIZYHfcfeNwOuAD5b59wHwIeBw1EUUic8C33T3m4F2yvh7MbMW4LeBbe6+GYgD90Vb1dwriaAHtgMd7n7M3UeBx4G7I64pMu5+wt33ha/7Cf5Hbom2quiYWRp4G/BXUdcSNTNLAW8E/hrA3Ufd/UK0VUUuAVSbWQKoAbojrmfOlUrQtwDH86Y7KeNgy2dma4HbgKejrSRSnwF+D8hFXUgRWAf0AH8TNmX9lZnVRl1UVNy9C/gU8ApwAuh1929FW9XcK5Wgl2mYWR3wJPAf3L0v6nqiYGZvB067+96oaykSCWAr8JfufhswCJRtn5aZLSH49b8OWA3Umtl7o61q7pVK0HfBpBusp8N5ZcvMKghC/kvu/rWo64nQG4C7zOxlgia9f2tmfxdtSZHqBDrdffwX3hMEwV+u7gB+6u497p4Bvgb8XMQ1zblSCfrdwAYzW2dmSYLOlJ0R1xQZMzOCNtjD7v7pqOuJkrt/1N3T7r6W4N/Fd9295I7YCuXuJ4HjZvbqcNYvAYciLClqrwCvM7Oa8P+bX6IEO6cTURcwF9w9a2YPAU8R9Jp/0d0PRlxWlN4A/CrwnJk9G877fXffFWFNUjx+C/hSeFB0DPi1iOuJjLs/bWZPAPsIzlZ7hhIcDkFDIIiIlLhSaboREZErUNCLiJQ4Bb2ISIlT0IuIlDgFvYhIiVPQi4iUOAW9iEiJ+/+W2p6C3EyhtAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGJo4p0TsOTS"
      },
      "source": [
        "6 epochs seem to be enough to reach a low value loss and a high accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfANFclTbCid"
      },
      "source": [
        "Need to repeat optimisation experiments various times for accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re8ma3ohbByj"
      },
      "source": [
        "def buildmultiple(filters, kernel_size, no_epochs, batch_size):\r\n",
        "  #initiate accuracy list.\r\n",
        "  repeat_accuracy = []*10\r\n",
        "  #for each repeat\r\n",
        "  for i in range(10):\r\n",
        "    #build the model\r\n",
        "    model = buildmodel(filters, kernel_size, no_epochs, batch_size)\r\n",
        "    #measure and record the accuracy\r\n",
        "    loss, accuracy = model.evaluate(test_data, test_classes, \r\n",
        "                                          batch_size=batch_size)\r\n",
        "    repeat_accuracy.append(accuracy)\r\n",
        "  return repeat_accuracy"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe9h3vOBp4jg"
      },
      "source": [
        "Number of filters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GLV1EldTq2Sd",
        "outputId": "649501fc-f614-43a8-b4fd-e89151614b98"
      },
      "source": [
        "#list of number of filters to be tested.\r\n",
        "filters = [8, 16, 32, 64, 128, 256]\r\n",
        "\r\n",
        "#initiate filters vector list\r\n",
        "filters_accuracy = []*6\r\n",
        "\r\n",
        "#repeat following steps for each number of filters.\r\n",
        "for i in range(len(filters)):\r\n",
        "  accuracy = buildmultiple(filters[i], 3, 6, 100)\r\n",
        "  filters_accuracy.append(accuracy)  \r\n",
        "\r\n",
        "#boxplot of the accuracy scores for each corresponding number of filters \r\n",
        "#invesitgated. \r\n",
        "plt.boxplot(filters_accuracy, labels = filters)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.6737 - accuracy: 0.5759 - val_loss: 0.5987 - val_accuracy: 0.5600\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.4557 - accuracy: 0.8536 - val_loss: 0.2189 - val_accuracy: 0.9570\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 14ms/step - loss: 0.1540 - accuracy: 0.9524 - val_loss: 0.1116 - val_accuracy: 0.9650\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0941 - accuracy: 0.9688 - val_loss: 0.0911 - val_accuracy: 0.9760\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0903 - accuracy: 0.9685 - val_loss: 0.0816 - val_accuracy: 0.9820\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0763 - accuracy: 0.9740 - val_loss: 0.0845 - val_accuracy: 0.9830\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0845 - accuracy: 0.9830\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 1s 24ms/step - loss: 0.6374 - accuracy: 0.6140 - val_loss: 0.4752 - val_accuracy: 0.9490\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.3060 - accuracy: 0.9349 - val_loss: 0.1671 - val_accuracy: 0.9620\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 14ms/step - loss: 0.1248 - accuracy: 0.9597 - val_loss: 0.1178 - val_accuracy: 0.9630\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 14ms/step - loss: 0.1051 - accuracy: 0.9694 - val_loss: 0.0858 - val_accuracy: 0.9810\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0743 - accuracy: 0.9763 - val_loss: 0.0714 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0797 - accuracy: 0.9777 - val_loss: 0.0738 - val_accuracy: 0.9850\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0738 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.6433 - accuracy: 0.6510 - val_loss: 0.4663 - val_accuracy: 0.9460\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.3182 - accuracy: 0.9159 - val_loss: 0.1875 - val_accuracy: 0.9570\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.1437 - accuracy: 0.9453 - val_loss: 0.1252 - val_accuracy: 0.9660\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.1196 - accuracy: 0.9551 - val_loss: 0.1061 - val_accuracy: 0.9760\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0933 - accuracy: 0.9717 - val_loss: 0.0881 - val_accuracy: 0.9770\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0959 - accuracy: 0.9652 - val_loss: 0.0796 - val_accuracy: 0.9780\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0796 - accuracy: 0.9780\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 1s 26ms/step - loss: 0.6509 - accuracy: 0.5989 - val_loss: 0.5249 - val_accuracy: 0.8950\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.3626 - accuracy: 0.9229 - val_loss: 0.1862 - val_accuracy: 0.9580\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.1471 - accuracy: 0.9478 - val_loss: 0.1104 - val_accuracy: 0.9700\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.1006 - accuracy: 0.9654 - val_loss: 0.0896 - val_accuracy: 0.9750\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.0864 - accuracy: 0.9727 - val_loss: 0.0803 - val_accuracy: 0.9810\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.0767 - accuracy: 0.9763 - val_loss: 0.0790 - val_accuracy: 0.9830\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9830\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 1s 24ms/step - loss: 0.6400 - accuracy: 0.6071 - val_loss: 0.4194 - val_accuracy: 0.9470\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.2954 - accuracy: 0.9188 - val_loss: 0.1922 - val_accuracy: 0.9590\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.1931 - accuracy: 0.9367 - val_loss: 0.1555 - val_accuracy: 0.9600\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.1412 - accuracy: 0.9465 - val_loss: 0.0994 - val_accuracy: 0.9690\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.0999 - accuracy: 0.9635 - val_loss: 0.0792 - val_accuracy: 0.9800\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0616 - accuracy: 0.9809 - val_loss: 0.0611 - val_accuracy: 0.9860\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0611 - accuracy: 0.9860\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 22ms/step - loss: 0.6533 - accuracy: 0.6155 - val_loss: 0.5162 - val_accuracy: 0.9220\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.3698 - accuracy: 0.9006 - val_loss: 0.2319 - val_accuracy: 0.9490\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.1886 - accuracy: 0.9377 - val_loss: 0.1430 - val_accuracy: 0.9620\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.1291 - accuracy: 0.9570 - val_loss: 0.1124 - val_accuracy: 0.9700\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.1079 - accuracy: 0.9652 - val_loss: 0.0957 - val_accuracy: 0.9750\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.0874 - accuracy: 0.9699 - val_loss: 0.0818 - val_accuracy: 0.9820\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.9820\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 1s 22ms/step - loss: 0.6090 - accuracy: 0.6855 - val_loss: 0.4315 - val_accuracy: 0.9570\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.3076 - accuracy: 0.9053 - val_loss: 0.1959 - val_accuracy: 0.9550\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.1606 - accuracy: 0.9462 - val_loss: 0.1222 - val_accuracy: 0.9670\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.1139 - accuracy: 0.9585 - val_loss: 0.0967 - val_accuracy: 0.9760\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 0.0903 - accuracy: 0.9689 - val_loss: 0.0847 - val_accuracy: 0.9790\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0999 - accuracy: 0.9661 - val_loss: 0.0776 - val_accuracy: 0.9820\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0776 - accuracy: 0.9820\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 1s 22ms/step - loss: 0.6316 - accuracy: 0.6440 - val_loss: 0.3820 - val_accuracy: 0.9530\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.2253 - accuracy: 0.9467 - val_loss: 0.1331 - val_accuracy: 0.9650\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.0978 - accuracy: 0.9697 - val_loss: 0.0984 - val_accuracy: 0.9800\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0825 - accuracy: 0.9698 - val_loss: 0.0741 - val_accuracy: 0.9790\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0666 - accuracy: 0.9785 - val_loss: 0.0660 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0624 - accuracy: 0.9799 - val_loss: 0.0605 - val_accuracy: 0.9850\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 1s 23ms/step - loss: 0.6435 - accuracy: 0.6361 - val_loss: 0.4514 - val_accuracy: 0.9510\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.3018 - accuracy: 0.9238 - val_loss: 0.1741 - val_accuracy: 0.9600\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.1425 - accuracy: 0.9487 - val_loss: 0.1245 - val_accuracy: 0.9650\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.1160 - accuracy: 0.9580 - val_loss: 0.0937 - val_accuracy: 0.9720\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0821 - accuracy: 0.9752 - val_loss: 0.0786 - val_accuracy: 0.9810\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.0722 - accuracy: 0.9758 - val_loss: 0.0665 - val_accuracy: 0.9830\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9830\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 1s 22ms/step - loss: 0.6434 - accuracy: 0.6175 - val_loss: 0.4394 - val_accuracy: 0.9520\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.3187 - accuracy: 0.9014 - val_loss: 0.1968 - val_accuracy: 0.9560\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.1688 - accuracy: 0.9433 - val_loss: 0.1485 - val_accuracy: 0.9630\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.1296 - accuracy: 0.9553 - val_loss: 0.1249 - val_accuracy: 0.9730\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 15ms/step - loss: 0.1088 - accuracy: 0.9639 - val_loss: 0.0927 - val_accuracy: 0.9780\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 16ms/step - loss: 0.0995 - accuracy: 0.9647 - val_loss: 0.0743 - val_accuracy: 0.9810\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0743 - accuracy: 0.9810\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 27ms/step - loss: 0.6472 - accuracy: 0.5988 - val_loss: 0.3651 - val_accuracy: 0.9600\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.2014 - accuracy: 0.9530 - val_loss: 0.1072 - val_accuracy: 0.9670\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0870 - accuracy: 0.9689 - val_loss: 0.0849 - val_accuracy: 0.9750\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 25ms/step - loss: 0.0693 - accuracy: 0.9787 - val_loss: 0.0680 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0689 - accuracy: 0.9768 - val_loss: 0.0925 - val_accuracy: 0.9700\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.0686 - accuracy: 0.9762 - val_loss: 0.0632 - val_accuracy: 0.9850\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0632 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 28ms/step - loss: 0.6166 - accuracy: 0.7032 - val_loss: 0.3140 - val_accuracy: 0.9540\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.2093 - accuracy: 0.9319 - val_loss: 0.1256 - val_accuracy: 0.9630\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.1255 - accuracy: 0.9527 - val_loss: 0.0983 - val_accuracy: 0.9740\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0963 - accuracy: 0.9684 - val_loss: 0.0833 - val_accuracy: 0.9770\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0655 - accuracy: 0.9784 - val_loss: 0.0655 - val_accuracy: 0.9810\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0705 - accuracy: 0.9737 - val_loss: 0.0596 - val_accuracy: 0.9850\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0596 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 31ms/step - loss: 0.5719 - accuracy: 0.7143 - val_loss: 0.2801 - val_accuracy: 0.9520\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.1844 - accuracy: 0.9472 - val_loss: 0.1179 - val_accuracy: 0.9640\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.1200 - accuracy: 0.9595 - val_loss: 0.0872 - val_accuracy: 0.9790\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.0751 - accuracy: 0.9745 - val_loss: 0.0736 - val_accuracy: 0.9820\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.0808 - accuracy: 0.9720 - val_loss: 0.0655 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.0610 - accuracy: 0.9793 - val_loss: 0.0617 - val_accuracy: 0.9860\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0617 - accuracy: 0.9860\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 27ms/step - loss: 0.6064 - accuracy: 0.6719 - val_loss: 0.2852 - val_accuracy: 0.9530\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.1743 - accuracy: 0.9496 - val_loss: 0.1213 - val_accuracy: 0.9710\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.1146 - accuracy: 0.9597 - val_loss: 0.0854 - val_accuracy: 0.9760\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.0861 - accuracy: 0.9718 - val_loss: 0.0715 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0695 - accuracy: 0.9768 - val_loss: 0.0757 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0668 - accuracy: 0.9803 - val_loss: 0.0688 - val_accuracy: 0.9840\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0688 - accuracy: 0.9840\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 32ms/step - loss: 0.5832 - accuracy: 0.7097 - val_loss: 0.2733 - val_accuracy: 0.9500\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.1781 - accuracy: 0.9449 - val_loss: 0.1236 - val_accuracy: 0.9640\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.1091 - accuracy: 0.9628 - val_loss: 0.0913 - val_accuracy: 0.9760\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0854 - accuracy: 0.9680 - val_loss: 0.0795 - val_accuracy: 0.9820\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.0691 - accuracy: 0.9776 - val_loss: 0.0703 - val_accuracy: 0.9800\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.0670 - accuracy: 0.9796 - val_loss: 0.0721 - val_accuracy: 0.9800\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0721 - accuracy: 0.9800\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 27ms/step - loss: 0.5674 - accuracy: 0.7134 - val_loss: 0.2410 - val_accuracy: 0.9570\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.1651 - accuracy: 0.9502 - val_loss: 0.1185 - val_accuracy: 0.9630\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0859 - accuracy: 0.9710 - val_loss: 0.0838 - val_accuracy: 0.9810\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0785 - accuracy: 0.9759 - val_loss: 0.0704 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0737 - accuracy: 0.9757 - val_loss: 0.0645 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 23ms/step - loss: 0.0612 - accuracy: 0.9817 - val_loss: 0.0626 - val_accuracy: 0.9850\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0626 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 32ms/step - loss: 0.5868 - accuracy: 0.6811 - val_loss: 0.2885 - val_accuracy: 0.9530\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.1785 - accuracy: 0.9463 - val_loss: 0.1097 - val_accuracy: 0.9660\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0939 - accuracy: 0.9679 - val_loss: 0.1044 - val_accuracy: 0.9660\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0772 - accuracy: 0.9719 - val_loss: 0.0765 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0685 - accuracy: 0.9757 - val_loss: 0.0707 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.0597 - accuracy: 0.9835 - val_loss: 0.0598 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 28ms/step - loss: 0.6438 - accuracy: 0.6558 - val_loss: 0.3932 - val_accuracy: 0.9530\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.2146 - accuracy: 0.9508 - val_loss: 0.1126 - val_accuracy: 0.9660\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.1058 - accuracy: 0.9619 - val_loss: 0.0937 - val_accuracy: 0.9730\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.0827 - accuracy: 0.9691 - val_loss: 0.0746 - val_accuracy: 0.9820\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0637 - accuracy: 0.9790 - val_loss: 0.0656 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 25ms/step - loss: 0.0698 - accuracy: 0.9773 - val_loss: 0.0618 - val_accuracy: 0.9850\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0618 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 28ms/step - loss: 0.5844 - accuracy: 0.6888 - val_loss: 0.2844 - val_accuracy: 0.9530\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.1794 - accuracy: 0.9472 - val_loss: 0.1221 - val_accuracy: 0.9650\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0965 - accuracy: 0.9662 - val_loss: 0.1001 - val_accuracy: 0.9680\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.0735 - accuracy: 0.9760 - val_loss: 0.0717 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0680 - accuracy: 0.9789 - val_loss: 0.0649 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0556 - accuracy: 0.9814 - val_loss: 0.0665 - val_accuracy: 0.9850\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 28ms/step - loss: 0.6327 - accuracy: 0.6770 - val_loss: 0.4016 - val_accuracy: 0.9250\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.2256 - accuracy: 0.9370 - val_loss: 0.1291 - val_accuracy: 0.9620\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 26ms/step - loss: 0.1220 - accuracy: 0.9607 - val_loss: 0.0933 - val_accuracy: 0.9740\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0832 - accuracy: 0.9723 - val_loss: 0.0793 - val_accuracy: 0.9810\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.0765 - accuracy: 0.9751 - val_loss: 0.0730 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.0834 - accuracy: 0.9727 - val_loss: 0.0844 - val_accuracy: 0.9810\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0844 - accuracy: 0.9810\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 40ms/step - loss: 0.5150 - accuracy: 0.7697 - val_loss: 0.1535 - val_accuracy: 0.9610\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 32ms/step - loss: 0.1160 - accuracy: 0.9575 - val_loss: 0.0889 - val_accuracy: 0.9740\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0869 - accuracy: 0.9699 - val_loss: 0.0770 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 32ms/step - loss: 0.0603 - accuracy: 0.9804 - val_loss: 0.0808 - val_accuracy: 0.9790\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0652 - accuracy: 0.9782 - val_loss: 0.0633 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0489 - accuracy: 0.9825 - val_loss: 0.0549 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0549 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 39ms/step - loss: 0.6023 - accuracy: 0.6744 - val_loss: 0.2365 - val_accuracy: 0.9530\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.1678 - accuracy: 0.9449 - val_loss: 0.1086 - val_accuracy: 0.9680\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 32ms/step - loss: 0.0901 - accuracy: 0.9654 - val_loss: 0.0775 - val_accuracy: 0.9790\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0759 - accuracy: 0.9738 - val_loss: 0.0693 - val_accuracy: 0.9820\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0734 - accuracy: 0.9726 - val_loss: 0.0659 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0725 - accuracy: 0.9754 - val_loss: 0.0619 - val_accuracy: 0.9830\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0619 - accuracy: 0.9830\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 40ms/step - loss: 0.5921 - accuracy: 0.6519 - val_loss: 0.2158 - val_accuracy: 0.9510\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.1494 - accuracy: 0.9455 - val_loss: 0.0980 - val_accuracy: 0.9680\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0836 - accuracy: 0.9694 - val_loss: 0.0749 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 2s 48ms/step - loss: 0.0654 - accuracy: 0.9785 - val_loss: 0.0696 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.0601 - accuracy: 0.9783 - val_loss: 0.0632 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0556 - accuracy: 0.9809 - val_loss: 0.0592 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0592 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.5886 - accuracy: 0.6723 - val_loss: 0.2136 - val_accuracy: 0.9550\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.1275 - accuracy: 0.9577 - val_loss: 0.0972 - val_accuracy: 0.9710\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0756 - accuracy: 0.9734 - val_loss: 0.0779 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.0665 - accuracy: 0.9807 - val_loss: 0.0888 - val_accuracy: 0.9750\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.0780 - accuracy: 0.9714 - val_loss: 0.0637 - val_accuracy: 0.9820\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.0595 - accuracy: 0.9843 - val_loss: 0.0557 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0557 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 43ms/step - loss: 0.5288 - accuracy: 0.7368 - val_loss: 0.1617 - val_accuracy: 0.9600\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.1186 - accuracy: 0.9554 - val_loss: 0.0944 - val_accuracy: 0.9700\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.0777 - accuracy: 0.9729 - val_loss: 0.0763 - val_accuracy: 0.9840\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0662 - accuracy: 0.9787 - val_loss: 0.0687 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.0543 - accuracy: 0.9818 - val_loss: 0.0624 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.0610 - accuracy: 0.9817 - val_loss: 0.0620 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0620 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.6254 - accuracy: 0.6293 - val_loss: 0.3497 - val_accuracy: 0.9070\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.1935 - accuracy: 0.9371 - val_loss: 0.1100 - val_accuracy: 0.9670\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.0992 - accuracy: 0.9608 - val_loss: 0.0786 - val_accuracy: 0.9780\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 36ms/step - loss: 0.0765 - accuracy: 0.9777 - val_loss: 0.0729 - val_accuracy: 0.9760\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 35ms/step - loss: 0.0596 - accuracy: 0.9812 - val_loss: 0.0621 - val_accuracy: 0.9830\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.0612 - accuracy: 0.9774 - val_loss: 0.0577 - val_accuracy: 0.9890\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0577 - accuracy: 0.9890\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 40ms/step - loss: 0.5748 - accuracy: 0.6932 - val_loss: 0.1899 - val_accuracy: 0.9560\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.1370 - accuracy: 0.9503 - val_loss: 0.0945 - val_accuracy: 0.9710\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.0906 - accuracy: 0.9735 - val_loss: 0.0769 - val_accuracy: 0.9810\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0764 - accuracy: 0.9730 - val_loss: 0.0733 - val_accuracy: 0.9780\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0727 - accuracy: 0.9762 - val_loss: 0.0624 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 37ms/step - loss: 0.0532 - accuracy: 0.9831 - val_loss: 0.0632 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0632 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 40ms/step - loss: 0.6140 - accuracy: 0.6364 - val_loss: 0.2609 - val_accuracy: 0.9380\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.1539 - accuracy: 0.9453 - val_loss: 0.1022 - val_accuracy: 0.9690\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.0841 - accuracy: 0.9698 - val_loss: 0.0880 - val_accuracy: 0.9800\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.0890 - accuracy: 0.9682 - val_loss: 0.0802 - val_accuracy: 0.9820\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0706 - accuracy: 0.9766 - val_loss: 0.0618 - val_accuracy: 0.9830\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0563 - accuracy: 0.9842 - val_loss: 0.0604 - val_accuracy: 0.9820\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0604 - accuracy: 0.9820\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 39ms/step - loss: 0.5973 - accuracy: 0.6934 - val_loss: 0.2035 - val_accuracy: 0.9540\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.1382 - accuracy: 0.9513 - val_loss: 0.1091 - val_accuracy: 0.9750\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 2s 40ms/step - loss: 0.0950 - accuracy: 0.9690 - val_loss: 0.0718 - val_accuracy: 0.9810\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 34ms/step - loss: 0.0671 - accuracy: 0.9773 - val_loss: 0.0723 - val_accuracy: 0.9790\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0805 - accuracy: 0.9743 - val_loss: 0.0629 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0521 - accuracy: 0.9817 - val_loss: 0.0624 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0624 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 2s 40ms/step - loss: 0.6030 - accuracy: 0.6775 - val_loss: 0.2436 - val_accuracy: 0.9540\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.1562 - accuracy: 0.9502 - val_loss: 0.1119 - val_accuracy: 0.9670\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0896 - accuracy: 0.9668 - val_loss: 0.0837 - val_accuracy: 0.9760\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0799 - accuracy: 0.9732 - val_loss: 0.0769 - val_accuracy: 0.9760\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0681 - accuracy: 0.9810 - val_loss: 0.0668 - val_accuracy: 0.9820\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 1s 33ms/step - loss: 0.0616 - accuracy: 0.9784 - val_loss: 0.0646 - val_accuracy: 0.9830\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0646 - accuracy: 0.9830\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 3s 71ms/step - loss: 0.5529 - accuracy: 0.7047 - val_loss: 0.1371 - val_accuracy: 0.9560\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.1170 - accuracy: 0.9579 - val_loss: 0.0782 - val_accuracy: 0.9790\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0684 - accuracy: 0.9763 - val_loss: 0.0768 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0576 - accuracy: 0.9817 - val_loss: 0.0615 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0544 - accuracy: 0.9805 - val_loss: 0.0574 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0449 - accuracy: 0.9859 - val_loss: 0.0565 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0565 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.6121 - accuracy: 0.7020 - val_loss: 0.2295 - val_accuracy: 0.9510\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.1450 - accuracy: 0.9503 - val_loss: 0.0930 - val_accuracy: 0.9700\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0814 - accuracy: 0.9708 - val_loss: 0.0694 - val_accuracy: 0.9840\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0709 - accuracy: 0.9784 - val_loss: 0.0624 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0600 - accuracy: 0.9794 - val_loss: 0.0613 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0584 - accuracy: 0.9819 - val_loss: 0.0591 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0591 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 4s 77ms/step - loss: 0.5150 - accuracy: 0.7094 - val_loss: 0.1208 - val_accuracy: 0.9570\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1316 - accuracy: 0.9511 - val_loss: 0.0871 - val_accuracy: 0.9750\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0739 - accuracy: 0.9721 - val_loss: 0.0769 - val_accuracy: 0.9760\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0717 - accuracy: 0.9739 - val_loss: 0.0683 - val_accuracy: 0.9810\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0550 - accuracy: 0.9841 - val_loss: 0.0613 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0565 - accuracy: 0.9821 - val_loss: 0.0537 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0537 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.5670 - accuracy: 0.6904 - val_loss: 0.1338 - val_accuracy: 0.9600\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1499 - accuracy: 0.9448 - val_loss: 0.0997 - val_accuracy: 0.9690\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0761 - accuracy: 0.9664 - val_loss: 0.0719 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0631 - accuracy: 0.9822 - val_loss: 0.0788 - val_accuracy: 0.9790\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0638 - accuracy: 0.9793 - val_loss: 0.0715 - val_accuracy: 0.9830\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 3s 70ms/step - loss: 0.0555 - accuracy: 0.9814 - val_loss: 0.0676 - val_accuracy: 0.9810\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 0.0676 - accuracy: 0.9810\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 3s 74ms/step - loss: 0.6355 - accuracy: 0.6626 - val_loss: 0.2422 - val_accuracy: 0.9570\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.1558 - accuracy: 0.9452 - val_loss: 0.1285 - val_accuracy: 0.9630\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.1070 - accuracy: 0.9603 - val_loss: 0.0755 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0604 - accuracy: 0.9816 - val_loss: 0.0626 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0598 - accuracy: 0.9798 - val_loss: 0.0579 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0512 - accuracy: 0.9837 - val_loss: 0.0656 - val_accuracy: 0.9860\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0656 - accuracy: 0.9860\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.5077 - accuracy: 0.7555 - val_loss: 0.1113 - val_accuracy: 0.9610\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.1004 - accuracy: 0.9636 - val_loss: 0.0789 - val_accuracy: 0.9780\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 3s 71ms/step - loss: 0.0592 - accuracy: 0.9828 - val_loss: 0.0787 - val_accuracy: 0.9770\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0708 - accuracy: 0.9804 - val_loss: 0.0631 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0671 - accuracy: 0.9779 - val_loss: 0.0568 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0472 - accuracy: 0.9850 - val_loss: 0.0581 - val_accuracy: 0.9860\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0581 - accuracy: 0.9860\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.6485 - accuracy: 0.6612 - val_loss: 0.3304 - val_accuracy: 0.9360\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.1728 - accuracy: 0.9483 - val_loss: 0.1231 - val_accuracy: 0.9620\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0836 - accuracy: 0.9727 - val_loss: 0.0702 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0716 - accuracy: 0.9764 - val_loss: 0.0791 - val_accuracy: 0.9750\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0597 - accuracy: 0.9812 - val_loss: 0.0620 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0522 - accuracy: 0.9836 - val_loss: 0.0559 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0559 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 3s 73ms/step - loss: 0.5671 - accuracy: 0.7337 - val_loss: 0.1741 - val_accuracy: 0.9510\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 3s 72ms/step - loss: 0.1284 - accuracy: 0.9522 - val_loss: 0.0927 - val_accuracy: 0.9770\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0703 - accuracy: 0.9807 - val_loss: 0.0680 - val_accuracy: 0.9840\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0615 - accuracy: 0.9827 - val_loss: 0.0620 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.0626 - accuracy: 0.9817 - val_loss: 0.0556 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0530 - accuracy: 0.9805 - val_loss: 0.0523 - val_accuracy: 0.9890\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0523 - accuracy: 0.9890\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 3s 74ms/step - loss: 0.5780 - accuracy: 0.7138 - val_loss: 0.1584 - val_accuracy: 0.9560\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1137 - accuracy: 0.9588 - val_loss: 0.1153 - val_accuracy: 0.9660\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0766 - accuracy: 0.9745 - val_loss: 0.0758 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0747 - accuracy: 0.9757 - val_loss: 0.0605 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0572 - accuracy: 0.9818 - val_loss: 0.0574 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 3s 66ms/step - loss: 0.0484 - accuracy: 0.9829 - val_loss: 0.0542 - val_accuracy: 0.9890\n",
            "10/10 [==============================] - 0s 15ms/step - loss: 0.0542 - accuracy: 0.9890\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 4s 86ms/step - loss: 0.5283 - accuracy: 0.7125 - val_loss: 0.1146 - val_accuracy: 0.9600\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 3s 68ms/step - loss: 0.1192 - accuracy: 0.9579 - val_loss: 0.0782 - val_accuracy: 0.9780\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0717 - accuracy: 0.9728 - val_loss: 0.0699 - val_accuracy: 0.9790\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 3s 70ms/step - loss: 0.0674 - accuracy: 0.9762 - val_loss: 0.0583 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 3s 67ms/step - loss: 0.0515 - accuracy: 0.9807 - val_loss: 0.0582 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 3s 69ms/step - loss: 0.0545 - accuracy: 0.9836 - val_loss: 0.0644 - val_accuracy: 0.9850\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 0.0644 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 161ms/step - loss: 0.6558 - accuracy: 0.6295 - val_loss: 0.2235 - val_accuracy: 0.9590\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.1332 - accuracy: 0.9567 - val_loss: 0.0823 - val_accuracy: 0.9760\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.0779 - accuracy: 0.9699 - val_loss: 0.0700 - val_accuracy: 0.9840\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.0645 - accuracy: 0.9785 - val_loss: 0.0645 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.0495 - accuracy: 0.9845 - val_loss: 0.0577 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0449 - accuracy: 0.9853 - val_loss: 0.0575 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0575 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 163ms/step - loss: 0.5653 - accuracy: 0.7014 - val_loss: 0.1594 - val_accuracy: 0.9490\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.1107 - accuracy: 0.9546 - val_loss: 0.0835 - val_accuracy: 0.9790\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.0667 - accuracy: 0.9783 - val_loss: 0.0839 - val_accuracy: 0.9750\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0679 - accuracy: 0.9758 - val_loss: 0.0540 - val_accuracy: 0.9870\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 156ms/step - loss: 0.0497 - accuracy: 0.9863 - val_loss: 0.0471 - val_accuracy: 0.9890\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0428 - accuracy: 0.9883 - val_loss: 0.0461 - val_accuracy: 0.9910\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.0461 - accuracy: 0.9910\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 158ms/step - loss: 0.6087 - accuracy: 0.6642 - val_loss: 0.1695 - val_accuracy: 0.9500\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.1384 - accuracy: 0.9512 - val_loss: 0.0920 - val_accuracy: 0.9750\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.0711 - accuracy: 0.9736 - val_loss: 0.0660 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 155ms/step - loss: 0.0638 - accuracy: 0.9801 - val_loss: 0.0699 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0605 - accuracy: 0.9803 - val_loss: 0.0661 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.0488 - accuracy: 0.9842 - val_loss: 0.0569 - val_accuracy: 0.9860\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0569 - accuracy: 0.9860\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 159ms/step - loss: 0.5122 - accuracy: 0.7555 - val_loss: 0.0964 - val_accuracy: 0.9680\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0779 - accuracy: 0.9687 - val_loss: 0.0694 - val_accuracy: 0.9840\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0635 - accuracy: 0.9813 - val_loss: 0.0568 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 0.0595 - accuracy: 0.9830 - val_loss: 0.0682 - val_accuracy: 0.9820\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.0470 - accuracy: 0.9845 - val_loss: 0.0493 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.0387 - accuracy: 0.9858 - val_loss: 0.0494 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0494 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 159ms/step - loss: 0.5269 - accuracy: 0.7166 - val_loss: 0.1174 - val_accuracy: 0.9600\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.1052 - accuracy: 0.9623 - val_loss: 0.0837 - val_accuracy: 0.9810\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 159ms/step - loss: 0.0679 - accuracy: 0.9812 - val_loss: 0.0660 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.0592 - accuracy: 0.9823 - val_loss: 0.0589 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0471 - accuracy: 0.9866 - val_loss: 0.0619 - val_accuracy: 0.9890\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.0482 - accuracy: 0.9856 - val_loss: 0.0621 - val_accuracy: 0.9860\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0621 - accuracy: 0.9860\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 161ms/step - loss: 0.5578 - accuracy: 0.7168 - val_loss: 0.1481 - val_accuracy: 0.9530\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.1019 - accuracy: 0.9579 - val_loss: 0.1036 - val_accuracy: 0.9760\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0863 - accuracy: 0.9704 - val_loss: 0.0611 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0566 - accuracy: 0.9798 - val_loss: 0.0625 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 7s 167ms/step - loss: 0.0533 - accuracy: 0.9841 - val_loss: 0.0506 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 162ms/step - loss: 0.0451 - accuracy: 0.9883 - val_loss: 0.0582 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0582 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 160ms/step - loss: 0.4665 - accuracy: 0.7695 - val_loss: 0.1183 - val_accuracy: 0.9610\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 159ms/step - loss: 0.0888 - accuracy: 0.9720 - val_loss: 0.0685 - val_accuracy: 0.9810\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 155ms/step - loss: 0.0628 - accuracy: 0.9790 - val_loss: 0.0688 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0555 - accuracy: 0.9818 - val_loss: 0.0516 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 155ms/step - loss: 0.0439 - accuracy: 0.9873 - val_loss: 0.0501 - val_accuracy: 0.9900\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0383 - accuracy: 0.9898 - val_loss: 0.0440 - val_accuracy: 0.9940\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0440 - accuracy: 0.9940\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 159ms/step - loss: 0.7102 - accuracy: 0.5606 - val_loss: 0.5894 - val_accuracy: 0.5600\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.4563 - accuracy: 0.7296 - val_loss: 0.3466 - val_accuracy: 0.9580\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.1900 - accuracy: 0.9636 - val_loss: 0.0711 - val_accuracy: 0.9790\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0625 - accuracy: 0.9799 - val_loss: 0.0637 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0586 - accuracy: 0.9804 - val_loss: 0.0783 - val_accuracy: 0.9810\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.0600 - accuracy: 0.9809 - val_loss: 0.0569 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0569 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 163ms/step - loss: 0.5458 - accuracy: 0.6851 - val_loss: 0.1069 - val_accuracy: 0.9630\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.1063 - accuracy: 0.9617 - val_loss: 0.0789 - val_accuracy: 0.9760\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0696 - accuracy: 0.9786 - val_loss: 0.0734 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0632 - accuracy: 0.9786 - val_loss: 0.0599 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0645 - accuracy: 0.9805 - val_loss: 0.0532 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0517 - accuracy: 0.9849 - val_loss: 0.0517 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0517 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 161ms/step - loss: 0.6347 - accuracy: 0.6052 - val_loss: 0.2299 - val_accuracy: 0.9500\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 0.1591 - accuracy: 0.9446 - val_loss: 0.1069 - val_accuracy: 0.9710\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0856 - accuracy: 0.9707 - val_loss: 0.1040 - val_accuracy: 0.9660\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0859 - accuracy: 0.9708 - val_loss: 0.0642 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.0701 - accuracy: 0.9793 - val_loss: 0.0643 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0566 - accuracy: 0.9858 - val_loss: 0.0622 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0622 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 19s 467ms/step - loss: 0.6080 - accuracy: 0.6662 - val_loss: 0.1202 - val_accuracy: 0.9620\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 20s 493ms/step - loss: 0.0941 - accuracy: 0.9631 - val_loss: 0.0722 - val_accuracy: 0.9830\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 18s 459ms/step - loss: 0.0551 - accuracy: 0.9858 - val_loss: 0.0664 - val_accuracy: 0.9790\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 18s 456ms/step - loss: 0.0590 - accuracy: 0.9808 - val_loss: 0.0731 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 18s 456ms/step - loss: 0.0521 - accuracy: 0.9816 - val_loss: 0.0542 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 18s 456ms/step - loss: 0.0328 - accuracy: 0.9880 - val_loss: 0.0504 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 1s 113ms/step - loss: 0.0504 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 19s 459ms/step - loss: 0.6570 - accuracy: 0.6036 - val_loss: 0.2132 - val_accuracy: 0.9440\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 18s 454ms/step - loss: 0.1392 - accuracy: 0.9452 - val_loss: 0.0737 - val_accuracy: 0.9810\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 18s 453ms/step - loss: 0.0616 - accuracy: 0.9824 - val_loss: 0.0611 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 18s 455ms/step - loss: 0.0657 - accuracy: 0.9785 - val_loss: 0.0583 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 18s 455ms/step - loss: 0.0495 - accuracy: 0.9843 - val_loss: 0.0508 - val_accuracy: 0.9900\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 18s 457ms/step - loss: 0.0488 - accuracy: 0.9831 - val_loss: 0.0489 - val_accuracy: 0.9900\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.0489 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 19s 465ms/step - loss: 0.6254 - accuracy: 0.6141 - val_loss: 0.1534 - val_accuracy: 0.9580\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 18s 455ms/step - loss: 0.1182 - accuracy: 0.9571 - val_loss: 0.0938 - val_accuracy: 0.9770\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 19s 474ms/step - loss: 0.0625 - accuracy: 0.9794 - val_loss: 0.0653 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 18s 457ms/step - loss: 0.0603 - accuracy: 0.9845 - val_loss: 0.0624 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 19s 481ms/step - loss: 0.0533 - accuracy: 0.9823 - val_loss: 0.0597 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 19s 467ms/step - loss: 0.0431 - accuracy: 0.9869 - val_loss: 0.0596 - val_accuracy: 0.9900\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.0596 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 19s 466ms/step - loss: 0.7008 - accuracy: 0.5246 - val_loss: 0.5124 - val_accuracy: 0.9500\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 18s 457ms/step - loss: 0.2531 - accuracy: 0.9476 - val_loss: 0.1084 - val_accuracy: 0.9700\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 18s 458ms/step - loss: 0.0926 - accuracy: 0.9658 - val_loss: 0.0763 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 18s 457ms/step - loss: 0.0675 - accuracy: 0.9769 - val_loss: 0.0590 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 18s 457ms/step - loss: 0.0478 - accuracy: 0.9846 - val_loss: 0.0630 - val_accuracy: 0.9820\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 18s 461ms/step - loss: 0.0470 - accuracy: 0.9834 - val_loss: 0.0647 - val_accuracy: 0.9840\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.0647 - accuracy: 0.9840\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 19s 464ms/step - loss: 0.6777 - accuracy: 0.5688 - val_loss: 0.2425 - val_accuracy: 0.9530\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 18s 459ms/step - loss: 0.1266 - accuracy: 0.9538 - val_loss: 0.0840 - val_accuracy: 0.9800\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 18s 459ms/step - loss: 0.0750 - accuracy: 0.9736 - val_loss: 0.0684 - val_accuracy: 0.9810\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 18s 458ms/step - loss: 0.0900 - accuracy: 0.9759 - val_loss: 0.0590 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 18s 459ms/step - loss: 0.0542 - accuracy: 0.9836 - val_loss: 0.0629 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 18s 457ms/step - loss: 0.0554 - accuracy: 0.9851 - val_loss: 0.0533 - val_accuracy: 0.9900\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.0533 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 19s 464ms/step - loss: 0.6347 - accuracy: 0.6051 - val_loss: 0.2048 - val_accuracy: 0.9350\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 18s 457ms/step - loss: 0.1382 - accuracy: 0.9443 - val_loss: 0.0912 - val_accuracy: 0.9720\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 19s 484ms/step - loss: 0.0714 - accuracy: 0.9704 - val_loss: 0.0669 - val_accuracy: 0.9860\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 18s 462ms/step - loss: 0.0631 - accuracy: 0.9793 - val_loss: 0.0736 - val_accuracy: 0.9870\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 19s 464ms/step - loss: 0.0541 - accuracy: 0.9851 - val_loss: 0.0572 - val_accuracy: 0.9910\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 19s 464ms/step - loss: 0.0435 - accuracy: 0.9854 - val_loss: 0.0513 - val_accuracy: 0.9910\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.0513 - accuracy: 0.9910\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 19s 471ms/step - loss: 0.6900 - accuracy: 0.5536 - val_loss: 0.3897 - val_accuracy: 0.9530\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 18s 458ms/step - loss: 0.1819 - accuracy: 0.9515 - val_loss: 0.0808 - val_accuracy: 0.9810\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 18s 460ms/step - loss: 0.0706 - accuracy: 0.9809 - val_loss: 0.0726 - val_accuracy: 0.9790\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 18s 459ms/step - loss: 0.0641 - accuracy: 0.9815 - val_loss: 0.0627 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 18s 459ms/step - loss: 0.0518 - accuracy: 0.9837 - val_loss: 0.0581 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 19s 487ms/step - loss: 0.0480 - accuracy: 0.9868 - val_loss: 0.0535 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 1s 112ms/step - loss: 0.0535 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 19s 472ms/step - loss: 0.6623 - accuracy: 0.6144 - val_loss: 0.1931 - val_accuracy: 0.9520\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 18s 460ms/step - loss: 0.1268 - accuracy: 0.9551 - val_loss: 0.0891 - val_accuracy: 0.9790\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 18s 462ms/step - loss: 0.0748 - accuracy: 0.9747 - val_loss: 0.0720 - val_accuracy: 0.9860\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 18s 461ms/step - loss: 0.0647 - accuracy: 0.9801 - val_loss: 0.0544 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 18s 459ms/step - loss: 0.0496 - accuracy: 0.9841 - val_loss: 0.0488 - val_accuracy: 0.9900\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 18s 459ms/step - loss: 0.0456 - accuracy: 0.9867 - val_loss: 0.0466 - val_accuracy: 0.9890\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.0466 - accuracy: 0.9890\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 19s 471ms/step - loss: 0.5653 - accuracy: 0.6880 - val_loss: 0.1344 - val_accuracy: 0.9580\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 18s 458ms/step - loss: 0.1059 - accuracy: 0.9600 - val_loss: 0.0754 - val_accuracy: 0.9800\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 19s 464ms/step - loss: 0.0544 - accuracy: 0.9840 - val_loss: 0.0623 - val_accuracy: 0.9840\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 19s 471ms/step - loss: 0.0616 - accuracy: 0.9801 - val_loss: 0.0626 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 19s 473ms/step - loss: 0.0619 - accuracy: 0.9797 - val_loss: 0.0522 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 18s 462ms/step - loss: 0.0399 - accuracy: 0.9881 - val_loss: 0.0484 - val_accuracy: 0.9890\n",
            "10/10 [==============================] - 1s 114ms/step - loss: 0.0484 - accuracy: 0.9890\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 19s 467ms/step - loss: 0.5411 - accuracy: 0.7111 - val_loss: 0.1168 - val_accuracy: 0.9590\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 18s 458ms/step - loss: 0.1028 - accuracy: 0.9669 - val_loss: 0.0703 - val_accuracy: 0.9820\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 18s 460ms/step - loss: 0.0572 - accuracy: 0.9799 - val_loss: 0.0669 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 18s 459ms/step - loss: 0.0508 - accuracy: 0.9842 - val_loss: 0.0785 - val_accuracy: 0.9790\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 18s 460ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.0460 - val_accuracy: 0.9890\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 19s 464ms/step - loss: 0.0412 - accuracy: 0.9850 - val_loss: 0.0508 - val_accuracy: 0.9890\n",
            "10/10 [==============================] - 1s 111ms/step - loss: 0.0508 - accuracy: 0.9890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boxes': [<matplotlib.lines.Line2D at 0x7f142f7d8a58>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1431826f28>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14349b1358>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fc10320>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1431886e10>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd30978>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7f142f7d84e0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1431826588>,\n",
              "  <matplotlib.lines.Line2D at 0x7f143192dc88>,\n",
              "  <matplotlib.lines.Line2D at 0x7f143192d438>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14318ef6a0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fc10c18>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142f7fb240>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142f7fb908>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd526d8>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd52ac8>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd2cf60>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd2cc18>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7f1431826c18>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1431876fd0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fc102b0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1431886550>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd30b38>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd2c518>],\n",
              " 'means': [],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7f14318260b8>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1431876c88>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fc10e80>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142f7fbf60>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd30f28>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd2cb38>],\n",
              " 'whiskers': [<matplotlib.lines.Line2D at 0x7f142f7d89e8>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142f7d85c0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142f7e2cc0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142f7e2780>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fc40e10>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fbe0908>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142f7fd048>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142f7fd1d0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd52dd8>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd52b70>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1430722f28>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1430722518>]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kXtoaSYYRKr"
      },
      "source": [
        "128 may be more suitable (takes twice as long but still quick enough that it wouldn't be considered inefficient)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSxtix0nqAq2"
      },
      "source": [
        "Kernel Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "guYyn0HsYgUX",
        "outputId": "410f4afd-4bd3-47e2-bb24-382d19f1e4da"
      },
      "source": [
        "#different kernel sizes to investigate.\r\n",
        "kernel = [2, 3, 5, 7, 11]\r\n",
        "\r\n",
        "#initiate accuracy list.\r\n",
        "kernel_accuracy = []*5\r\n",
        "\r\n",
        "#repeat following steps for each kernel size.\r\n",
        "for i in range(len(kernel)):\r\n",
        "  accuracy = buildmultiple(128, kernel[i], 6, 100)\r\n",
        "  kernel_accuracy.append(accuracy)  \r\n",
        "\r\n",
        "#boxplots of the accuracy scores corresponding to each kernel size investigated. \r\n",
        "plt.boxplot(kernel_accuracy, labels = kernel)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "40/40 [==============================] - 6s 130ms/step - loss: 0.5982 - accuracy: 0.6484 - val_loss: 0.1480 - val_accuracy: 0.9570\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.1290 - accuracy: 0.9474 - val_loss: 0.1094 - val_accuracy: 0.9680\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.0704 - accuracy: 0.9788 - val_loss: 0.0683 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.0689 - accuracy: 0.9776 - val_loss: 0.0808 - val_accuracy: 0.9780\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 5s 122ms/step - loss: 0.0658 - accuracy: 0.9785 - val_loss: 0.0612 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.0484 - accuracy: 0.9853 - val_loss: 0.0560 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.0560 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 151ms/step - loss: 0.6340 - accuracy: 0.6379 - val_loss: 0.2303 - val_accuracy: 0.9550\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 5s 137ms/step - loss: 0.1332 - accuracy: 0.9546 - val_loss: 0.1193 - val_accuracy: 0.9750\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.0768 - accuracy: 0.9738 - val_loss: 0.0785 - val_accuracy: 0.9800\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.0649 - accuracy: 0.9785 - val_loss: 0.0636 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 5s 123ms/step - loss: 0.0457 - accuracy: 0.9842 - val_loss: 0.0553 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.0491 - accuracy: 0.9857 - val_loss: 0.0511 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.0511 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 6s 129ms/step - loss: 0.6782 - accuracy: 0.5882 - val_loss: 0.4182 - val_accuracy: 0.9470\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.2199 - accuracy: 0.9427 - val_loss: 0.1078 - val_accuracy: 0.9630\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.0843 - accuracy: 0.9676 - val_loss: 0.0764 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.0665 - accuracy: 0.9789 - val_loss: 0.0901 - val_accuracy: 0.9770\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 5s 123ms/step - loss: 0.0596 - accuracy: 0.9804 - val_loss: 0.0567 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.0611 - accuracy: 0.9767 - val_loss: 0.0588 - val_accuracy: 0.9900\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.0588 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 6s 135ms/step - loss: 0.6776 - accuracy: 0.5513 - val_loss: 0.3936 - val_accuracy: 0.9530\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.1953 - accuracy: 0.9475 - val_loss: 0.1148 - val_accuracy: 0.9650\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.0905 - accuracy: 0.9714 - val_loss: 0.0801 - val_accuracy: 0.9780\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.0742 - accuracy: 0.9762 - val_loss: 0.0711 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 5s 127ms/step - loss: 0.0625 - accuracy: 0.9822 - val_loss: 0.0607 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.0529 - accuracy: 0.9829 - val_loss: 0.0569 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.0569 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 6s 133ms/step - loss: 0.5711 - accuracy: 0.6656 - val_loss: 0.1558 - val_accuracy: 0.9510\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.1181 - accuracy: 0.9585 - val_loss: 0.0834 - val_accuracy: 0.9750\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.0614 - accuracy: 0.9782 - val_loss: 0.0685 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.0581 - accuracy: 0.9809 - val_loss: 0.0754 - val_accuracy: 0.9770\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.0647 - accuracy: 0.9781 - val_loss: 0.0604 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.0475 - accuracy: 0.9863 - val_loss: 0.0519 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.0519 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 6s 137ms/step - loss: 0.6215 - accuracy: 0.6228 - val_loss: 0.2508 - val_accuracy: 0.9510\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 5s 131ms/step - loss: 0.1577 - accuracy: 0.9456 - val_loss: 0.1173 - val_accuracy: 0.9690\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 5s 123ms/step - loss: 0.0863 - accuracy: 0.9689 - val_loss: 0.0758 - val_accuracy: 0.9810\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.0627 - accuracy: 0.9828 - val_loss: 0.0814 - val_accuracy: 0.9760\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 5s 123ms/step - loss: 0.0606 - accuracy: 0.9806 - val_loss: 0.0702 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 5s 122ms/step - loss: 0.0438 - accuracy: 0.9842 - val_loss: 0.0599 - val_accuracy: 0.9860\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.0599 - accuracy: 0.9860\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 6s 132ms/step - loss: 0.5197 - accuracy: 0.7440 - val_loss: 0.1394 - val_accuracy: 0.9580\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.1116 - accuracy: 0.9606 - val_loss: 0.0780 - val_accuracy: 0.9790\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.0743 - accuracy: 0.9759 - val_loss: 0.0641 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.0642 - accuracy: 0.9806 - val_loss: 0.0703 - val_accuracy: 0.9820\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 5s 127ms/step - loss: 0.0629 - accuracy: 0.9803 - val_loss: 0.0701 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.0504 - accuracy: 0.9826 - val_loss: 0.0479 - val_accuracy: 0.9910\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.0479 - accuracy: 0.9910\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 6s 140ms/step - loss: 0.4962 - accuracy: 0.7433 - val_loss: 0.1946 - val_accuracy: 0.9380\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.1145 - accuracy: 0.9595 - val_loss: 0.0820 - val_accuracy: 0.9780\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 5s 123ms/step - loss: 0.0650 - accuracy: 0.9776 - val_loss: 0.0605 - val_accuracy: 0.9840\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.0721 - accuracy: 0.9766 - val_loss: 0.0585 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.0492 - accuracy: 0.9847 - val_loss: 0.0653 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.0384 - accuracy: 0.9870 - val_loss: 0.0504 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.0504 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 6s 133ms/step - loss: 0.6394 - accuracy: 0.6309 - val_loss: 0.2315 - val_accuracy: 0.9550\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.1311 - accuracy: 0.9561 - val_loss: 0.0982 - val_accuracy: 0.9790\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 145ms/step - loss: 0.0715 - accuracy: 0.9773 - val_loss: 0.0671 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 5s 131ms/step - loss: 0.0702 - accuracy: 0.9748 - val_loss: 0.0631 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.0764 - accuracy: 0.9805 - val_loss: 0.0590 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 5s 127ms/step - loss: 0.0523 - accuracy: 0.9813 - val_loss: 0.0557 - val_accuracy: 0.9900\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.0557 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 6s 133ms/step - loss: 0.5151 - accuracy: 0.7331 - val_loss: 0.1720 - val_accuracy: 0.9520\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.1127 - accuracy: 0.9594 - val_loss: 0.0774 - val_accuracy: 0.9790\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.0692 - accuracy: 0.9759 - val_loss: 0.0618 - val_accuracy: 0.9840\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 5s 125ms/step - loss: 0.0700 - accuracy: 0.9784 - val_loss: 0.0952 - val_accuracy: 0.9710\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 5s 126ms/step - loss: 0.0749 - accuracy: 0.9807 - val_loss: 0.0557 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 5s 124ms/step - loss: 0.0564 - accuracy: 0.9833 - val_loss: 0.0626 - val_accuracy: 0.9860\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.0626 - accuracy: 0.9860\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 161ms/step - loss: 0.6397 - accuracy: 0.5938 - val_loss: 0.2018 - val_accuracy: 0.9520\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 150ms/step - loss: 0.1345 - accuracy: 0.9482 - val_loss: 0.0823 - val_accuracy: 0.9750\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 0.0743 - accuracy: 0.9721 - val_loss: 0.0708 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.0633 - accuracy: 0.9816 - val_loss: 0.0588 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 155ms/step - loss: 0.0617 - accuracy: 0.9786 - val_loss: 0.0608 - val_accuracy: 0.9810\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 158ms/step - loss: 0.0428 - accuracy: 0.9852 - val_loss: 0.0667 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.0667 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 160ms/step - loss: 0.6292 - accuracy: 0.6245 - val_loss: 0.1993 - val_accuracy: 0.9470\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.1211 - accuracy: 0.9593 - val_loss: 0.0913 - val_accuracy: 0.9790\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0672 - accuracy: 0.9762 - val_loss: 0.0689 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.0703 - accuracy: 0.9739 - val_loss: 0.0923 - val_accuracy: 0.9820\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0627 - accuracy: 0.9794 - val_loss: 0.0635 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 156ms/step - loss: 0.0522 - accuracy: 0.9825 - val_loss: 0.0586 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0586 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 161ms/step - loss: 0.5479 - accuracy: 0.7172 - val_loss: 0.1405 - val_accuracy: 0.9570\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 155ms/step - loss: 0.1220 - accuracy: 0.9619 - val_loss: 0.0797 - val_accuracy: 0.9790\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 157ms/step - loss: 0.0643 - accuracy: 0.9813 - val_loss: 0.0699 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.0571 - accuracy: 0.9827 - val_loss: 0.0617 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.0515 - accuracy: 0.9841 - val_loss: 0.0659 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0536 - accuracy: 0.9838 - val_loss: 0.0518 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0518 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 159ms/step - loss: 0.6533 - accuracy: 0.5834 - val_loss: 0.2415 - val_accuracy: 0.9520\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.1285 - accuracy: 0.9523 - val_loss: 0.0761 - val_accuracy: 0.9770\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0651 - accuracy: 0.9754 - val_loss: 0.0656 - val_accuracy: 0.9860\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.0604 - accuracy: 0.9802 - val_loss: 0.0594 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.0502 - accuracy: 0.9842 - val_loss: 0.0595 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0490 - accuracy: 0.9818 - val_loss: 0.0515 - val_accuracy: 0.9900\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0515 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 160ms/step - loss: 0.5444 - accuracy: 0.6936 - val_loss: 0.1253 - val_accuracy: 0.9590\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 157ms/step - loss: 0.1038 - accuracy: 0.9600 - val_loss: 0.0778 - val_accuracy: 0.9800\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 150ms/step - loss: 0.0632 - accuracy: 0.9805 - val_loss: 0.0793 - val_accuracy: 0.9790\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 149ms/step - loss: 0.0595 - accuracy: 0.9809 - val_loss: 0.0566 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 0.0592 - accuracy: 0.9812 - val_loss: 0.0559 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 7s 171ms/step - loss: 0.0447 - accuracy: 0.9830 - val_loss: 0.0524 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.0524 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 163ms/step - loss: 0.6980 - accuracy: 0.5606 - val_loss: 0.5085 - val_accuracy: 0.8740\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.2801 - accuracy: 0.9146 - val_loss: 0.1642 - val_accuracy: 0.9540\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 155ms/step - loss: 0.1001 - accuracy: 0.9661 - val_loss: 0.0792 - val_accuracy: 0.9780\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0819 - accuracy: 0.9687 - val_loss: 0.0705 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.0607 - accuracy: 0.9816 - val_loss: 0.0619 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.0615 - accuracy: 0.9794 - val_loss: 0.0827 - val_accuracy: 0.9770\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0827 - accuracy: 0.9770\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 163ms/step - loss: 0.6622 - accuracy: 0.6070 - val_loss: 0.2705 - val_accuracy: 0.9560\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.1489 - accuracy: 0.9503 - val_loss: 0.1029 - val_accuracy: 0.9750\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.0861 - accuracy: 0.9700 - val_loss: 0.0876 - val_accuracy: 0.9720\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 0.0643 - accuracy: 0.9782 - val_loss: 0.0699 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 0.0514 - accuracy: 0.9815 - val_loss: 0.0651 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 0.0494 - accuracy: 0.9854 - val_loss: 0.0508 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0508 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 161ms/step - loss: 0.5962 - accuracy: 0.6785 - val_loss: 0.1672 - val_accuracy: 0.9590\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 152ms/step - loss: 0.1268 - accuracy: 0.9540 - val_loss: 0.0884 - val_accuracy: 0.9770\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 154ms/step - loss: 0.0719 - accuracy: 0.9775 - val_loss: 0.0718 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0670 - accuracy: 0.9811 - val_loss: 0.0758 - val_accuracy: 0.9760\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0677 - accuracy: 0.9788 - val_loss: 0.0544 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0466 - accuracy: 0.9871 - val_loss: 0.0556 - val_accuracy: 0.9890\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0556 - accuracy: 0.9890\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 7s 168ms/step - loss: 0.5998 - accuracy: 0.6632 - val_loss: 0.1462 - val_accuracy: 0.9600\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 0.1077 - accuracy: 0.9597 - val_loss: 0.0957 - val_accuracy: 0.9770\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 150ms/step - loss: 0.0659 - accuracy: 0.9752 - val_loss: 0.0662 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 151ms/step - loss: 0.0728 - accuracy: 0.9784 - val_loss: 0.0625 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 150ms/step - loss: 0.0620 - accuracy: 0.9793 - val_loss: 0.0560 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0451 - accuracy: 0.9852 - val_loss: 0.0640 - val_accuracy: 0.9810\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0640 - accuracy: 0.9810\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 8s 180ms/step - loss: 0.5954 - accuracy: 0.6824 - val_loss: 0.1492 - val_accuracy: 0.9540\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 6s 158ms/step - loss: 0.1332 - accuracy: 0.9501 - val_loss: 0.0805 - val_accuracy: 0.9800\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 6s 156ms/step - loss: 0.0693 - accuracy: 0.9736 - val_loss: 0.0662 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 6s 155ms/step - loss: 0.0574 - accuracy: 0.9815 - val_loss: 0.0627 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 6s 155ms/step - loss: 0.0718 - accuracy: 0.9757 - val_loss: 0.0607 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 6s 153ms/step - loss: 0.0446 - accuracy: 0.9855 - val_loss: 0.0592 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0592 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 10s 234ms/step - loss: 0.5662 - accuracy: 0.7016 - val_loss: 0.1197 - val_accuracy: 0.9620\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 9s 228ms/step - loss: 0.0940 - accuracy: 0.9674 - val_loss: 0.0703 - val_accuracy: 0.9830\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 9s 230ms/step - loss: 0.0691 - accuracy: 0.9755 - val_loss: 0.0593 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 9s 227ms/step - loss: 0.0575 - accuracy: 0.9809 - val_loss: 0.0556 - val_accuracy: 0.9870\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 9s 224ms/step - loss: 0.0382 - accuracy: 0.9876 - val_loss: 0.0512 - val_accuracy: 0.9890\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 9s 226ms/step - loss: 0.0522 - accuracy: 0.9826 - val_loss: 0.0464 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0464 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 10s 233ms/step - loss: 0.5805 - accuracy: 0.6599 - val_loss: 0.1575 - val_accuracy: 0.9510\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 9s 228ms/step - loss: 0.1346 - accuracy: 0.9471 - val_loss: 0.0818 - val_accuracy: 0.9780\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 9s 226ms/step - loss: 0.0814 - accuracy: 0.9696 - val_loss: 0.0692 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 9s 228ms/step - loss: 0.0560 - accuracy: 0.9803 - val_loss: 0.0582 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 9s 230ms/step - loss: 0.0583 - accuracy: 0.9782 - val_loss: 0.0632 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 9s 225ms/step - loss: 0.0599 - accuracy: 0.9782 - val_loss: 0.0548 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0548 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 10s 233ms/step - loss: 0.6487 - accuracy: 0.5955 - val_loss: 0.2468 - val_accuracy: 0.9500\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 10s 246ms/step - loss: 0.1364 - accuracy: 0.9524 - val_loss: 0.0974 - val_accuracy: 0.9680\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 9s 235ms/step - loss: 0.0855 - accuracy: 0.9687 - val_loss: 0.0655 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 9s 227ms/step - loss: 0.0511 - accuracy: 0.9832 - val_loss: 0.0829 - val_accuracy: 0.9770\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 9s 227ms/step - loss: 0.0535 - accuracy: 0.9824 - val_loss: 0.0667 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 9s 226ms/step - loss: 0.0470 - accuracy: 0.9851 - val_loss: 0.0563 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0563 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 10s 232ms/step - loss: 0.6570 - accuracy: 0.6181 - val_loss: 0.2801 - val_accuracy: 0.9490\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 9s 228ms/step - loss: 0.1404 - accuracy: 0.9539 - val_loss: 0.0884 - val_accuracy: 0.9750\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 9s 226ms/step - loss: 0.0735 - accuracy: 0.9709 - val_loss: 0.0718 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 9s 231ms/step - loss: 0.0523 - accuracy: 0.9831 - val_loss: 0.0646 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 9s 227ms/step - loss: 0.0520 - accuracy: 0.9826 - val_loss: 0.0592 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 9s 225ms/step - loss: 0.0473 - accuracy: 0.9841 - val_loss: 0.0534 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0534 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 10s 233ms/step - loss: 0.5266 - accuracy: 0.7081 - val_loss: 0.1097 - val_accuracy: 0.9630\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 9s 226ms/step - loss: 0.0931 - accuracy: 0.9629 - val_loss: 0.0835 - val_accuracy: 0.9770\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 9s 226ms/step - loss: 0.0571 - accuracy: 0.9840 - val_loss: 0.0641 - val_accuracy: 0.9840\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 9s 226ms/step - loss: 0.0432 - accuracy: 0.9846 - val_loss: 0.0563 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 10s 250ms/step - loss: 0.0506 - accuracy: 0.9831 - val_loss: 0.0607 - val_accuracy: 0.9810\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 10s 239ms/step - loss: 0.0471 - accuracy: 0.9850 - val_loss: 0.0532 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0532 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 10s 236ms/step - loss: 0.5069 - accuracy: 0.7316 - val_loss: 0.1280 - val_accuracy: 0.9590\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 9s 230ms/step - loss: 0.0964 - accuracy: 0.9675 - val_loss: 0.0810 - val_accuracy: 0.9790\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 9s 229ms/step - loss: 0.0683 - accuracy: 0.9787 - val_loss: 0.0573 - val_accuracy: 0.9860\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 9s 230ms/step - loss: 0.0474 - accuracy: 0.9825 - val_loss: 0.0534 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 9s 228ms/step - loss: 0.0474 - accuracy: 0.9855 - val_loss: 0.0497 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 9s 226ms/step - loss: 0.0552 - accuracy: 0.9836 - val_loss: 0.0568 - val_accuracy: 0.9860\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0568 - accuracy: 0.9860\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 10s 234ms/step - loss: 0.6262 - accuracy: 0.6127 - val_loss: 0.2039 - val_accuracy: 0.9470\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 9s 229ms/step - loss: 0.1507 - accuracy: 0.9427 - val_loss: 0.1001 - val_accuracy: 0.9680\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 9s 226ms/step - loss: 0.0751 - accuracy: 0.9743 - val_loss: 0.0736 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 9s 226ms/step - loss: 0.0680 - accuracy: 0.9805 - val_loss: 0.0561 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 9s 225ms/step - loss: 0.0563 - accuracy: 0.9812 - val_loss: 0.0625 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 9s 225ms/step - loss: 0.0472 - accuracy: 0.9825 - val_loss: 0.0515 - val_accuracy: 0.9890\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0515 - accuracy: 0.9890\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 10s 237ms/step - loss: 0.5699 - accuracy: 0.6666 - val_loss: 0.1247 - val_accuracy: 0.9550\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 9s 227ms/step - loss: 0.1098 - accuracy: 0.9615 - val_loss: 0.0869 - val_accuracy: 0.9790\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 9s 230ms/step - loss: 0.0744 - accuracy: 0.9740 - val_loss: 0.0608 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 9s 224ms/step - loss: 0.0513 - accuracy: 0.9865 - val_loss: 0.0522 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 9s 224ms/step - loss: 0.0435 - accuracy: 0.9850 - val_loss: 0.0550 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 9s 224ms/step - loss: 0.0491 - accuracy: 0.9851 - val_loss: 0.0464 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0464 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 10s 235ms/step - loss: 0.6818 - accuracy: 0.5778 - val_loss: 0.3442 - val_accuracy: 0.9560\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 9s 226ms/step - loss: 0.1826 - accuracy: 0.9483 - val_loss: 0.0974 - val_accuracy: 0.9690\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 9s 227ms/step - loss: 0.0879 - accuracy: 0.9659 - val_loss: 0.0807 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 9s 226ms/step - loss: 0.0592 - accuracy: 0.9785 - val_loss: 0.0602 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 9s 226ms/step - loss: 0.0544 - accuracy: 0.9819 - val_loss: 0.0547 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 10s 255ms/step - loss: 0.0686 - accuracy: 0.9810 - val_loss: 0.0616 - val_accuracy: 0.9860\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0616 - accuracy: 0.9860\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 10s 242ms/step - loss: 0.5832 - accuracy: 0.6847 - val_loss: 0.1278 - val_accuracy: 0.9640\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 9s 224ms/step - loss: 0.0924 - accuracy: 0.9655 - val_loss: 0.0714 - val_accuracy: 0.9830\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 9s 223ms/step - loss: 0.0574 - accuracy: 0.9793 - val_loss: 0.0529 - val_accuracy: 0.9840\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 9s 226ms/step - loss: 0.0452 - accuracy: 0.9845 - val_loss: 0.0548 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 9s 223ms/step - loss: 0.0525 - accuracy: 0.9824 - val_loss: 0.0534 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 9s 224ms/step - loss: 0.0496 - accuracy: 0.9815 - val_loss: 0.0599 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.0599 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 12s 287ms/step - loss: 0.6366 - accuracy: 0.6405 - val_loss: 0.1638 - val_accuracy: 0.9550\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.1188 - accuracy: 0.9497 - val_loss: 0.0860 - val_accuracy: 0.9840\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.0599 - accuracy: 0.9781 - val_loss: 0.0727 - val_accuracy: 0.9790\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.0633 - accuracy: 0.9769 - val_loss: 0.0554 - val_accuracy: 0.9820\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.0582 - accuracy: 0.9818 - val_loss: 0.0573 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.0463 - accuracy: 0.9856 - val_loss: 0.0619 - val_accuracy: 0.9850\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.0619 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 12s 292ms/step - loss: 0.6332 - accuracy: 0.6265 - val_loss: 0.2259 - val_accuracy: 0.9480\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.1293 - accuracy: 0.9545 - val_loss: 0.0751 - val_accuracy: 0.9790\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.0698 - accuracy: 0.9756 - val_loss: 0.0584 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.0602 - accuracy: 0.9790 - val_loss: 0.0748 - val_accuracy: 0.9800\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.0542 - accuracy: 0.9834 - val_loss: 0.0536 - val_accuracy: 0.9900\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.0446 - accuracy: 0.9850 - val_loss: 0.0537 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.0537 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 12s 287ms/step - loss: 0.6860 - accuracy: 0.5768 - val_loss: 0.4487 - val_accuracy: 0.8210\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.2440 - accuracy: 0.9276 - val_loss: 0.0823 - val_accuracy: 0.9800\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.0726 - accuracy: 0.9708 - val_loss: 0.0859 - val_accuracy: 0.9800\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 12s 309ms/step - loss: 0.0544 - accuracy: 0.9811 - val_loss: 0.0878 - val_accuracy: 0.9750\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.0839 - accuracy: 0.9701 - val_loss: 0.0567 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.0523 - accuracy: 0.9846 - val_loss: 0.0506 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.0506 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 12s 293ms/step - loss: 0.5802 - accuracy: 0.6901 - val_loss: 0.0995 - val_accuracy: 0.9610\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.0852 - accuracy: 0.9704 - val_loss: 0.0749 - val_accuracy: 0.9860\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.0858 - accuracy: 0.9701 - val_loss: 0.0596 - val_accuracy: 0.9860\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.0541 - accuracy: 0.9811 - val_loss: 0.0491 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.0418 - accuracy: 0.9868 - val_loss: 0.0613 - val_accuracy: 0.9830\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.0490 - accuracy: 0.9862 - val_loss: 0.0457 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.0457 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 12s 287ms/step - loss: 0.5990 - accuracy: 0.6444 - val_loss: 0.0961 - val_accuracy: 0.9610\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.0839 - accuracy: 0.9709 - val_loss: 0.0682 - val_accuracy: 0.9800\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.0569 - accuracy: 0.9808 - val_loss: 0.0628 - val_accuracy: 0.9840\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.0612 - accuracy: 0.9806 - val_loss: 0.0869 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.0586 - accuracy: 0.9843 - val_loss: 0.0482 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.0360 - accuracy: 0.9879 - val_loss: 0.0622 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.0622 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 12s 284ms/step - loss: 0.6223 - accuracy: 0.6256 - val_loss: 0.1538 - val_accuracy: 0.9610\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.0873 - accuracy: 0.9655 - val_loss: 0.0806 - val_accuracy: 0.9790\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.0588 - accuracy: 0.9784 - val_loss: 0.0655 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.0569 - accuracy: 0.9828 - val_loss: 0.0559 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 11s 280ms/step - loss: 0.0508 - accuracy: 0.9842 - val_loss: 0.0541 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.0526 - accuracy: 0.9824 - val_loss: 0.0467 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.0467 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 13s 306ms/step - loss: 0.6227 - accuracy: 0.6379 - val_loss: 0.1889 - val_accuracy: 0.9640\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 11s 286ms/step - loss: 0.1029 - accuracy: 0.9634 - val_loss: 0.0677 - val_accuracy: 0.9810\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.0767 - accuracy: 0.9731 - val_loss: 0.0618 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.0575 - accuracy: 0.9792 - val_loss: 0.0569 - val_accuracy: 0.9870\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 11s 283ms/step - loss: 0.0453 - accuracy: 0.9835 - val_loss: 0.0661 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.0478 - accuracy: 0.9852 - val_loss: 0.0497 - val_accuracy: 0.9900\n",
            "10/10 [==============================] - 1s 68ms/step - loss: 0.0497 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 12s 286ms/step - loss: 0.5493 - accuracy: 0.6913 - val_loss: 0.1071 - val_accuracy: 0.9730\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.0845 - accuracy: 0.9704 - val_loss: 0.0681 - val_accuracy: 0.9790\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.0567 - accuracy: 0.9791 - val_loss: 0.0740 - val_accuracy: 0.9800\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.0653 - accuracy: 0.9767 - val_loss: 0.0682 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 0.0621 - accuracy: 0.9748 - val_loss: 0.0501 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 0.0538 - accuracy: 0.9854 - val_loss: 0.0508 - val_accuracy: 0.9890\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.0508 - accuracy: 0.9890\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 12s 288ms/step - loss: 0.6296 - accuracy: 0.6376 - val_loss: 0.1299 - val_accuracy: 0.9620\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.0861 - accuracy: 0.9671 - val_loss: 0.0633 - val_accuracy: 0.9830\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.0560 - accuracy: 0.9809 - val_loss: 0.0667 - val_accuracy: 0.9790\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 11s 285ms/step - loss: 0.0649 - accuracy: 0.9769 - val_loss: 0.0524 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 11s 277ms/step - loss: 0.0537 - accuracy: 0.9832 - val_loss: 0.0491 - val_accuracy: 0.9900\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.0473 - accuracy: 0.9841 - val_loss: 0.0510 - val_accuracy: 0.9860\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.0510 - accuracy: 0.9860\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 12s 292ms/step - loss: 0.6188 - accuracy: 0.6446 - val_loss: 0.1359 - val_accuracy: 0.9760\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 12s 297ms/step - loss: 0.0757 - accuracy: 0.9729 - val_loss: 0.0636 - val_accuracy: 0.9820\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 12s 288ms/step - loss: 0.0561 - accuracy: 0.9816 - val_loss: 0.0601 - val_accuracy: 0.9870\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 11s 284ms/step - loss: 0.0575 - accuracy: 0.9816 - val_loss: 0.0524 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 11s 282ms/step - loss: 0.0430 - accuracy: 0.9849 - val_loss: 0.0532 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 11s 281ms/step - loss: 0.0674 - accuracy: 0.9794 - val_loss: 0.0475 - val_accuracy: 0.9890\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.0475 - accuracy: 0.9890\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 15s 375ms/step - loss: 0.6384 - accuracy: 0.6017 - val_loss: 0.1131 - val_accuracy: 0.9720\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 15s 367ms/step - loss: 0.0926 - accuracy: 0.9724 - val_loss: 0.0752 - val_accuracy: 0.9780\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 15s 373ms/step - loss: 0.0718 - accuracy: 0.9779 - val_loss: 0.0615 - val_accuracy: 0.9810\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 15s 372ms/step - loss: 0.0459 - accuracy: 0.9824 - val_loss: 0.0767 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 14s 362ms/step - loss: 0.0538 - accuracy: 0.9834 - val_loss: 0.0497 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 15s 365ms/step - loss: 0.0439 - accuracy: 0.9873 - val_loss: 0.0518 - val_accuracy: 0.9900\n",
            "10/10 [==============================] - 1s 88ms/step - loss: 0.0518 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 15s 372ms/step - loss: 0.6101 - accuracy: 0.6275 - val_loss: 0.1025 - val_accuracy: 0.9790\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 15s 366ms/step - loss: 0.0973 - accuracy: 0.9714 - val_loss: 0.0781 - val_accuracy: 0.9790\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 15s 366ms/step - loss: 0.0628 - accuracy: 0.9817 - val_loss: 0.0754 - val_accuracy: 0.9810\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 15s 366ms/step - loss: 0.0545 - accuracy: 0.9816 - val_loss: 0.0536 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 15s 365ms/step - loss: 0.0536 - accuracy: 0.9820 - val_loss: 0.0495 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 15s 365ms/step - loss: 0.0339 - accuracy: 0.9890 - val_loss: 0.0515 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 0.0515 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 15s 372ms/step - loss: 0.5522 - accuracy: 0.7139 - val_loss: 0.0952 - val_accuracy: 0.9710\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 16s 392ms/step - loss: 0.0839 - accuracy: 0.9727 - val_loss: 0.0808 - val_accuracy: 0.9820\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 15s 369ms/step - loss: 0.0591 - accuracy: 0.9795 - val_loss: 0.0717 - val_accuracy: 0.9840\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 15s 368ms/step - loss: 0.0531 - accuracy: 0.9836 - val_loss: 0.0551 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 15s 367ms/step - loss: 0.0401 - accuracy: 0.9862 - val_loss: 0.0611 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 15s 368ms/step - loss: 0.0474 - accuracy: 0.9857 - val_loss: 0.0451 - val_accuracy: 0.9900\n",
            "10/10 [==============================] - 1s 88ms/step - loss: 0.0451 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 15s 374ms/step - loss: 0.5499 - accuracy: 0.6753 - val_loss: 0.0743 - val_accuracy: 0.9770\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 15s 368ms/step - loss: 0.0763 - accuracy: 0.9756 - val_loss: 0.0726 - val_accuracy: 0.9820\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 15s 367ms/step - loss: 0.0586 - accuracy: 0.9831 - val_loss: 0.0479 - val_accuracy: 0.9860\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 15s 368ms/step - loss: 0.0413 - accuracy: 0.9866 - val_loss: 0.0531 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 15s 365ms/step - loss: 0.0384 - accuracy: 0.9897 - val_loss: 0.0545 - val_accuracy: 0.9830\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 15s 370ms/step - loss: 0.0425 - accuracy: 0.9883 - val_loss: 0.0426 - val_accuracy: 0.9920\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0426 - accuracy: 0.9920\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 16s 379ms/step - loss: 0.5839 - accuracy: 0.6628 - val_loss: 0.0862 - val_accuracy: 0.9740\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 15s 369ms/step - loss: 0.1205 - accuracy: 0.9667 - val_loss: 0.0713 - val_accuracy: 0.9780\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 15s 365ms/step - loss: 0.0770 - accuracy: 0.9783 - val_loss: 0.0772 - val_accuracy: 0.9810\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 15s 386ms/step - loss: 0.0485 - accuracy: 0.9869 - val_loss: 0.0528 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 15s 373ms/step - loss: 0.0506 - accuracy: 0.9840 - val_loss: 0.0512 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 15s 367ms/step - loss: 0.0400 - accuracy: 0.9878 - val_loss: 0.0507 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 0.0507 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 15s 376ms/step - loss: 0.5365 - accuracy: 0.7433 - val_loss: 0.1040 - val_accuracy: 0.9710\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 15s 370ms/step - loss: 0.0969 - accuracy: 0.9713 - val_loss: 0.0784 - val_accuracy: 0.9770\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 15s 366ms/step - loss: 0.0667 - accuracy: 0.9776 - val_loss: 0.0538 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 15s 369ms/step - loss: 0.0448 - accuracy: 0.9877 - val_loss: 0.0544 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 15s 366ms/step - loss: 0.0385 - accuracy: 0.9863 - val_loss: 0.0603 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 15s 372ms/step - loss: 0.0377 - accuracy: 0.9880 - val_loss: 0.0530 - val_accuracy: 0.9870\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.0530 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 16s 378ms/step - loss: 0.6513 - accuracy: 0.6420 - val_loss: 0.1778 - val_accuracy: 0.9800\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 16s 394ms/step - loss: 0.1118 - accuracy: 0.9671 - val_loss: 0.0853 - val_accuracy: 0.9780\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 15s 371ms/step - loss: 0.0707 - accuracy: 0.9768 - val_loss: 0.0886 - val_accuracy: 0.9810\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 15s 370ms/step - loss: 0.0736 - accuracy: 0.9770 - val_loss: 0.0566 - val_accuracy: 0.9810\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 15s 370ms/step - loss: 0.0479 - accuracy: 0.9860 - val_loss: 0.0543 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 15s 367ms/step - loss: 0.0470 - accuracy: 0.9860 - val_loss: 0.0572 - val_accuracy: 0.9880\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 0.0572 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 16s 377ms/step - loss: 0.6762 - accuracy: 0.6189 - val_loss: 0.1456 - val_accuracy: 0.9790\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 15s 371ms/step - loss: 0.0920 - accuracy: 0.9725 - val_loss: 0.0944 - val_accuracy: 0.9720\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 15s 376ms/step - loss: 0.0722 - accuracy: 0.9761 - val_loss: 0.0666 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 15s 369ms/step - loss: 0.0558 - accuracy: 0.9830 - val_loss: 0.0611 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 15s 384ms/step - loss: 0.0473 - accuracy: 0.9866 - val_loss: 0.0527 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 15s 376ms/step - loss: 0.0414 - accuracy: 0.9869 - val_loss: 0.0626 - val_accuracy: 0.9830\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 0.0626 - accuracy: 0.9830\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 15s 376ms/step - loss: 0.5442 - accuracy: 0.6779 - val_loss: 0.1471 - val_accuracy: 0.9710\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 15s 371ms/step - loss: 0.0916 - accuracy: 0.9705 - val_loss: 0.0744 - val_accuracy: 0.9800\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 15s 370ms/step - loss: 0.0864 - accuracy: 0.9705 - val_loss: 0.0581 - val_accuracy: 0.9800\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 15s 370ms/step - loss: 0.0481 - accuracy: 0.9829 - val_loss: 0.0608 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 15s 370ms/step - loss: 0.0536 - accuracy: 0.9855 - val_loss: 0.0478 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 15s 368ms/step - loss: 0.0465 - accuracy: 0.9842 - val_loss: 0.0517 - val_accuracy: 0.9850\n",
            "10/10 [==============================] - 1s 89ms/step - loss: 0.0517 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "40/40 [==============================] - 16s 377ms/step - loss: 0.6386 - accuracy: 0.6564 - val_loss: 0.1056 - val_accuracy: 0.9600\n",
            "Epoch 2/6\n",
            "40/40 [==============================] - 15s 369ms/step - loss: 0.0985 - accuracy: 0.9719 - val_loss: 0.0679 - val_accuracy: 0.9760\n",
            "Epoch 3/6\n",
            "40/40 [==============================] - 16s 400ms/step - loss: 0.0880 - accuracy: 0.9718 - val_loss: 0.0575 - val_accuracy: 0.9810\n",
            "Epoch 4/6\n",
            "40/40 [==============================] - 15s 367ms/step - loss: 0.0525 - accuracy: 0.9834 - val_loss: 0.0522 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "40/40 [==============================] - 16s 393ms/step - loss: 0.0411 - accuracy: 0.9862 - val_loss: 0.0526 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "40/40 [==============================] - 15s 371ms/step - loss: 0.0449 - accuracy: 0.9858 - val_loss: 0.0499 - val_accuracy: 0.9860\n",
            "10/10 [==============================] - 1s 98ms/step - loss: 0.0499 - accuracy: 0.9860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boxes': [<matplotlib.lines.Line2D at 0x7f142fb0c588>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1431880320>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd71748>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fbf70b8>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14329a3b38>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7f142fe0fa58>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fe0f978>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1431880390>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1431937470>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fbf7668>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fbf7710>,\n",
              "  <matplotlib.lines.Line2D at 0x7f143299b828>,\n",
              "  <matplotlib.lines.Line2D at 0x7f143299b668>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fbeb2b0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fbeb048>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7f142fe0f240>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd71828>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fbf77b8>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14329a3ef0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fbeb8d0>],\n",
              " 'means': [],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7f142fe0fda0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1431937240>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fbf7d68>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14329a3780>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fbeb6d8>],\n",
              " 'whiskers': [<matplotlib.lines.Line2D at 0x7f142fb0c0f0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fb0cf60>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14318807f0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1431880b00>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd71710>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd71588>,\n",
              "  <matplotlib.lines.Line2D at 0x7f143299bfd0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f143299b588>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14329a35c0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14329a30b8>]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1R-hpOgZw4o"
      },
      "source": [
        "A kernel size of 3 seems fine (less variation and not much of a mean difference in accuracy across kernel sizes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyEZ-oQZZ4uf"
      },
      "source": [
        "Batch Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J_43t947Z7E-",
        "outputId": "9b7ae8bf-85f9-4a62-fee5-fc48f7c1c22c"
      },
      "source": [
        "#list of batch sizes to be tested.\r\n",
        "batch = [8, 16, 32, 64, 128, 256]\r\n",
        "\r\n",
        "#initiate accuracy list.\r\n",
        "batch_accuracy = []*6\r\n",
        "\r\n",
        "#repeat following steps for each batch size.\r\n",
        "for i in range(len(batch)):\r\n",
        "  accuracy = buildmultiple(128, 3, 6, batch[i])\r\n",
        "  batch_accuracy.append(accuracy)  \r\n",
        "\r\n",
        "#boxplot of the accuracy scores against the corresponding batch sizes \r\n",
        "#investigated. \r\n",
        "plt.boxplot(batch_accuracy, labels = batch)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "500/500 [==============================] - 12s 23ms/step - loss: 0.3230 - accuracy: 0.8212 - val_loss: 0.0649 - val_accuracy: 0.9790\n",
            "Epoch 2/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0636 - accuracy: 0.9774 - val_loss: 0.0459 - val_accuracy: 0.9890\n",
            "Epoch 3/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0429 - accuracy: 0.9830 - val_loss: 0.0531 - val_accuracy: 0.9810\n",
            "Epoch 4/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0342 - accuracy: 0.9878 - val_loss: 0.0449 - val_accuracy: 0.9920\n",
            "Epoch 5/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0296 - accuracy: 0.9918 - val_loss: 0.0373 - val_accuracy: 0.9890\n",
            "Epoch 6/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0215 - accuracy: 0.9946 - val_loss: 0.0419 - val_accuracy: 0.9920\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0419 - accuracy: 0.9920\n",
            "Epoch 1/6\n",
            "500/500 [==============================] - 12s 23ms/step - loss: 0.3161 - accuracy: 0.8293 - val_loss: 0.0665 - val_accuracy: 0.9770\n",
            "Epoch 2/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0613 - accuracy: 0.9804 - val_loss: 0.0468 - val_accuracy: 0.9860\n",
            "Epoch 3/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0552 - accuracy: 0.9864 - val_loss: 0.0415 - val_accuracy: 0.9910\n",
            "Epoch 4/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0352 - accuracy: 0.9882 - val_loss: 0.0405 - val_accuracy: 0.9920\n",
            "Epoch 5/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0331 - accuracy: 0.9911 - val_loss: 0.0453 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0248 - accuracy: 0.9909 - val_loss: 0.0410 - val_accuracy: 0.9900\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0410 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "500/500 [==============================] - 12s 22ms/step - loss: 0.2706 - accuracy: 0.8744 - val_loss: 0.0499 - val_accuracy: 0.9890\n",
            "Epoch 2/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0522 - accuracy: 0.9849 - val_loss: 0.0440 - val_accuracy: 0.9890\n",
            "Epoch 3/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0444 - accuracy: 0.9892 - val_loss: 0.0591 - val_accuracy: 0.9910\n",
            "Epoch 4/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0320 - accuracy: 0.9885 - val_loss: 0.0377 - val_accuracy: 0.9910\n",
            "Epoch 5/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0330 - accuracy: 0.9893 - val_loss: 0.0356 - val_accuracy: 0.9920\n",
            "Epoch 6/6\n",
            "500/500 [==============================] - 12s 25ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.0338 - val_accuracy: 0.9910\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0338 - accuracy: 0.9910\n",
            "Epoch 1/6\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.2401 - accuracy: 0.9017 - val_loss: 0.0944 - val_accuracy: 0.9710\n",
            "Epoch 2/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0499 - accuracy: 0.9833 - val_loss: 0.1172 - val_accuracy: 0.9730\n",
            "Epoch 3/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0523 - accuracy: 0.9833 - val_loss: 0.0482 - val_accuracy: 0.9900\n",
            "Epoch 4/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0457 - accuracy: 0.9853 - val_loss: 0.0446 - val_accuracy: 0.9870\n",
            "Epoch 5/6\n",
            "500/500 [==============================] - 12s 24ms/step - loss: 0.0361 - accuracy: 0.9895 - val_loss: 0.0390 - val_accuracy: 0.9890\n",
            "Epoch 6/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0309 - accuracy: 0.9909 - val_loss: 0.0454 - val_accuracy: 0.9850\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0454 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "500/500 [==============================] - 12s 23ms/step - loss: 0.2924 - accuracy: 0.8680 - val_loss: 0.0515 - val_accuracy: 0.9860\n",
            "Epoch 2/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0579 - accuracy: 0.9806 - val_loss: 0.0501 - val_accuracy: 0.9860\n",
            "Epoch 3/6\n",
            "500/500 [==============================] - 11s 23ms/step - loss: 0.0427 - accuracy: 0.9847 - val_loss: 0.0362 - val_accuracy: 0.9880\n",
            "Epoch 4/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0498 - accuracy: 0.9841 - val_loss: 0.0373 - val_accuracy: 0.9890\n",
            "Epoch 5/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0290 - accuracy: 0.9909 - val_loss: 0.0335 - val_accuracy: 0.9930\n",
            "Epoch 6/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0368 - accuracy: 0.9868 - val_loss: 0.0357 - val_accuracy: 0.9930\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0357 - accuracy: 0.9930\n",
            "Epoch 1/6\n",
            "500/500 [==============================] - 12s 23ms/step - loss: 0.3460 - accuracy: 0.8216 - val_loss: 0.0728 - val_accuracy: 0.9810\n",
            "Epoch 2/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0550 - accuracy: 0.9807 - val_loss: 0.0589 - val_accuracy: 0.9860\n",
            "Epoch 3/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0589 - accuracy: 0.9793 - val_loss: 0.0465 - val_accuracy: 0.9870\n",
            "Epoch 4/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0473 - accuracy: 0.9851 - val_loss: 0.0331 - val_accuracy: 0.9910\n",
            "Epoch 5/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0277 - accuracy: 0.9905 - val_loss: 0.0397 - val_accuracy: 0.9910\n",
            "Epoch 6/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0295 - accuracy: 0.9921 - val_loss: 0.0378 - val_accuracy: 0.9900\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0378 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "500/500 [==============================] - 12s 23ms/step - loss: 0.3007 - accuracy: 0.8566 - val_loss: 0.0797 - val_accuracy: 0.9700\n",
            "Epoch 2/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0683 - accuracy: 0.9777 - val_loss: 0.0438 - val_accuracy: 0.9890\n",
            "Epoch 3/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0439 - accuracy: 0.9844 - val_loss: 0.0529 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0348 - accuracy: 0.9906 - val_loss: 0.0563 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0347 - accuracy: 0.9881 - val_loss: 0.0338 - val_accuracy: 0.9890\n",
            "Epoch 6/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0296 - accuracy: 0.9909 - val_loss: 0.0435 - val_accuracy: 0.9910\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0435 - accuracy: 0.9910\n",
            "Epoch 1/6\n",
            "500/500 [==============================] - 12s 23ms/step - loss: 0.3088 - accuracy: 0.8541 - val_loss: 0.0612 - val_accuracy: 0.9850\n",
            "Epoch 2/6\n",
            "500/500 [==============================] - 13s 25ms/step - loss: 0.0558 - accuracy: 0.9829 - val_loss: 0.0531 - val_accuracy: 0.9860\n",
            "Epoch 3/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0531 - accuracy: 0.9790 - val_loss: 0.0451 - val_accuracy: 0.9880\n",
            "Epoch 4/6\n",
            "500/500 [==============================] - 11s 23ms/step - loss: 0.0690 - accuracy: 0.9785 - val_loss: 0.0362 - val_accuracy: 0.9920\n",
            "Epoch 5/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0302 - accuracy: 0.9915 - val_loss: 0.0652 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0291 - accuracy: 0.9910 - val_loss: 0.0356 - val_accuracy: 0.9900\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0356 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "500/500 [==============================] - 12s 23ms/step - loss: 0.2962 - accuracy: 0.8519 - val_loss: 0.0565 - val_accuracy: 0.9850\n",
            "Epoch 2/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0555 - accuracy: 0.9783 - val_loss: 0.0587 - val_accuracy: 0.9820\n",
            "Epoch 3/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0434 - accuracy: 0.9857 - val_loss: 0.0446 - val_accuracy: 0.9890\n",
            "Epoch 4/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0281 - accuracy: 0.9897 - val_loss: 0.0433 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0332 - accuracy: 0.9910 - val_loss: 0.0464 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0343 - accuracy: 0.9882 - val_loss: 0.0363 - val_accuracy: 0.9910\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0363 - accuracy: 0.9910\n",
            "Epoch 1/6\n",
            "500/500 [==============================] - 12s 23ms/step - loss: 0.3137 - accuracy: 0.8664 - val_loss: 0.0622 - val_accuracy: 0.9880\n",
            "Epoch 2/6\n",
            "500/500 [==============================] - 12s 23ms/step - loss: 0.0605 - accuracy: 0.9833 - val_loss: 0.0439 - val_accuracy: 0.9880\n",
            "Epoch 3/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0538 - accuracy: 0.9835 - val_loss: 0.0410 - val_accuracy: 0.9900\n",
            "Epoch 4/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0439 - accuracy: 0.9883 - val_loss: 0.0581 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "500/500 [==============================] - 11s 22ms/step - loss: 0.0405 - accuracy: 0.9871 - val_loss: 0.0369 - val_accuracy: 0.9930\n",
            "Epoch 6/6\n",
            "500/500 [==============================] - 11s 23ms/step - loss: 0.0307 - accuracy: 0.9926 - val_loss: 0.0419 - val_accuracy: 0.9860\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0419 - accuracy: 0.9860\n",
            "Epoch 1/6\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.2901 - accuracy: 0.8873 - val_loss: 0.0661 - val_accuracy: 0.9790\n",
            "Epoch 2/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0492 - accuracy: 0.9838 - val_loss: 0.0430 - val_accuracy: 0.9890\n",
            "Epoch 3/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0449 - accuracy: 0.9844 - val_loss: 0.0435 - val_accuracy: 0.9920\n",
            "Epoch 4/6\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 0.0385 - accuracy: 0.9897 - val_loss: 0.0381 - val_accuracy: 0.9910\n",
            "Epoch 5/6\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.0293 - accuracy: 0.9906 - val_loss: 0.0518 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0401 - accuracy: 0.9835 - val_loss: 0.0445 - val_accuracy: 0.9890\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0445 - accuracy: 0.9890\n",
            "Epoch 1/6\n",
            "250/250 [==============================] - 9s 36ms/step - loss: 0.2692 - accuracy: 0.8709 - val_loss: 0.0589 - val_accuracy: 0.9840\n",
            "Epoch 2/6\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.0547 - accuracy: 0.9828 - val_loss: 0.0391 - val_accuracy: 0.9890\n",
            "Epoch 3/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0408 - accuracy: 0.9863 - val_loss: 0.0473 - val_accuracy: 0.9920\n",
            "Epoch 4/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0398 - accuracy: 0.9854 - val_loss: 0.0394 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0286 - accuracy: 0.9906 - val_loss: 0.0390 - val_accuracy: 0.9940\n",
            "Epoch 6/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 0.0425 - val_accuracy: 0.9860\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0425 - accuracy: 0.9860\n",
            "Epoch 1/6\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.3783 - accuracy: 0.7850 - val_loss: 0.0873 - val_accuracy: 0.9730\n",
            "Epoch 2/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0583 - accuracy: 0.9813 - val_loss: 0.0461 - val_accuracy: 0.9890\n",
            "Epoch 3/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0396 - accuracy: 0.9866 - val_loss: 0.0703 - val_accuracy: 0.9790\n",
            "Epoch 4/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0349 - accuracy: 0.9880 - val_loss: 0.0446 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0355 - accuracy: 0.9900 - val_loss: 0.0359 - val_accuracy: 0.9910\n",
            "Epoch 6/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0337 - accuracy: 0.9896 - val_loss: 0.0339 - val_accuracy: 0.9900\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0339 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.3710 - accuracy: 0.8146 - val_loss: 0.0693 - val_accuracy: 0.9810\n",
            "Epoch 2/6\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.0634 - accuracy: 0.9785 - val_loss: 0.0539 - val_accuracy: 0.9860\n",
            "Epoch 3/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0534 - accuracy: 0.9810 - val_loss: 0.0508 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0354 - accuracy: 0.9894 - val_loss: 0.0491 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0355 - accuracy: 0.9885 - val_loss: 0.0485 - val_accuracy: 0.9910\n",
            "Epoch 6/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0398 - accuracy: 0.9874 - val_loss: 0.0474 - val_accuracy: 0.9910\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0474 - accuracy: 0.9910\n",
            "Epoch 1/6\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.2966 - accuracy: 0.8803 - val_loss: 0.0635 - val_accuracy: 0.9820\n",
            "Epoch 2/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0627 - accuracy: 0.9785 - val_loss: 0.0661 - val_accuracy: 0.9820\n",
            "Epoch 3/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0580 - accuracy: 0.9776 - val_loss: 0.0553 - val_accuracy: 0.9840\n",
            "Epoch 4/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0475 - accuracy: 0.9833 - val_loss: 0.0511 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0478 - accuracy: 0.9840 - val_loss: 0.0422 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0312 - accuracy: 0.9920 - val_loss: 0.0447 - val_accuracy: 0.9900\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0447 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "250/250 [==============================] - 10s 36ms/step - loss: 0.3951 - accuracy: 0.7840 - val_loss: 0.0817 - val_accuracy: 0.9770\n",
            "Epoch 2/6\n",
            "250/250 [==============================] - 8s 33ms/step - loss: 0.0546 - accuracy: 0.9848 - val_loss: 0.0616 - val_accuracy: 0.9870\n",
            "Epoch 3/6\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 0.0616 - accuracy: 0.9786 - val_loss: 0.0509 - val_accuracy: 0.9860\n",
            "Epoch 4/6\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.0523 - accuracy: 0.9833 - val_loss: 0.0556 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0382 - accuracy: 0.9838 - val_loss: 0.0370 - val_accuracy: 0.9940\n",
            "Epoch 6/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0340 - accuracy: 0.9900 - val_loss: 0.0419 - val_accuracy: 0.9920\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0419 - accuracy: 0.9920\n",
            "Epoch 1/6\n",
            "250/250 [==============================] - 9s 36ms/step - loss: 0.3779 - accuracy: 0.8088 - val_loss: 0.0941 - val_accuracy: 0.9810\n",
            "Epoch 2/6\n",
            "250/250 [==============================] - 8s 34ms/step - loss: 0.0606 - accuracy: 0.9791 - val_loss: 0.0554 - val_accuracy: 0.9910\n",
            "Epoch 3/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0411 - accuracy: 0.9881 - val_loss: 0.0457 - val_accuracy: 0.9900\n",
            "Epoch 4/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0353 - accuracy: 0.9894 - val_loss: 0.0481 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0325 - accuracy: 0.9914 - val_loss: 0.0459 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0257 - accuracy: 0.9920 - val_loss: 0.0495 - val_accuracy: 0.9900\n",
            "63/63 [==============================] - 1s 10ms/step - loss: 0.0495 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "250/250 [==============================] - 10s 37ms/step - loss: 0.2894 - accuracy: 0.8814 - val_loss: 0.0609 - val_accuracy: 0.9840\n",
            "Epoch 2/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0663 - accuracy: 0.9777 - val_loss: 0.0419 - val_accuracy: 0.9870\n",
            "Epoch 3/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0458 - accuracy: 0.9873 - val_loss: 0.0545 - val_accuracy: 0.9870\n",
            "Epoch 4/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0389 - accuracy: 0.9874 - val_loss: 0.0454 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0331 - accuracy: 0.9898 - val_loss: 0.0443 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0398 - accuracy: 0.9870 - val_loss: 0.0368 - val_accuracy: 0.9910\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0368 - accuracy: 0.9910\n",
            "Epoch 1/6\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.3003 - accuracy: 0.8507 - val_loss: 0.0529 - val_accuracy: 0.9830\n",
            "Epoch 2/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0635 - accuracy: 0.9756 - val_loss: 0.0496 - val_accuracy: 0.9910\n",
            "Epoch 3/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0340 - accuracy: 0.9870 - val_loss: 0.0431 - val_accuracy: 0.9890\n",
            "Epoch 4/6\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.0395 - accuracy: 0.9890 - val_loss: 0.0403 - val_accuracy: 0.9890\n",
            "Epoch 5/6\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.0381 - accuracy: 0.9885 - val_loss: 0.0388 - val_accuracy: 0.9930\n",
            "Epoch 6/6\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.0449 - accuracy: 0.9866 - val_loss: 0.0646 - val_accuracy: 0.9760\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0646 - accuracy: 0.9760\n",
            "Epoch 1/6\n",
            "250/250 [==============================] - 10s 36ms/step - loss: 0.3261 - accuracy: 0.8438 - val_loss: 0.0703 - val_accuracy: 0.9760\n",
            "Epoch 2/6\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.0596 - accuracy: 0.9807 - val_loss: 0.0739 - val_accuracy: 0.9830\n",
            "Epoch 3/6\n",
            "250/250 [==============================] - 10s 39ms/step - loss: 0.0451 - accuracy: 0.9864 - val_loss: 0.0505 - val_accuracy: 0.9900\n",
            "Epoch 4/6\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.0334 - accuracy: 0.9863 - val_loss: 0.0667 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "250/250 [==============================] - 9s 35ms/step - loss: 0.0320 - accuracy: 0.9894 - val_loss: 0.0404 - val_accuracy: 0.9930\n",
            "Epoch 6/6\n",
            "250/250 [==============================] - 9s 34ms/step - loss: 0.0312 - accuracy: 0.9917 - val_loss: 0.0353 - val_accuracy: 0.9930\n",
            "63/63 [==============================] - 1s 8ms/step - loss: 0.0353 - accuracy: 0.9930\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3750 - accuracy: 0.8053 - val_loss: 0.0811 - val_accuracy: 0.9810\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0845 - accuracy: 0.9729 - val_loss: 0.0707 - val_accuracy: 0.9780\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0570 - accuracy: 0.9845 - val_loss: 0.0539 - val_accuracy: 0.9880\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0497 - accuracy: 0.9868 - val_loss: 0.0595 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0403 - accuracy: 0.9869 - val_loss: 0.0483 - val_accuracy: 0.9900\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0328 - accuracy: 0.9899 - val_loss: 0.0454 - val_accuracy: 0.9920\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0454 - accuracy: 0.9920\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.4466 - accuracy: 0.7797 - val_loss: 0.0802 - val_accuracy: 0.9750\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0804 - accuracy: 0.9717 - val_loss: 0.0585 - val_accuracy: 0.9850\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0444 - accuracy: 0.9856 - val_loss: 0.0650 - val_accuracy: 0.9910\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0411 - accuracy: 0.9863 - val_loss: 0.0591 - val_accuracy: 0.9910\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0468 - accuracy: 0.9841 - val_loss: 0.0412 - val_accuracy: 0.9910\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0316 - accuracy: 0.9918 - val_loss: 0.0463 - val_accuracy: 0.9910\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0463 - accuracy: 0.9910\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.4308 - accuracy: 0.7664 - val_loss: 0.0809 - val_accuracy: 0.9780\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0695 - accuracy: 0.9772 - val_loss: 0.0652 - val_accuracy: 0.9840\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0462 - accuracy: 0.9878 - val_loss: 0.0809 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0457 - accuracy: 0.9851 - val_loss: 0.0562 - val_accuracy: 0.9900\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0497 - accuracy: 0.9854 - val_loss: 0.0357 - val_accuracy: 0.9920\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0429 - accuracy: 0.9864 - val_loss: 0.0404 - val_accuracy: 0.9940\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0404 - accuracy: 0.9940\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 9s 65ms/step - loss: 0.3327 - accuracy: 0.8419 - val_loss: 0.1204 - val_accuracy: 0.9610\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0821 - accuracy: 0.9697 - val_loss: 0.0630 - val_accuracy: 0.9860\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0526 - accuracy: 0.9822 - val_loss: 0.0506 - val_accuracy: 0.9860\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0442 - accuracy: 0.9870 - val_loss: 0.0402 - val_accuracy: 0.9910\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0371 - accuracy: 0.9862 - val_loss: 0.0410 - val_accuracy: 0.9940\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0449 - accuracy: 0.9875 - val_loss: 0.0438 - val_accuracy: 0.9910\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0438 - accuracy: 0.9910\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.4630 - accuracy: 0.7361 - val_loss: 0.0953 - val_accuracy: 0.9770\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0761 - accuracy: 0.9779 - val_loss: 0.0603 - val_accuracy: 0.9820\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0514 - accuracy: 0.9853 - val_loss: 0.0714 - val_accuracy: 0.9800\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0412 - accuracy: 0.9873 - val_loss: 0.0609 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0442 - accuracy: 0.9869 - val_loss: 0.0415 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0495 - accuracy: 0.9858 - val_loss: 0.0528 - val_accuracy: 0.9920\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0528 - accuracy: 0.9920\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 9s 65ms/step - loss: 0.4937 - accuracy: 0.7458 - val_loss: 0.0763 - val_accuracy: 0.9760\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0837 - accuracy: 0.9669 - val_loss: 0.0716 - val_accuracy: 0.9850\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0572 - accuracy: 0.9805 - val_loss: 0.0554 - val_accuracy: 0.9890\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0342 - accuracy: 0.9894 - val_loss: 0.0496 - val_accuracy: 0.9870\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0588 - accuracy: 0.9811 - val_loss: 0.0446 - val_accuracy: 0.9900\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0398 - accuracy: 0.9882 - val_loss: 0.0420 - val_accuracy: 0.9910\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0420 - accuracy: 0.9910\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.5571 - accuracy: 0.6586 - val_loss: 0.0980 - val_accuracy: 0.9690\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 8s 60ms/step - loss: 0.0692 - accuracy: 0.9758 - val_loss: 0.0622 - val_accuracy: 0.9840\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0735 - accuracy: 0.9777 - val_loss: 0.0566 - val_accuracy: 0.9870\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0450 - accuracy: 0.9871 - val_loss: 0.0714 - val_accuracy: 0.9810\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0545 - accuracy: 0.9803 - val_loss: 0.0447 - val_accuracy: 0.9920\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0435 - accuracy: 0.9850 - val_loss: 0.0430 - val_accuracy: 0.9900\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0430 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 9s 65ms/step - loss: 0.5400 - accuracy: 0.7012 - val_loss: 0.1296 - val_accuracy: 0.9610\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0804 - accuracy: 0.9726 - val_loss: 0.0663 - val_accuracy: 0.9820\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0482 - accuracy: 0.9866 - val_loss: 0.0533 - val_accuracy: 0.9890\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0449 - accuracy: 0.9851 - val_loss: 0.0685 - val_accuracy: 0.9780\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0441 - accuracy: 0.9853 - val_loss: 0.0440 - val_accuracy: 0.9900\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 8s 60ms/step - loss: 0.0432 - accuracy: 0.9864 - val_loss: 0.0441 - val_accuracy: 0.9920\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0441 - accuracy: 0.9920\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.3622 - accuracy: 0.8092 - val_loss: 0.1046 - val_accuracy: 0.9750\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0739 - accuracy: 0.9755 - val_loss: 0.0539 - val_accuracy: 0.9860\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0485 - accuracy: 0.9814 - val_loss: 0.0458 - val_accuracy: 0.9870\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0358 - accuracy: 0.9898 - val_loss: 0.0496 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0348 - accuracy: 0.9909 - val_loss: 0.0417 - val_accuracy: 0.9890\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 8s 60ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 0.0447 - val_accuracy: 0.9930\n",
            "32/32 [==============================] - 0s 14ms/step - loss: 0.0447 - accuracy: 0.9930\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 9s 65ms/step - loss: 0.3477 - accuracy: 0.8382 - val_loss: 0.0814 - val_accuracy: 0.9830\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0635 - accuracy: 0.9802 - val_loss: 0.0530 - val_accuracy: 0.9850\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0519 - accuracy: 0.9846 - val_loss: 0.0428 - val_accuracy: 0.9920\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0408 - accuracy: 0.9863 - val_loss: 0.0443 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0394 - accuracy: 0.9871 - val_loss: 0.0447 - val_accuracy: 0.9910\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0348 - accuracy: 0.9917 - val_loss: 0.0436 - val_accuracy: 0.9890\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 0.0436 - accuracy: 0.9890\n",
            "Epoch 1/6\n",
            "63/63 [==============================] - 8s 112ms/step - loss: 0.5504 - accuracy: 0.7257 - val_loss: 0.1239 - val_accuracy: 0.9610\n",
            "Epoch 2/6\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.0899 - accuracy: 0.9712 - val_loss: 0.0864 - val_accuracy: 0.9760\n",
            "Epoch 3/6\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.0655 - accuracy: 0.9813 - val_loss: 0.0586 - val_accuracy: 0.9860\n",
            "Epoch 4/6\n",
            "63/63 [==============================] - 7s 108ms/step - loss: 0.0604 - accuracy: 0.9820 - val_loss: 0.0539 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.0412 - accuracy: 0.9876 - val_loss: 0.0457 - val_accuracy: 0.9920\n",
            "Epoch 6/6\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.0347 - accuracy: 0.9899 - val_loss: 0.0449 - val_accuracy: 0.9900\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0449 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "63/63 [==============================] - 8s 113ms/step - loss: 0.4520 - accuracy: 0.7772 - val_loss: 0.0970 - val_accuracy: 0.9800\n",
            "Epoch 2/6\n",
            "63/63 [==============================] - 6s 103ms/step - loss: 0.0776 - accuracy: 0.9715 - val_loss: 0.1120 - val_accuracy: 0.9660\n",
            "Epoch 3/6\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.0799 - accuracy: 0.9739 - val_loss: 0.0518 - val_accuracy: 0.9880\n",
            "Epoch 4/6\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.0464 - accuracy: 0.9830 - val_loss: 0.0462 - val_accuracy: 0.9900\n",
            "Epoch 5/6\n",
            "63/63 [==============================] - 6s 103ms/step - loss: 0.0348 - accuracy: 0.9901 - val_loss: 0.0582 - val_accuracy: 0.9890\n",
            "Epoch 6/6\n",
            "63/63 [==============================] - 6s 103ms/step - loss: 0.0433 - accuracy: 0.9855 - val_loss: 0.0425 - val_accuracy: 0.9890\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0425 - accuracy: 0.9890\n",
            "Epoch 1/6\n",
            "63/63 [==============================] - 7s 108ms/step - loss: 0.5158 - accuracy: 0.7421 - val_loss: 0.1203 - val_accuracy: 0.9690\n",
            "Epoch 2/6\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.0855 - accuracy: 0.9679 - val_loss: 0.0823 - val_accuracy: 0.9760\n",
            "Epoch 3/6\n",
            "63/63 [==============================] - 7s 105ms/step - loss: 0.0584 - accuracy: 0.9825 - val_loss: 0.0677 - val_accuracy: 0.9840\n",
            "Epoch 4/6\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.0542 - accuracy: 0.9837 - val_loss: 0.0685 - val_accuracy: 0.9810\n",
            "Epoch 5/6\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.0533 - accuracy: 0.9823 - val_loss: 0.0479 - val_accuracy: 0.9890\n",
            "Epoch 6/6\n",
            "63/63 [==============================] - 7s 105ms/step - loss: 0.0374 - accuracy: 0.9900 - val_loss: 0.0467 - val_accuracy: 0.9890\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0467 - accuracy: 0.9890\n",
            "Epoch 1/6\n",
            "63/63 [==============================] - 8s 111ms/step - loss: 0.5067 - accuracy: 0.7392 - val_loss: 0.1012 - val_accuracy: 0.9730\n",
            "Epoch 2/6\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.0837 - accuracy: 0.9698 - val_loss: 0.0728 - val_accuracy: 0.9840\n",
            "Epoch 3/6\n",
            "63/63 [==============================] - 7s 105ms/step - loss: 0.0777 - accuracy: 0.9728 - val_loss: 0.0591 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.0519 - accuracy: 0.9847 - val_loss: 0.0594 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.0426 - accuracy: 0.9851 - val_loss: 0.0456 - val_accuracy: 0.9900\n",
            "Epoch 6/6\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.0440 - accuracy: 0.9874 - val_loss: 0.0439 - val_accuracy: 0.9920\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0439 - accuracy: 0.9920\n",
            "Epoch 1/6\n",
            "63/63 [==============================] - 7s 108ms/step - loss: 0.4156 - accuracy: 0.8289 - val_loss: 0.0862 - val_accuracy: 0.9770\n",
            "Epoch 2/6\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.0711 - accuracy: 0.9785 - val_loss: 0.0650 - val_accuracy: 0.9840\n",
            "Epoch 3/6\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.0624 - accuracy: 0.9801 - val_loss: 0.0654 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.0543 - accuracy: 0.9784 - val_loss: 0.0615 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.0465 - accuracy: 0.9843 - val_loss: 0.0440 - val_accuracy: 0.9890\n",
            "Epoch 6/6\n",
            "63/63 [==============================] - 7s 109ms/step - loss: 0.0442 - accuracy: 0.9857 - val_loss: 0.0417 - val_accuracy: 0.9880\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0417 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "63/63 [==============================] - 7s 109ms/step - loss: 0.6394 - accuracy: 0.6127 - val_loss: 0.1727 - val_accuracy: 0.9470\n",
            "Epoch 2/6\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.1123 - accuracy: 0.9600 - val_loss: 0.0796 - val_accuracy: 0.9770\n",
            "Epoch 3/6\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.0813 - accuracy: 0.9710 - val_loss: 0.0622 - val_accuracy: 0.9840\n",
            "Epoch 4/6\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.0609 - accuracy: 0.9812 - val_loss: 0.0550 - val_accuracy: 0.9850\n",
            "Epoch 5/6\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.0528 - accuracy: 0.9838 - val_loss: 0.0529 - val_accuracy: 0.9890\n",
            "Epoch 6/6\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.0465 - accuracy: 0.9881 - val_loss: 0.0448 - val_accuracy: 0.9900\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0448 - accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "63/63 [==============================] - 8s 122ms/step - loss: 0.4226 - accuracy: 0.7797 - val_loss: 0.0737 - val_accuracy: 0.9760\n",
            "Epoch 2/6\n",
            "63/63 [==============================] - 7s 107ms/step - loss: 0.0797 - accuracy: 0.9738 - val_loss: 0.0641 - val_accuracy: 0.9830\n",
            "Epoch 3/6\n",
            "63/63 [==============================] - 7s 105ms/step - loss: 0.0594 - accuracy: 0.9826 - val_loss: 0.0495 - val_accuracy: 0.9890\n",
            "Epoch 4/6\n",
            "63/63 [==============================] - 7s 105ms/step - loss: 0.0362 - accuracy: 0.9885 - val_loss: 0.0534 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "63/63 [==============================] - 7s 108ms/step - loss: 0.0366 - accuracy: 0.9846 - val_loss: 0.0541 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "63/63 [==============================] - 6s 103ms/step - loss: 0.0379 - accuracy: 0.9870 - val_loss: 0.0450 - val_accuracy: 0.9890\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0450 - accuracy: 0.9890\n",
            "Epoch 1/6\n",
            "63/63 [==============================] - 7s 108ms/step - loss: 0.5613 - accuracy: 0.6603 - val_loss: 0.1411 - val_accuracy: 0.9590\n",
            "Epoch 2/6\n",
            "63/63 [==============================] - 7s 103ms/step - loss: 0.0848 - accuracy: 0.9700 - val_loss: 0.0738 - val_accuracy: 0.9850\n",
            "Epoch 3/6\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.0593 - accuracy: 0.9800 - val_loss: 0.0698 - val_accuracy: 0.9840\n",
            "Epoch 4/6\n",
            "63/63 [==============================] - 6s 103ms/step - loss: 0.0586 - accuracy: 0.9800 - val_loss: 0.0757 - val_accuracy: 0.9790\n",
            "Epoch 5/6\n",
            "63/63 [==============================] - 6s 103ms/step - loss: 0.0671 - accuracy: 0.9780 - val_loss: 0.0512 - val_accuracy: 0.9910\n",
            "Epoch 6/6\n",
            "63/63 [==============================] - 6s 103ms/step - loss: 0.0403 - accuracy: 0.9859 - val_loss: 0.0539 - val_accuracy: 0.9850\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0539 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "63/63 [==============================] - 7s 109ms/step - loss: 0.4666 - accuracy: 0.8195 - val_loss: 0.0939 - val_accuracy: 0.9690\n",
            "Epoch 2/6\n",
            "63/63 [==============================] - 6s 103ms/step - loss: 0.0812 - accuracy: 0.9670 - val_loss: 0.0732 - val_accuracy: 0.9850\n",
            "Epoch 3/6\n",
            "63/63 [==============================] - 7s 104ms/step - loss: 0.0592 - accuracy: 0.9829 - val_loss: 0.0637 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "63/63 [==============================] - 6s 103ms/step - loss: 0.0532 - accuracy: 0.9830 - val_loss: 0.0610 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.0440 - accuracy: 0.9858 - val_loss: 0.0518 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "63/63 [==============================] - 6s 103ms/step - loss: 0.0401 - accuracy: 0.9832 - val_loss: 0.0493 - val_accuracy: 0.9910\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0493 - accuracy: 0.9910\n",
            "Epoch 1/6\n",
            "63/63 [==============================] - 7s 109ms/step - loss: 0.4631 - accuracy: 0.7364 - val_loss: 0.0984 - val_accuracy: 0.9700\n",
            "Epoch 2/6\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.0763 - accuracy: 0.9710 - val_loss: 0.0653 - val_accuracy: 0.9840\n",
            "Epoch 3/6\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.0659 - accuracy: 0.9758 - val_loss: 0.0589 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "63/63 [==============================] - 7s 111ms/step - loss: 0.0544 - accuracy: 0.9789 - val_loss: 0.0492 - val_accuracy: 0.9890\n",
            "Epoch 5/6\n",
            "63/63 [==============================] - 7s 109ms/step - loss: 0.0397 - accuracy: 0.9880 - val_loss: 0.0489 - val_accuracy: 0.9900\n",
            "Epoch 6/6\n",
            "63/63 [==============================] - 7s 106ms/step - loss: 0.0270 - accuracy: 0.9908 - val_loss: 0.0467 - val_accuracy: 0.9890\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0467 - accuracy: 0.9890\n",
            "Epoch 1/6\n",
            "32/32 [==============================] - 7s 201ms/step - loss: 0.5963 - accuracy: 0.6389 - val_loss: 0.1523 - val_accuracy: 0.9510\n",
            "Epoch 2/6\n",
            "32/32 [==============================] - 6s 192ms/step - loss: 0.1418 - accuracy: 0.9553 - val_loss: 0.1345 - val_accuracy: 0.9660\n",
            "Epoch 3/6\n",
            "32/32 [==============================] - 7s 219ms/step - loss: 0.0971 - accuracy: 0.9658 - val_loss: 0.0679 - val_accuracy: 0.9800\n",
            "Epoch 4/6\n",
            "32/32 [==============================] - 6s 201ms/step - loss: 0.0698 - accuracy: 0.9756 - val_loss: 0.0601 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "32/32 [==============================] - 6s 198ms/step - loss: 0.0753 - accuracy: 0.9774 - val_loss: 0.0614 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "32/32 [==============================] - 6s 192ms/step - loss: 0.0683 - accuracy: 0.9788 - val_loss: 0.0685 - val_accuracy: 0.9790\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0685 - accuracy: 0.9790\n",
            "Epoch 1/6\n",
            "32/32 [==============================] - 7s 203ms/step - loss: 0.6891 - accuracy: 0.6090 - val_loss: 0.5140 - val_accuracy: 0.9240\n",
            "Epoch 2/6\n",
            "32/32 [==============================] - 6s 192ms/step - loss: 0.3119 - accuracy: 0.9359 - val_loss: 0.1162 - val_accuracy: 0.9630\n",
            "Epoch 3/6\n",
            "32/32 [==============================] - 6s 193ms/step - loss: 0.1110 - accuracy: 0.9600 - val_loss: 0.0823 - val_accuracy: 0.9780\n",
            "Epoch 4/6\n",
            "32/32 [==============================] - 6s 190ms/step - loss: 0.0763 - accuracy: 0.9736 - val_loss: 0.0755 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "32/32 [==============================] - 6s 190ms/step - loss: 0.0666 - accuracy: 0.9771 - val_loss: 0.0608 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "32/32 [==============================] - 6s 192ms/step - loss: 0.0697 - accuracy: 0.9769 - val_loss: 0.0627 - val_accuracy: 0.9850\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0627 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "32/32 [==============================] - 7s 200ms/step - loss: 0.6577 - accuracy: 0.5858 - val_loss: 0.3390 - val_accuracy: 0.9560\n",
            "Epoch 2/6\n",
            "32/32 [==============================] - 6s 195ms/step - loss: 0.1719 - accuracy: 0.9496 - val_loss: 0.0977 - val_accuracy: 0.9710\n",
            "Epoch 3/6\n",
            "32/32 [==============================] - 6s 191ms/step - loss: 0.0798 - accuracy: 0.9692 - val_loss: 0.0879 - val_accuracy: 0.9740\n",
            "Epoch 4/6\n",
            "32/32 [==============================] - 6s 194ms/step - loss: 0.0842 - accuracy: 0.9763 - val_loss: 0.0939 - val_accuracy: 0.9720\n",
            "Epoch 5/6\n",
            "32/32 [==============================] - 6s 190ms/step - loss: 0.0797 - accuracy: 0.9755 - val_loss: 0.0607 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "32/32 [==============================] - 6s 196ms/step - loss: 0.0444 - accuracy: 0.9861 - val_loss: 0.0682 - val_accuracy: 0.9870\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0682 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "32/32 [==============================] - 7s 200ms/step - loss: 0.5515 - accuracy: 0.7018 - val_loss: 0.1297 - val_accuracy: 0.9560\n",
            "Epoch 2/6\n",
            "32/32 [==============================] - 6s 193ms/step - loss: 0.1268 - accuracy: 0.9573 - val_loss: 0.1009 - val_accuracy: 0.9760\n",
            "Epoch 3/6\n",
            "32/32 [==============================] - 6s 192ms/step - loss: 0.0691 - accuracy: 0.9748 - val_loss: 0.0651 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "32/32 [==============================] - 6s 191ms/step - loss: 0.0715 - accuracy: 0.9759 - val_loss: 0.0805 - val_accuracy: 0.9760\n",
            "Epoch 5/6\n",
            "32/32 [==============================] - 6s 192ms/step - loss: 0.0683 - accuracy: 0.9767 - val_loss: 0.0674 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "32/32 [==============================] - 6s 192ms/step - loss: 0.0569 - accuracy: 0.9853 - val_loss: 0.0557 - val_accuracy: 0.9870\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0557 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "32/32 [==============================] - 7s 199ms/step - loss: 0.6206 - accuracy: 0.6909 - val_loss: 0.1912 - val_accuracy: 0.9580\n",
            "Epoch 2/6\n",
            "32/32 [==============================] - 6s 196ms/step - loss: 0.1293 - accuracy: 0.9574 - val_loss: 0.0833 - val_accuracy: 0.9750\n",
            "Epoch 3/6\n",
            "32/32 [==============================] - 6s 190ms/step - loss: 0.0712 - accuracy: 0.9727 - val_loss: 0.0686 - val_accuracy: 0.9820\n",
            "Epoch 4/6\n",
            "32/32 [==============================] - 6s 192ms/step - loss: 0.0649 - accuracy: 0.9778 - val_loss: 0.0605 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "32/32 [==============================] - 6s 192ms/step - loss: 0.0696 - accuracy: 0.9771 - val_loss: 0.0581 - val_accuracy: 0.9860\n",
            "Epoch 6/6\n",
            "32/32 [==============================] - 6s 190ms/step - loss: 0.0507 - accuracy: 0.9843 - val_loss: 0.0569 - val_accuracy: 0.9870\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.0569 - accuracy: 0.9870\n",
            "Epoch 1/6\n",
            "32/32 [==============================] - 7s 199ms/step - loss: 0.6244 - accuracy: 0.6177 - val_loss: 0.2063 - val_accuracy: 0.9560\n",
            "Epoch 2/6\n",
            "32/32 [==============================] - 6s 193ms/step - loss: 0.1247 - accuracy: 0.9559 - val_loss: 0.1227 - val_accuracy: 0.9690\n",
            "Epoch 3/6\n",
            "32/32 [==============================] - 6s 190ms/step - loss: 0.0822 - accuracy: 0.9728 - val_loss: 0.0752 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "32/32 [==============================] - 6s 191ms/step - loss: 0.0680 - accuracy: 0.9790 - val_loss: 0.0631 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "32/32 [==============================] - 6s 190ms/step - loss: 0.0543 - accuracy: 0.9812 - val_loss: 0.0698 - val_accuracy: 0.9760\n",
            "Epoch 6/6\n",
            "32/32 [==============================] - 6s 190ms/step - loss: 0.0621 - accuracy: 0.9792 - val_loss: 0.0613 - val_accuracy: 0.9840\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.0613 - accuracy: 0.9840\n",
            "Epoch 1/6\n",
            "32/32 [==============================] - 7s 206ms/step - loss: 0.6205 - accuracy: 0.6362 - val_loss: 0.2210 - val_accuracy: 0.9460\n",
            "Epoch 2/6\n",
            "32/32 [==============================] - 6s 193ms/step - loss: 0.1667 - accuracy: 0.9438 - val_loss: 0.1546 - val_accuracy: 0.9650\n",
            "Epoch 3/6\n",
            "32/32 [==============================] - 6s 193ms/step - loss: 0.0994 - accuracy: 0.9639 - val_loss: 0.0877 - val_accuracy: 0.9790\n",
            "Epoch 4/6\n",
            "32/32 [==============================] - 6s 193ms/step - loss: 0.0901 - accuracy: 0.9733 - val_loss: 0.0652 - val_accuracy: 0.9820\n",
            "Epoch 5/6\n",
            "32/32 [==============================] - 6s 192ms/step - loss: 0.0593 - accuracy: 0.9784 - val_loss: 0.0659 - val_accuracy: 0.9820\n",
            "Epoch 6/6\n",
            "32/32 [==============================] - 6s 192ms/step - loss: 0.0541 - accuracy: 0.9813 - val_loss: 0.0573 - val_accuracy: 0.9850\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.0573 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "32/32 [==============================] - 7s 200ms/step - loss: 0.6561 - accuracy: 0.6076 - val_loss: 0.2984 - val_accuracy: 0.9530\n",
            "Epoch 2/6\n",
            "32/32 [==============================] - 7s 216ms/step - loss: 0.1529 - accuracy: 0.9488 - val_loss: 0.0876 - val_accuracy: 0.9710\n",
            "Epoch 3/6\n",
            "32/32 [==============================] - 6s 196ms/step - loss: 0.0942 - accuracy: 0.9661 - val_loss: 0.0753 - val_accuracy: 0.9800\n",
            "Epoch 4/6\n",
            "32/32 [==============================] - 6s 194ms/step - loss: 0.0620 - accuracy: 0.9758 - val_loss: 0.0666 - val_accuracy: 0.9830\n",
            "Epoch 5/6\n",
            "32/32 [==============================] - 6s 193ms/step - loss: 0.0584 - accuracy: 0.9830 - val_loss: 0.0721 - val_accuracy: 0.9780\n",
            "Epoch 6/6\n",
            "32/32 [==============================] - 6s 193ms/step - loss: 0.0621 - accuracy: 0.9809 - val_loss: 0.0737 - val_accuracy: 0.9750\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.0737 - accuracy: 0.9750\n",
            "Epoch 1/6\n",
            "32/32 [==============================] - 7s 207ms/step - loss: 0.7016 - accuracy: 0.5653 - val_loss: 0.5590 - val_accuracy: 0.8820\n",
            "Epoch 2/6\n",
            "32/32 [==============================] - 6s 193ms/step - loss: 0.3542 - accuracy: 0.9256 - val_loss: 0.1378 - val_accuracy: 0.9560\n",
            "Epoch 3/6\n",
            "32/32 [==============================] - 6s 192ms/step - loss: 0.1130 - accuracy: 0.9586 - val_loss: 0.0850 - val_accuracy: 0.9760\n",
            "Epoch 4/6\n",
            "32/32 [==============================] - 6s 195ms/step - loss: 0.0704 - accuracy: 0.9762 - val_loss: 0.0844 - val_accuracy: 0.9810\n",
            "Epoch 5/6\n",
            "32/32 [==============================] - 6s 192ms/step - loss: 0.0637 - accuracy: 0.9783 - val_loss: 0.0697 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "32/32 [==============================] - 6s 191ms/step - loss: 0.0589 - accuracy: 0.9837 - val_loss: 0.0587 - val_accuracy: 0.9860\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0587 - accuracy: 0.9860\n",
            "Epoch 1/6\n",
            "32/32 [==============================] - 7s 201ms/step - loss: 0.6081 - accuracy: 0.6767 - val_loss: 0.2199 - val_accuracy: 0.9400\n",
            "Epoch 2/6\n",
            "32/32 [==============================] - 6s 191ms/step - loss: 0.1317 - accuracy: 0.9550 - val_loss: 0.0940 - val_accuracy: 0.9760\n",
            "Epoch 3/6\n",
            "32/32 [==============================] - 6s 194ms/step - loss: 0.0766 - accuracy: 0.9779 - val_loss: 0.0718 - val_accuracy: 0.9830\n",
            "Epoch 4/6\n",
            "32/32 [==============================] - 6s 191ms/step - loss: 0.0601 - accuracy: 0.9796 - val_loss: 0.0625 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "32/32 [==============================] - 6s 190ms/step - loss: 0.0644 - accuracy: 0.9812 - val_loss: 0.0574 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "32/32 [==============================] - 6s 191ms/step - loss: 0.0522 - accuracy: 0.9820 - val_loss: 0.0533 - val_accuracy: 0.9880\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.0533 - accuracy: 0.9880\n",
            "Epoch 1/6\n",
            "16/16 [==============================] - 7s 388ms/step - loss: 0.5988 - accuracy: 0.6891 - val_loss: 0.3102 - val_accuracy: 0.9540\n",
            "Epoch 2/6\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.1725 - accuracy: 0.9492 - val_loss: 0.1077 - val_accuracy: 0.9620\n",
            "Epoch 3/6\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.1001 - accuracy: 0.9576 - val_loss: 0.0777 - val_accuracy: 0.9760\n",
            "Epoch 4/6\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.0730 - accuracy: 0.9747 - val_loss: 0.0671 - val_accuracy: 0.9840\n",
            "Epoch 5/6\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.0553 - accuracy: 0.9853 - val_loss: 0.0619 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "16/16 [==============================] - 6s 364ms/step - loss: 0.0574 - accuracy: 0.9820 - val_loss: 0.0594 - val_accuracy: 0.9860\n",
            "4/4 [==============================] - 0s 88ms/step - loss: 0.0594 - accuracy: 0.9860\n",
            "Epoch 1/6\n",
            "16/16 [==============================] - 7s 378ms/step - loss: 0.6735 - accuracy: 0.6016 - val_loss: 0.5539 - val_accuracy: 0.9540\n",
            "Epoch 2/6\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.3790 - accuracy: 0.9392 - val_loss: 0.1711 - val_accuracy: 0.9550\n",
            "Epoch 3/6\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.1302 - accuracy: 0.9542 - val_loss: 0.1041 - val_accuracy: 0.9640\n",
            "Epoch 4/6\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.0776 - accuracy: 0.9698 - val_loss: 0.0816 - val_accuracy: 0.9750\n",
            "Epoch 5/6\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.0668 - accuracy: 0.9752 - val_loss: 0.0718 - val_accuracy: 0.9820\n",
            "Epoch 6/6\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.0603 - accuracy: 0.9841 - val_loss: 0.0657 - val_accuracy: 0.9840\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 0.0657 - accuracy: 0.9840\n",
            "Epoch 1/6\n",
            "16/16 [==============================] - 7s 390ms/step - loss: 0.6797 - accuracy: 0.5821 - val_loss: 0.5780 - val_accuracy: 0.9250\n",
            "Epoch 2/6\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.4045 - accuracy: 0.9064 - val_loss: 0.1646 - val_accuracy: 0.9590\n",
            "Epoch 3/6\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.1230 - accuracy: 0.9536 - val_loss: 0.0936 - val_accuracy: 0.9650\n",
            "Epoch 4/6\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.1048 - accuracy: 0.9587 - val_loss: 0.0878 - val_accuracy: 0.9720\n",
            "Epoch 5/6\n",
            "16/16 [==============================] - 6s 409ms/step - loss: 0.0715 - accuracy: 0.9739 - val_loss: 0.0804 - val_accuracy: 0.9810\n",
            "Epoch 6/6\n",
            "16/16 [==============================] - 6s 368ms/step - loss: 0.0693 - accuracy: 0.9751 - val_loss: 0.0673 - val_accuracy: 0.9820\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 0.0673 - accuracy: 0.9820\n",
            "Epoch 1/6\n",
            "16/16 [==============================] - 7s 381ms/step - loss: 0.6830 - accuracy: 0.5435 - val_loss: 0.5803 - val_accuracy: 0.8790\n",
            "Epoch 2/6\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.4055 - accuracy: 0.9212 - val_loss: 0.1570 - val_accuracy: 0.9580\n",
            "Epoch 3/6\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.1203 - accuracy: 0.9566 - val_loss: 0.1081 - val_accuracy: 0.9680\n",
            "Epoch 4/6\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.0880 - accuracy: 0.9662 - val_loss: 0.0737 - val_accuracy: 0.9820\n",
            "Epoch 5/6\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.0702 - accuracy: 0.9802 - val_loss: 0.0901 - val_accuracy: 0.9750\n",
            "Epoch 6/6\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.0706 - accuracy: 0.9775 - val_loss: 0.0718 - val_accuracy: 0.9840\n",
            "4/4 [==============================] - 0s 86ms/step - loss: 0.0718 - accuracy: 0.9840\n",
            "Epoch 1/6\n",
            "16/16 [==============================] - 6s 376ms/step - loss: 0.6501 - accuracy: 0.6275 - val_loss: 0.4406 - val_accuracy: 0.9240\n",
            "Epoch 2/6\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.2557 - accuracy: 0.9415 - val_loss: 0.1506 - val_accuracy: 0.9480\n",
            "Epoch 3/6\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.1328 - accuracy: 0.9495 - val_loss: 0.0855 - val_accuracy: 0.9690\n",
            "Epoch 4/6\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.0815 - accuracy: 0.9698 - val_loss: 0.0774 - val_accuracy: 0.9790\n",
            "Epoch 5/6\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.0629 - accuracy: 0.9789 - val_loss: 0.0708 - val_accuracy: 0.9840\n",
            "Epoch 6/6\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.0614 - accuracy: 0.9794 - val_loss: 0.0627 - val_accuracy: 0.9840\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 0.0627 - accuracy: 0.9840\n",
            "Epoch 1/6\n",
            "16/16 [==============================] - 6s 377ms/step - loss: 0.7176 - accuracy: 0.5361 - val_loss: 0.6681 - val_accuracy: 0.5600\n",
            "Epoch 2/6\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.6280 - accuracy: 0.6014 - val_loss: 0.5204 - val_accuracy: 0.9060\n",
            "Epoch 3/6\n",
            "16/16 [==============================] - 6s 357ms/step - loss: 0.3506 - accuracy: 0.9334 - val_loss: 0.1743 - val_accuracy: 0.9550\n",
            "Epoch 4/6\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.1390 - accuracy: 0.9495 - val_loss: 0.0986 - val_accuracy: 0.9620\n",
            "Epoch 5/6\n",
            "16/16 [==============================] - 6s 369ms/step - loss: 0.0919 - accuracy: 0.9682 - val_loss: 0.0804 - val_accuracy: 0.9740\n",
            "Epoch 6/6\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.0831 - accuracy: 0.9718 - val_loss: 0.0749 - val_accuracy: 0.9800\n",
            "4/4 [==============================] - 0s 87ms/step - loss: 0.0749 - accuracy: 0.9800\n",
            "Epoch 1/6\n",
            "16/16 [==============================] - 7s 388ms/step - loss: 0.6852 - accuracy: 0.5327 - val_loss: 0.6206 - val_accuracy: 0.6360\n",
            "Epoch 2/6\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.4952 - accuracy: 0.8101 - val_loss: 0.2634 - val_accuracy: 0.9480\n",
            "Epoch 3/6\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.1582 - accuracy: 0.9519 - val_loss: 0.1138 - val_accuracy: 0.9610\n",
            "Epoch 4/6\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.1048 - accuracy: 0.9588 - val_loss: 0.0996 - val_accuracy: 0.9760\n",
            "Epoch 5/6\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.0818 - accuracy: 0.9731 - val_loss: 0.0713 - val_accuracy: 0.9820\n",
            "Epoch 6/6\n",
            "16/16 [==============================] - 6s 366ms/step - loss: 0.0606 - accuracy: 0.9798 - val_loss: 0.0675 - val_accuracy: 0.9850\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 0.0675 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "16/16 [==============================] - 7s 379ms/step - loss: 0.6398 - accuracy: 0.6411 - val_loss: 0.4097 - val_accuracy: 0.9570\n",
            "Epoch 2/6\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.2381 - accuracy: 0.9425 - val_loss: 0.1175 - val_accuracy: 0.9590\n",
            "Epoch 3/6\n",
            "16/16 [==============================] - 6s 355ms/step - loss: 0.0966 - accuracy: 0.9638 - val_loss: 0.0798 - val_accuracy: 0.9720\n",
            "Epoch 4/6\n",
            "16/16 [==============================] - 6s 372ms/step - loss: 0.0805 - accuracy: 0.9688 - val_loss: 0.0700 - val_accuracy: 0.9820\n",
            "Epoch 5/6\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.0618 - accuracy: 0.9796 - val_loss: 0.0669 - val_accuracy: 0.9850\n",
            "Epoch 6/6\n",
            "16/16 [==============================] - 6s 365ms/step - loss: 0.0539 - accuracy: 0.9851 - val_loss: 0.0620 - val_accuracy: 0.9850\n",
            "4/4 [==============================] - 0s 89ms/step - loss: 0.0620 - accuracy: 0.9850\n",
            "Epoch 1/6\n",
            "16/16 [==============================] - 6s 378ms/step - loss: 0.6691 - accuracy: 0.5876 - val_loss: 0.5226 - val_accuracy: 0.7440\n",
            "Epoch 2/6\n",
            "16/16 [==============================] - 6s 358ms/step - loss: 0.3363 - accuracy: 0.9097 - val_loss: 0.1453 - val_accuracy: 0.9580\n",
            "Epoch 3/6\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.1127 - accuracy: 0.9551 - val_loss: 0.0815 - val_accuracy: 0.9710\n",
            "Epoch 4/6\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.0689 - accuracy: 0.9756 - val_loss: 0.0805 - val_accuracy: 0.9800\n",
            "Epoch 5/6\n",
            "16/16 [==============================] - 6s 361ms/step - loss: 0.0676 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9770\n",
            "Epoch 6/6\n",
            "16/16 [==============================] - 6s 360ms/step - loss: 0.0599 - accuracy: 0.9793 - val_loss: 0.0630 - val_accuracy: 0.9840\n",
            "4/4 [==============================] - 0s 89ms/step - loss: 0.0630 - accuracy: 0.9840\n",
            "Epoch 1/6\n",
            "16/16 [==============================] - 6s 375ms/step - loss: 0.6919 - accuracy: 0.5699 - val_loss: 0.6296 - val_accuracy: 0.5670\n",
            "Epoch 2/6\n",
            "16/16 [==============================] - 6s 359ms/step - loss: 0.5167 - accuracy: 0.7561 - val_loss: 0.2714 - val_accuracy: 0.9520\n",
            "Epoch 3/6\n",
            "16/16 [==============================] - 6s 402ms/step - loss: 0.1527 - accuracy: 0.9523 - val_loss: 0.1117 - val_accuracy: 0.9610\n",
            "Epoch 4/6\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 0.0932 - accuracy: 0.9650 - val_loss: 0.1007 - val_accuracy: 0.9740\n",
            "Epoch 5/6\n",
            "16/16 [==============================] - 6s 363ms/step - loss: 0.0898 - accuracy: 0.9665 - val_loss: 0.0793 - val_accuracy: 0.9780\n",
            "Epoch 6/6\n",
            "16/16 [==============================] - 6s 362ms/step - loss: 0.0666 - accuracy: 0.9786 - val_loss: 0.0664 - val_accuracy: 0.9830\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.0664 - accuracy: 0.9830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boxes': [<matplotlib.lines.Line2D at 0x7f14318fde48>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14318b1d68>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1431848080>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1435c03438>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142f9e5c18>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fba5898>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7f142fd3cbe0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1456377198>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14318a8f60>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14307b2ba8>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fdd3748>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fdd35f8>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14318cce10>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14318cc550>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fa687f0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fa689b0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14307e3a58>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd7a898>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7f14318b1978>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fa8f278>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fd2fc18>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142f9e5be0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fba59b0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fc86630>],\n",
              " 'means': [],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7f1430709320>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fc7cac8>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fdd32b0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142f9e5080>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fa68828>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fa9a438>],\n",
              " 'whiskers': [<matplotlib.lines.Line2D at 0x7f142fbd2518>,\n",
              "  <matplotlib.lines.Line2D at 0x7f1430780e48>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14318b19b0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14318b1ef0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14306d1cc0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fdeb240>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14318cc128>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14318ccda0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142f9e5860>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fa683c8>,\n",
              "  <matplotlib.lines.Line2D at 0x7f142fba5908>,\n",
              "  <matplotlib.lines.Line2D at 0x7f14318613c8>]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQk_0B9VnxM6"
      },
      "source": [
        "32 looks like the optimal batch size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ9JBnZ8pJzT"
      },
      "source": [
        "Much of the above code was taken from Jason Brownlee (https://machinelearningmastery.com/cnn-models-for-human-activity-recognition-time-series-classification/) and manipulated for the ECG data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3-7EDnEprrK"
      },
      "source": [
        "# Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWBu9Skapq6P"
      },
      "source": [
        "Performance Metrics for data provided."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44aGxCmOpvbt",
        "outputId": "e0d3773e-5589-4a9a-8809-37514a3f89a1"
      },
      "source": [
        "#initiate performance metrics lists.\r\n",
        "accuracy1 = []*10\r\n",
        "precision1 = []*10\r\n",
        "recall1 = []*10\r\n",
        "f1_1 = []*10\r\n",
        "\r\n",
        "#repeat 10 times for accuracy.\r\n",
        "for i in range(10):\r\n",
        "  #build model and predict for the test data.\r\n",
        "  model1 = buildmodel(128, 3, 6, 32)\r\n",
        "  #calculate and record performance metrics.\r\n",
        "  pred1 = model1.predict_classes(test_data)\r\n",
        "  accuracy1.append(accuracy_score(test_labels, pred1))\r\n",
        "  precision1.append(precision_score(test_labels, pred1))\r\n",
        "  recall1.append(recall_score(test_labels, pred1))\r\n",
        "  f1_1.append(f1_score(test_labels, pred1))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.4372 - accuracy: 0.7836 - val_loss: 0.0940 - val_accuracy: 0.9740\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0852 - accuracy: 0.9735 - val_loss: 0.0822 - val_accuracy: 0.9840\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0674 - accuracy: 0.9806 - val_loss: 0.0563 - val_accuracy: 0.9870\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0388 - accuracy: 0.9897 - val_loss: 0.0480 - val_accuracy: 0.9890\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0366 - accuracy: 0.9899 - val_loss: 0.0486 - val_accuracy: 0.9930\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.0508 - val_accuracy: 0.9870\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "125/125 [==============================] - 8s 60ms/step - loss: 0.4383 - accuracy: 0.7535 - val_loss: 0.0911 - val_accuracy: 0.9750\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 7s 57ms/step - loss: 0.0848 - accuracy: 0.9746 - val_loss: 0.0621 - val_accuracy: 0.9840\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 7s 57ms/step - loss: 0.0608 - accuracy: 0.9817 - val_loss: 0.0509 - val_accuracy: 0.9880\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 57ms/step - loss: 0.0415 - accuracy: 0.9857 - val_loss: 0.0702 - val_accuracy: 0.9860\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 57ms/step - loss: 0.0527 - accuracy: 0.9867 - val_loss: 0.0417 - val_accuracy: 0.9940\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 7s 57ms/step - loss: 0.0426 - accuracy: 0.9873 - val_loss: 0.0393 - val_accuracy: 0.9910\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 8s 59ms/step - loss: 0.3739 - accuracy: 0.8196 - val_loss: 0.0751 - val_accuracy: 0.9760\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0795 - accuracy: 0.9732 - val_loss: 0.0936 - val_accuracy: 0.9760\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0567 - accuracy: 0.9814 - val_loss: 0.0507 - val_accuracy: 0.9880\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 57ms/step - loss: 0.0394 - accuracy: 0.9903 - val_loss: 0.0407 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0349 - accuracy: 0.9885 - val_loss: 0.0401 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0439 - accuracy: 0.9871 - val_loss: 0.0365 - val_accuracy: 0.9930\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.3804 - accuracy: 0.7978 - val_loss: 0.0756 - val_accuracy: 0.9830\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0807 - accuracy: 0.9724 - val_loss: 0.1372 - val_accuracy: 0.9560\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 7s 57ms/step - loss: 0.0592 - accuracy: 0.9793 - val_loss: 0.0434 - val_accuracy: 0.9890\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0423 - accuracy: 0.9881 - val_loss: 0.0447 - val_accuracy: 0.9900\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0309 - accuracy: 0.9927 - val_loss: 0.0466 - val_accuracy: 0.9920\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0388 - accuracy: 0.9870 - val_loss: 0.0419 - val_accuracy: 0.9920\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.3556 - accuracy: 0.8087 - val_loss: 0.0800 - val_accuracy: 0.9760\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0643 - accuracy: 0.9781 - val_loss: 0.0625 - val_accuracy: 0.9810\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0551 - accuracy: 0.9799 - val_loss: 0.0648 - val_accuracy: 0.9780\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0509 - accuracy: 0.9857 - val_loss: 0.0392 - val_accuracy: 0.9910\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0375 - accuracy: 0.9881 - val_loss: 0.0876 - val_accuracy: 0.9720\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0650 - accuracy: 0.9767 - val_loss: 0.0424 - val_accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.5023 - accuracy: 0.7121 - val_loss: 0.0787 - val_accuracy: 0.9790\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0862 - accuracy: 0.9732 - val_loss: 0.0648 - val_accuracy: 0.9840\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0569 - accuracy: 0.9839 - val_loss: 0.0553 - val_accuracy: 0.9900\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0475 - accuracy: 0.9890 - val_loss: 0.0501 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0364 - accuracy: 0.9881 - val_loss: 0.0468 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0395 - accuracy: 0.9926 - val_loss: 0.0524 - val_accuracy: 0.9840\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 9s 62ms/step - loss: 0.3913 - accuracy: 0.8210 - val_loss: 0.0706 - val_accuracy: 0.9800\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0893 - accuracy: 0.9701 - val_loss: 0.0723 - val_accuracy: 0.9850\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0462 - accuracy: 0.9824 - val_loss: 0.0714 - val_accuracy: 0.9860\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0555 - accuracy: 0.9841 - val_loss: 0.0416 - val_accuracy: 0.9880\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0339 - accuracy: 0.9880 - val_loss: 0.0437 - val_accuracy: 0.9870\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0342 - accuracy: 0.9884 - val_loss: 0.0405 - val_accuracy: 0.9920\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.4020 - accuracy: 0.7949 - val_loss: 0.0779 - val_accuracy: 0.9760\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0593 - accuracy: 0.9787 - val_loss: 0.0623 - val_accuracy: 0.9860\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0477 - accuracy: 0.9832 - val_loss: 0.0511 - val_accuracy: 0.9860\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0450 - accuracy: 0.9856 - val_loss: 0.0458 - val_accuracy: 0.9910\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0383 - accuracy: 0.9884 - val_loss: 0.0444 - val_accuracy: 0.9920\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 0.0461 - val_accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.3645 - accuracy: 0.8128 - val_loss: 0.0846 - val_accuracy: 0.9770\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 8s 60ms/step - loss: 0.0828 - accuracy: 0.9721 - val_loss: 0.0542 - val_accuracy: 0.9850\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0571 - accuracy: 0.9821 - val_loss: 0.0467 - val_accuracy: 0.9900\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 58ms/step - loss: 0.0529 - accuracy: 0.9817 - val_loss: 0.0457 - val_accuracy: 0.9900\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0345 - accuracy: 0.9892 - val_loss: 0.0395 - val_accuracy: 0.9880\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0300 - accuracy: 0.9915 - val_loss: 0.0470 - val_accuracy: 0.9900\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.3242 - accuracy: 0.8455 - val_loss: 0.1061 - val_accuracy: 0.9670\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0678 - accuracy: 0.9757 - val_loss: 0.0502 - val_accuracy: 0.9860\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 8s 60ms/step - loss: 0.0487 - accuracy: 0.9866 - val_loss: 0.0481 - val_accuracy: 0.9850\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0464 - accuracy: 0.9855 - val_loss: 0.0427 - val_accuracy: 0.9930\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 8s 60ms/step - loss: 0.0397 - accuracy: 0.9882 - val_loss: 0.0363 - val_accuracy: 0.9900\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.0410 - accuracy: 0.9891 - val_loss: 0.0378 - val_accuracy: 0.9910\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXCRKY7dLo51"
      },
      "source": [
        "Load in a second dataset for comparison (the data was taken from these sources: https://www.kaggle.com/shayanfazeli/heartbeat?select=ptbdb_abnormal.csv and https://www.kaggle.com/shayanfazeli/heartbeat?select=ptbdb_normal.csv). 2500 observations were taken from each and then combined into the dataset used below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "cm0tJpkxLsUR",
        "outputId": "08945f0b-7718-4a34-987c-3e19142ca042"
      },
      "source": [
        "dataframe = pd.read_csv('https://raw.githubusercontent.com/chloeworthington/SCC413-Computer-Vision-Coursework/main/ecgdata.csv', header = None)\r\n",
        "raw_data = dataframe.values\r\n",
        "dataframe.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>148</th>\n",
              "      <th>149</th>\n",
              "      <th>150</th>\n",
              "      <th>151</th>\n",
              "      <th>152</th>\n",
              "      <th>153</th>\n",
              "      <th>154</th>\n",
              "      <th>155</th>\n",
              "      <th>156</th>\n",
              "      <th>157</th>\n",
              "      <th>158</th>\n",
              "      <th>159</th>\n",
              "      <th>160</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.932233</td>\n",
              "      <td>0.869679</td>\n",
              "      <td>0.886186</td>\n",
              "      <td>0.929626</td>\n",
              "      <td>0.908775</td>\n",
              "      <td>0.933970</td>\n",
              "      <td>0.801043</td>\n",
              "      <td>0.749783</td>\n",
              "      <td>0.687229</td>\n",
              "      <td>0.635100</td>\n",
              "      <td>0.649870</td>\n",
              "      <td>0.635100</td>\n",
              "      <td>0.655083</td>\n",
              "      <td>0.664639</td>\n",
              "      <td>0.633362</td>\n",
              "      <td>0.746308</td>\n",
              "      <td>0.871416</td>\n",
              "      <td>0.938314</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.948740</td>\n",
              "      <td>0.396177</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.039096</td>\n",
              "      <td>0.128584</td>\n",
              "      <td>0.305821</td>\n",
              "      <td>0.640313</td>\n",
              "      <td>0.617724</td>\n",
              "      <td>0.537793</td>\n",
              "      <td>0.352737</td>\n",
              "      <td>0.220678</td>\n",
              "      <td>0.256299</td>\n",
              "      <td>0.357950</td>\n",
              "      <td>0.482189</td>\n",
              "      <td>0.570808</td>\n",
              "      <td>0.577758</td>\n",
              "      <td>0.620330</td>\n",
              "      <td>0.622068</td>\n",
              "      <td>0.618593</td>\n",
              "      <td>0.626412</td>\n",
              "      <td>0.612511</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.606941</td>\n",
              "      <td>0.384181</td>\n",
              "      <td>0.254237</td>\n",
              "      <td>0.223567</td>\n",
              "      <td>0.276836</td>\n",
              "      <td>0.253430</td>\n",
              "      <td>0.184826</td>\n",
              "      <td>0.153349</td>\n",
              "      <td>0.121872</td>\n",
              "      <td>0.125101</td>\n",
              "      <td>0.129136</td>\n",
              "      <td>0.137207</td>\n",
              "      <td>0.137207</td>\n",
              "      <td>0.132365</td>\n",
              "      <td>0.126715</td>\n",
              "      <td>0.158192</td>\n",
              "      <td>0.152542</td>\n",
              "      <td>0.132365</td>\n",
              "      <td>0.168684</td>\n",
              "      <td>0.156578</td>\n",
              "      <td>0.183212</td>\n",
              "      <td>0.191283</td>\n",
              "      <td>0.204197</td>\n",
              "      <td>0.230024</td>\n",
              "      <td>0.244552</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.307506</td>\n",
              "      <td>0.321227</td>\n",
              "      <td>0.327684</td>\n",
              "      <td>0.351897</td>\n",
              "      <td>0.373688</td>\n",
              "      <td>0.397094</td>\n",
              "      <td>0.363196</td>\n",
              "      <td>0.340597</td>\n",
              "      <td>0.307506</td>\n",
              "      <td>0.258273</td>\n",
              "      <td>0.197740</td>\n",
              "      <td>0.199354</td>\n",
              "      <td>0.173527</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.951613</td>\n",
              "      <td>0.923963</td>\n",
              "      <td>0.853303</td>\n",
              "      <td>0.791859</td>\n",
              "      <td>0.734255</td>\n",
              "      <td>0.672043</td>\n",
              "      <td>0.685100</td>\n",
              "      <td>0.670507</td>\n",
              "      <td>0.667435</td>\n",
              "      <td>0.681260</td>\n",
              "      <td>0.616743</td>\n",
              "      <td>0.624424</td>\n",
              "      <td>0.619816</td>\n",
              "      <td>0.596006</td>\n",
              "      <td>0.627496</td>\n",
              "      <td>0.631336</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.612903</td>\n",
              "      <td>0.613671</td>\n",
              "      <td>0.607527</td>\n",
              "      <td>0.586790</td>\n",
              "      <td>0.568356</td>\n",
              "      <td>0.543779</td>\n",
              "      <td>0.526882</td>\n",
              "      <td>0.552995</td>\n",
              "      <td>0.577573</td>\n",
              "      <td>0.592166</td>\n",
              "      <td>0.576037</td>\n",
              "      <td>0.579109</td>\n",
              "      <td>0.573733</td>\n",
              "      <td>0.589862</td>\n",
              "      <td>0.542243</td>\n",
              "      <td>0.519201</td>\n",
              "      <td>0.514593</td>\n",
              "      <td>0.528418</td>\n",
              "      <td>0.493856</td>\n",
              "      <td>0.485407</td>\n",
              "      <td>0.461598</td>\n",
              "      <td>0.478495</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.977819</td>\n",
              "      <td>0.899261</td>\n",
              "      <td>0.230129</td>\n",
              "      <td>0.032348</td>\n",
              "      <td>0.142329</td>\n",
              "      <td>0.223660</td>\n",
              "      <td>0.328096</td>\n",
              "      <td>0.367837</td>\n",
              "      <td>0.381701</td>\n",
              "      <td>0.389094</td>\n",
              "      <td>0.357671</td>\n",
              "      <td>0.379852</td>\n",
              "      <td>0.375231</td>\n",
              "      <td>0.397412</td>\n",
              "      <td>0.388170</td>\n",
              "      <td>0.378004</td>\n",
              "      <td>0.398336</td>\n",
              "      <td>0.419593</td>\n",
              "      <td>0.427911</td>\n",
              "      <td>0.402033</td>\n",
              "      <td>0.378928</td>\n",
              "      <td>0.400185</td>\n",
              "      <td>0.406654</td>\n",
              "      <td>0.422366</td>\n",
              "      <td>0.402033</td>\n",
              "      <td>0.383549</td>\n",
              "      <td>0.398336</td>\n",
              "      <td>0.393715</td>\n",
              "      <td>0.417745</td>\n",
              "      <td>0.388170</td>\n",
              "      <td>0.360444</td>\n",
              "      <td>0.402957</td>\n",
              "      <td>0.392791</td>\n",
              "      <td>0.413124</td>\n",
              "      <td>0.377079</td>\n",
              "      <td>0.327172</td>\n",
              "      <td>0.346580</td>\n",
              "      <td>0.338262</td>\n",
              "      <td>0.356747</td>\n",
              "      <td>0.314233</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.935618</td>\n",
              "      <td>0.801661</td>\n",
              "      <td>0.805815</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.722741</td>\n",
              "      <td>0.480789</td>\n",
              "      <td>0.454829</td>\n",
              "      <td>0.319834</td>\n",
              "      <td>0.266874</td>\n",
              "      <td>0.308411</td>\n",
              "      <td>0.285566</td>\n",
              "      <td>0.343718</td>\n",
              "      <td>0.281412</td>\n",
              "      <td>0.281412</td>\n",
              "      <td>0.283489</td>\n",
              "      <td>0.281412</td>\n",
              "      <td>0.319834</td>\n",
              "      <td>0.311526</td>\n",
              "      <td>0.283489</td>\n",
              "      <td>0.278297</td>\n",
              "      <td>0.274143</td>\n",
              "      <td>0.317757</td>\n",
              "      <td>0.267913</td>\n",
              "      <td>0.275182</td>\n",
              "      <td>0.280374</td>\n",
              "      <td>0.255452</td>\n",
              "      <td>0.313603</td>\n",
              "      <td>0.266874</td>\n",
              "      <td>0.244029</td>\n",
              "      <td>0.198339</td>\n",
              "      <td>0.192108</td>\n",
              "      <td>0.190031</td>\n",
              "      <td>0.134995</td>\n",
              "      <td>0.086189</td>\n",
              "      <td>0.078920</td>\n",
              "      <td>0.036345</td>\n",
              "      <td>0.024922</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.044652</td>\n",
              "      <td>0.024922</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 188 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3         4    ...  183  184  185  186  187\n",
              "0  0.932233  0.869679  0.886186  0.929626  0.908775  ...  0.0  0.0  0.0    0    1\n",
              "1  1.000000  0.606941  0.384181  0.254237  0.223567  ...  0.0  0.0  0.0    0    1\n",
              "2  1.000000  0.951613  0.923963  0.853303  0.791859  ...  0.0  0.0  0.0    0    1\n",
              "3  0.977819  0.899261  0.230129  0.032348  0.142329  ...  0.0  0.0  0.0    0    1\n",
              "4  0.935618  0.801661  0.805815  1.000000  0.722741  ...  0.0  0.0  0.0    0    1\n",
              "\n",
              "[5 rows x 188 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zaFMPNT4MQEv",
        "outputId": "5b1de022-c3d2-41a4-cc65-0dbacfa6e0d3"
      },
      "source": [
        "# The last element contains the labels\r\n",
        "labels = raw_data[:, -1]\r\n",
        "\r\n",
        "# The other data points are the electrocadriogram data\r\n",
        "data = raw_data[:, 0:-1]\r\n",
        "\r\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=21)\r\n",
        "\r\n",
        "# Normalize to [0, 1]\r\n",
        "min_val = tf.reduce_min(train_data)\r\n",
        "max_val = tf.reduce_max(train_data)\r\n",
        "\r\n",
        "train_data = (train_data - min_val) / (max_val - min_val)\r\n",
        "test_data = (test_data - min_val) / (max_val - min_val)\r\n",
        "\r\n",
        "train_data = tf.cast(train_data, tf.float32)\r\n",
        "test_data = tf.cast(test_data, tf.float32)\r\n",
        "\r\n",
        "# plot data\r\n",
        "plt.grid()\r\n",
        "plt.plot(np.arange(187), train_data[0])\r\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "PHoqWK1KMeTW",
        "outputId": "7fe92985-e480-4005-94da-5da5f21f6501"
      },
      "source": [
        "plt.grid()\r\n",
        "plt.plot(np.arange(187), train_data[100])\r\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgXRDMhHNJTF"
      },
      "source": [
        "# the model requires a 3-dimensional input therefore, we need to expand the \r\n",
        "# dimensions of the training and testing data.\r\n",
        "train_data = np.expand_dims(train_data, 2)\r\n",
        "test_data = np.expand_dims(test_data, 2)\r\n",
        "\r\n",
        "# the model requires these to be in binary matrix form.\r\n",
        "train_classes = to_categorical(train_labels, 2)\r\n",
        "test_classes = to_categorical(test_labels, 2)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc7PmgwiMzx0"
      },
      "source": [
        "Performance metrics for second data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99DfiTFmM6OC",
        "outputId": "89c2c605-d89a-43c2-c6ec-30aab2acb817"
      },
      "source": [
        "#initiate performance metrics lists.\r\n",
        "accuracy2 = []*10\r\n",
        "precision2 = []*10\r\n",
        "recall2 = []*10\r\n",
        "f1_2 = []*10\r\n",
        "\r\n",
        "#change input shape\r\n",
        "input_shape = (187, 1)\r\n",
        "\r\n",
        "#repeat 10 times for accuracy.\r\n",
        "for i in range(10):\r\n",
        "  #build model and predict for the test data.\r\n",
        "  model2 = buildmodel(128, 3, 6, 32)\r\n",
        "  #calculate and record performance metrics.\r\n",
        "  pred2 = model2.predict_classes(test_data)\r\n",
        "  accuracy2.append(accuracy_score(test_labels, pred2))\r\n",
        "  precision2.append(precision_score(test_labels, pred2))\r\n",
        "  recall2.append(recall_score(test_labels, pred2))\r\n",
        "  f1_2.append(f1_score(test_labels, pred2))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.5859 - accuracy: 0.6754 - val_loss: 0.4696 - val_accuracy: 0.7910\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.4144 - accuracy: 0.8129 - val_loss: 0.3882 - val_accuracy: 0.8200\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.3443 - accuracy: 0.8479 - val_loss: 0.3589 - val_accuracy: 0.8310\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.3061 - accuracy: 0.8665 - val_loss: 0.2889 - val_accuracy: 0.8960\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.2546 - accuracy: 0.8950 - val_loss: 0.2482 - val_accuracy: 0.9250\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.2203 - accuracy: 0.9071 - val_loss: 0.2297 - val_accuracy: 0.9200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.5276 - accuracy: 0.7183 - val_loss: 0.4225 - val_accuracy: 0.8150\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.3805 - accuracy: 0.8329 - val_loss: 0.3432 - val_accuracy: 0.8530\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.3221 - accuracy: 0.8507 - val_loss: 0.2986 - val_accuracy: 0.8890\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.2900 - accuracy: 0.8774 - val_loss: 0.2797 - val_accuracy: 0.8860\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.2129 - accuracy: 0.9178 - val_loss: 0.2298 - val_accuracy: 0.9310\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.1819 - accuracy: 0.9258 - val_loss: 0.2210 - val_accuracy: 0.9320\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.5527 - accuracy: 0.7136 - val_loss: 0.4598 - val_accuracy: 0.7940\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.3864 - accuracy: 0.8386 - val_loss: 0.3678 - val_accuracy: 0.8580\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.3204 - accuracy: 0.8596 - val_loss: 0.3205 - val_accuracy: 0.8830\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.2579 - accuracy: 0.8974 - val_loss: 0.2506 - val_accuracy: 0.9030\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.2450 - accuracy: 0.8921 - val_loss: 0.2440 - val_accuracy: 0.9280\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 10s 84ms/step - loss: 0.1933 - accuracy: 0.9235 - val_loss: 0.2124 - val_accuracy: 0.9310\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.5468 - accuracy: 0.7100 - val_loss: 0.4241 - val_accuracy: 0.8230\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.3880 - accuracy: 0.8172 - val_loss: 0.3843 - val_accuracy: 0.8370\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.3195 - accuracy: 0.8693 - val_loss: 0.3159 - val_accuracy: 0.8780\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.2614 - accuracy: 0.8919 - val_loss: 0.2406 - val_accuracy: 0.9260\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.2111 - accuracy: 0.9152 - val_loss: 0.2332 - val_accuracy: 0.9310\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.1749 - accuracy: 0.9364 - val_loss: 0.1805 - val_accuracy: 0.9480\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.5520 - accuracy: 0.7254 - val_loss: 0.4587 - val_accuracy: 0.7940\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.4055 - accuracy: 0.8248 - val_loss: 0.4060 - val_accuracy: 0.8310\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.3388 - accuracy: 0.8554 - val_loss: 0.3335 - val_accuracy: 0.8540\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.2930 - accuracy: 0.8746 - val_loss: 0.2738 - val_accuracy: 0.9080\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.2399 - accuracy: 0.9003 - val_loss: 0.2715 - val_accuracy: 0.9100\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.2163 - accuracy: 0.9189 - val_loss: 0.2216 - val_accuracy: 0.9280\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 0.5393 - accuracy: 0.7395 - val_loss: 0.4368 - val_accuracy: 0.8120\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 0.4041 - accuracy: 0.8206 - val_loss: 0.3754 - val_accuracy: 0.8390\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.3290 - accuracy: 0.8563 - val_loss: 0.3089 - val_accuracy: 0.8800\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.2773 - accuracy: 0.8885 - val_loss: 0.2872 - val_accuracy: 0.8960\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 0.2206 - accuracy: 0.9167 - val_loss: 0.2497 - val_accuracy: 0.9110\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.2088 - accuracy: 0.9174 - val_loss: 0.2087 - val_accuracy: 0.9280\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 0.5606 - accuracy: 0.7001 - val_loss: 0.4422 - val_accuracy: 0.8000\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.3979 - accuracy: 0.8314 - val_loss: 0.4052 - val_accuracy: 0.8310\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.3444 - accuracy: 0.8428 - val_loss: 0.3237 - val_accuracy: 0.8600\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.2612 - accuracy: 0.8908 - val_loss: 0.2797 - val_accuracy: 0.8880\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.2278 - accuracy: 0.9062 - val_loss: 0.2204 - val_accuracy: 0.9260\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.1738 - accuracy: 0.9332 - val_loss: 0.2126 - val_accuracy: 0.9380\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 12s 82ms/step - loss: 0.5454 - accuracy: 0.7175 - val_loss: 0.4355 - val_accuracy: 0.7970\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.3896 - accuracy: 0.8258 - val_loss: 0.3587 - val_accuracy: 0.8330\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.3191 - accuracy: 0.8597 - val_loss: 0.3139 - val_accuracy: 0.8750\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.2872 - accuracy: 0.8774 - val_loss: 0.2673 - val_accuracy: 0.9180\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.2317 - accuracy: 0.9053 - val_loss: 0.2409 - val_accuracy: 0.9350\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.2112 - accuracy: 0.9203 - val_loss: 0.2374 - val_accuracy: 0.9190\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.5567 - accuracy: 0.7248 - val_loss: 0.4392 - val_accuracy: 0.7960\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.4002 - accuracy: 0.8192 - val_loss: 0.3818 - val_accuracy: 0.8290\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.3516 - accuracy: 0.8403 - val_loss: 0.3069 - val_accuracy: 0.8930\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.2765 - accuracy: 0.8840 - val_loss: 0.3014 - val_accuracy: 0.8880\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.2362 - accuracy: 0.9093 - val_loss: 0.2357 - val_accuracy: 0.9160\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.1905 - accuracy: 0.9284 - val_loss: 0.2079 - val_accuracy: 0.9300\n",
            "Epoch 1/6\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 0.5529 - accuracy: 0.7103 - val_loss: 0.4251 - val_accuracy: 0.8120\n",
            "Epoch 2/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.4037 - accuracy: 0.8116 - val_loss: 0.3854 - val_accuracy: 0.8410\n",
            "Epoch 3/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.3357 - accuracy: 0.8563 - val_loss: 0.3145 - val_accuracy: 0.8800\n",
            "Epoch 4/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.2629 - accuracy: 0.8888 - val_loss: 0.2427 - val_accuracy: 0.9180\n",
            "Epoch 5/6\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.2353 - accuracy: 0.9015 - val_loss: 0.2371 - val_accuracy: 0.9160\n",
            "Epoch 6/6\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.1793 - accuracy: 0.9330 - val_loss: 0.1954 - val_accuracy: 0.9400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKKrSzPge4Gs"
      },
      "source": [
        "Collate the performance metrics into a dataframe and save for later direct comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs8BzhkMe2f7"
      },
      "source": [
        "cnnperf = pd.DataFrame()\r\n",
        "cnnperf[\"Accuracy1\"] = accuracy1\r\n",
        "cnnperf[\"Precision1\"] = precision1\r\n",
        "cnnperf[\"Recall1\"] = recall1\r\n",
        "cnnperf[\"F1Score1\"] = f1_1\r\n",
        "cnnperf[\"Accuracy2\"] = accuracy2\r\n",
        "cnnperf[\"Precision2\"] = precision2\r\n",
        "cnnperf[\"Recall2\"] = recall2\r\n",
        "cnnperf[\"F1Score2\"] = f1_2\r\n",
        "\r\n",
        "cnnperf.to_csv(\"CNN_performance_metrics.csv\")"
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}